{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sym_cargo_alt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bTzsC2_o8Jg772hCJWDRqrHnkqeQuRQx",
      "authorship_tag": "ABX9TyPgqGSEdBOSEqdLGsbMfcFJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaobviously/sym-cargo/blob/main/sym_cargo_alt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRudeILZCNAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f661a21-e036-4836-dc3d-6c02c0e82c9f"
      },
      "source": [
        "!pip install plotly-express --quiet\n",
        "!pip install vincenty --quiet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for vincenty (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrMMphhGyTIp"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFygxcBXBsUT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, RepeatVector, LSTM, Dense, TimeDistributed\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import EarlyStopping\n",
        "from xgboost import XGBClassifier\n",
        "from vincenty import vincenty\n",
        "from sklearn.model_selection import train_test_split\n",
        "import plotly_express as px"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERdgnPI_B8xV"
      },
      "source": [
        "port_file = '/content/drive/MyDrive/Ports/ports.csv'\n",
        "tracking_file = '/content/drive/MyDrive/Ports/tracking.csv'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGQ3oW9dCGF6"
      },
      "source": [
        "def wrangle():\n",
        "  \n",
        "  df1 = pd.read_csv(port_file)\n",
        "\n",
        "  # converting lat and long to radians to compute haversine distance\n",
        "  df1['lat_rad'] = np.radians(df1['lat'])\n",
        "  df1['long_rad'] = np.radians(df1['long'])\n",
        "  \n",
        "  # rounding lat and long in port df\n",
        "  df1['lat'] = df1['lat']\n",
        "  df1['long'] = df1['long']\n",
        "  df1['lat_long'] = [[x,y] for x, y in zip(df1['lat'], df1['long'])]\n",
        "\n",
        "  df2 = pd.read_csv(tracking_file, parse_dates=['datetime'])\n",
        "  df2 = df2.drop_duplicates()\n",
        "  df2 = df2.sort_values(['vessel', 'datetime'])\n",
        "  df2['vessel_1back'] = df2['vessel'].shift()\n",
        "  \n",
        "  # converting lat and long to radians to compute haversine distance  \n",
        "  df2['lat_rad'] = np.radians(df2['lat'])\n",
        "  df2['long_rad'] = np.radians(df2['long'])\n",
        "\n",
        "  # adding lat/long column and lat/long 1 back to later compute delta\n",
        "  df2['lat_long'] = [[x,y] for x, y in zip(df2['lat'], df2['long'])]\n",
        "  df2['lat_long_1back'] = df2.groupby('vessel')['lat_long'].transform(lambda x: x.shift())\n",
        "  df2['direction'] = pd.cut(df2['heading'],\n",
        "                            bins=[0, 22.5, 67.5, 112.5, 157.5, 202.5, 247.5,\n",
        "                                  292.5, 337.5, 360],\n",
        "                            labels=['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW', 'N'],\n",
        "                            ordered=False,\n",
        "                            include_lowest=True)\n",
        "  \n",
        "  # time delta and hour delta that will be used for filtering - i do it again\n",
        "  # after the filter\n",
        "\n",
        "  df2['time_delta'] = df2.groupby('vessel')['datetime'].transform(lambda x: x - x.shift())\n",
        "  df2['hour_delta'] = [n.total_seconds()/3600 for n in df2['time_delta']]\n",
        "\n",
        "  # i divide the map into quadrants to calculate the proportion of the time each\n",
        "  # vessel was in each quadrant\n",
        "\n",
        "  conditions = [((df2['lat'] > 0) & (df2['long'] > 0)),\n",
        "                ((df2['lat'] < 0) & (df2['long'] > 0)), \n",
        "                ((df2['lat'] > 0) & (df2['long'] < 0)), \n",
        "                ((df2['lat'] < 0) & (df2['long'] < 0))\n",
        "  ]\n",
        "\n",
        "  labels = ['quad1', 'quad4', 'quad2', 'quad3']\n",
        "\n",
        "  df2['quad'] = np.select(conditions, labels)\n",
        "  \n",
        "\n",
        "  # filtering using query to eliminate unneeded/impossible values\n",
        "  df2 = df2.query('speed <30 & heading <=360 & draft < 13.5')\n",
        "  df2 = df2.reset_index(drop=True)\n",
        "\n",
        "  return df1, df2"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZJrWQ6eCIqV"
      },
      "source": [
        "df1, df2 = wrangle()"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tL74j_2a7LR"
      },
      "source": [
        "def vincent_distance(row):\n",
        "  \"\"\" \n",
        "  returns the vincenty distance for contiguous rows - will be used to identify\n",
        "  impossible distances travelled, and so on. could be used to create distance\n",
        "  matrix, but this may not be worthwhile \n",
        "  \"\"\"\n",
        "  if row['vessel'] != row['vessel_1back']:\n",
        "    return -99\n",
        "\n",
        "  loc1 = row['lat_long']\n",
        "  loc2 = row['lat_long_1back']\n",
        "\n",
        "  try:\n",
        "    distance = vincenty(loc1, loc2)\n",
        "    return distance\n",
        "  except:\n",
        "    return -99"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1P_JxyybKHc"
      },
      "source": [
        "# creating a dictionary of ports with their lat and longs - will be used\n",
        "# repeatedly to explore data and assign values\n",
        "\n",
        "ports = {port:(lat, long) for port, lat, long in zip(df1['port'], df1['lat'], df1['long'])}\n",
        "\n",
        "# a dictionary to retrieve the port id from the index\n",
        "idx_ports = {idx:port for idx, port in zip(df1.index, df1.port)}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvA-nfJqtqAQ"
      },
      "source": [
        "# getting the vincenty distances for each pair of ports in the ports.csv file\n",
        "# extracting those that are within 100km of each other\n",
        "\n",
        "close_ones = []\n",
        "\n",
        "for x in df1['lat_long']:\n",
        "  distances = []\n",
        "  for y in df1['lat_long']:\n",
        "    vdist = vincenty(x, y)\n",
        "    distances.append(vdist)\n",
        "  close_ones.append(distances)\n",
        "\n",
        "disters = [[(df1['port'].iloc[n], z) for n, z in zip(np.argsort(p)[:5], sorted(p)[:5])] for p in close_ones]\n",
        "\n",
        "close_ones = {}\n",
        "\n",
        "for n in disters:\n",
        "  port = n[0][0]\n",
        "  dees = {d:v for d, v in n[1:] if v < 100}\n",
        "  close_ones[port] = dees\n",
        "\n",
        "close_ones = {k:v for k,v in close_ones.items() if len(v) >= 1}\n",
        "\n",
        "really_close = [30, 109, 42, 51, 65]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGEzp5sWtDyn"
      },
      "source": [
        "really_close.extend([71, 108, 139, 63, 152, 102])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rg5F1xcTElh",
        "outputId": "53d72ba2-caec-424c-924f-e68b1fc4c561"
      },
      "source": [
        "# training a nearest neighbor model to  find the closest port when the \n",
        "# conditions indicating an extended stop have occurred. the metric is haversine\n",
        "# in order to compute the 'great circle' distance. so i don't forget, the model\n",
        "# returns the *index* of the port, not the port's identifying label\n",
        "\n",
        "ports_train = df1[['lat_rad', 'long_rad']]\n",
        "\n",
        "neigh_ports = NearestNeighbors(n_neighbors=3, algorithm='ball_tree', metric='haversine')\n",
        "neigh_ports.fit(ports_train)\n",
        "\n",
        "dist, n = neigh_ports.kneighbors(np.array([0.677565, 0.469731]).reshape(1,-1))\n",
        "\n",
        "print(dist[0] * 6370)\n",
        "print([idx_ports[n] for n in n[0]])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  3.30931026  46.44757565 255.13837716]\n",
            "[82, 113, 44]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC92dd_FI7MT"
      },
      "source": [
        "def nearest_port(df, radius=0.015):\n",
        "  \"\"\"\n",
        "  returns the port identifier of the nearest port using the nearest neighbors\n",
        "  model \n",
        "  \"\"\"\n",
        "\n",
        "  data = np.array([df['lat_rad'], df['long_rad']]).reshape(1, -1)\n",
        "  dist, pred = neigh_ports.radius_neighbors(data, radius=radius, sort_results = True) \n",
        "\n",
        "  if len(dist[0]) == 0:\n",
        "    return -1\n",
        "  \n",
        "  else:\n",
        "    return idx_ports[pred[0][0]]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2cHgfSNZbx2"
      },
      "source": [
        "def nearest_distance(df, radius=0.015):\n",
        "  \"\"\"\n",
        "  returns the distance of the nearest port in the dataset\n",
        "  \"\"\"\n",
        "  \n",
        "  data = np.array([df['lat_rad'], df['long_rad']]).reshape(1, -1)\n",
        "  dist, pred = neigh_ports.radius_neighbors(data, radius=radius, sort_results = True) \n",
        "\n",
        "  if len(dist[0]) == 0:\n",
        "    return -1\n",
        "  \n",
        "  else:\n",
        "    return dist[0][0]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoYZuM6lqJIa"
      },
      "source": [
        "def vincenty_port(row):\n",
        "  \"\"\"\n",
        "  a function that computes the vincenty distance between the assigned port\n",
        "  and the latitude and longitude of the location data\n",
        "  \"\"\"\n",
        "  port = row['port_coords']\n",
        "  loc = row['lat_long']\n",
        "  return vincenty(port, loc)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLCHF2I5CII2"
      },
      "source": [
        "def train_dbscan(df=df1, eps=0.1, min_samples=4):\n",
        "  \"\"\"\n",
        "  use the dbscan clustering algorithm to find groupss of ports\n",
        "\n",
        "  params\n",
        "  ------\n",
        "      df: pandas df\n",
        "      eps: min distance between points in cluster\n",
        "      min_samples: min members in a cluster\n",
        "\n",
        "  returns\n",
        "  -------\n",
        "      labels: labels matching index of long/lat input pairs\n",
        "  \"\"\"\n",
        "  \n",
        "  coords = df[['long_rad', 'lat_rad']].values\n",
        "  db = DBSCAN(eps=eps, min_samples=min_samples, algorithm='ball_tree', metric='haversine')\n",
        "\n",
        "  db.fit(coords)\n",
        "\n",
        "  return db.labels_"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkBxR8F_UykW"
      },
      "source": [
        "def fix_ports(testdf):\n",
        "  \"\"\"\n",
        "  fills out port sequences if there's a draft change in the sequence. this will\n",
        "  help get better arrival and departure dates. it should be applied to \n",
        "  groupby DataFrames \n",
        "\n",
        "  parameters\n",
        "  ----------\n",
        "      df: a pandas DataFrame\n",
        "\n",
        "  returns\n",
        "  -------\n",
        "      df: a pandas Series\n",
        "  \"\"\"\n",
        "  \n",
        "  ugh = []\n",
        "\n",
        "  for x in testdf['port_sequence'].unique():\n",
        "    df_ = testdf.query(f'port_sequence == {x}')\n",
        "    ports = df_['pred_port']\n",
        "    new_ports = []\n",
        "    if not all(ports <= 0):\n",
        "      new_ports.append([ports.max()] * len(ports))\n",
        "    else:\n",
        "      new_ports.append(ports)\n",
        "  \n",
        "    ugh.append(new_ports[0])\n",
        "  \n",
        "  \n",
        "  thisthis = []\n",
        "\n",
        "  for n in ugh:\n",
        "    for p in n:\n",
        "      thisthis.append(p)\n",
        "\n",
        "  return thisthis"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU_Co92uMDoL"
      },
      "source": [
        "# creating a dictionary of labels\n",
        "df1['labels'] = train_dbscan()\n",
        "db_labels = {port:cluster for port, cluster in zip(df1['port'], df1['labels'])}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDnoQ4hnfhce"
      },
      "source": [
        "def get_voyages(df):\n",
        "  \"\"\"\n",
        "  converts the port sequences in each dataframe into voyages\n",
        "  with the proper formatting\n",
        "\n",
        "  param:\n",
        "  -----\n",
        "      df: pandas DataFrame\n",
        "  \n",
        "  returns:\n",
        "  -------\n",
        "      df: processed pandas DataFrame\n",
        "      \n",
        "  \"\"\"\n",
        "  # filtering out columns without an assigned port\n",
        "  nz = df[(df['pred_port'] > 0) | (df['pred_port'] == -75)].reset_index()\n",
        "\n",
        "  vessel = nz['vessel'][0]\n",
        "  dt = nz['datetime']\n",
        "  pred = nz['pred_port']\n",
        "\n",
        "  records = []\n",
        "\n",
        "  for i in range(len(dt)-1):\n",
        "    if pred[i] != pred[i+1]:\n",
        "      start_port = pred[i]\n",
        "      end_port = pred[i+1]\n",
        "      begin_date = dt[i]\n",
        "      end_date = dt[i+1]\n",
        "      records.append([vessel, begin_date, end_date, start_port, end_port])\n",
        "\n",
        "  df = pd.DataFrame.from_records(records, columns = ['vessel', 'begin_date', 'end_date', 'begin_port_id', 'end_port_id'])\n",
        "  \n",
        "  return df"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gr1MtPzAGrP"
      },
      "source": [
        "def fix_really_close_cluster(row):\n",
        "  \"\"\"\n",
        "  Applies filters to ports: come back to this.\n",
        "\n",
        "  Heading sequence time is maybe the simplest\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  duration = row['port_sequence_time']\n",
        "  dist = row['pred_port_dist']\n",
        "\n",
        "  if row['pred_port_backup'] in ([72, 152]):\n",
        "    if ((duration > 48) & (dist < 50) & (row['heading_sequence_time'] > 8)):\n",
        "      return row['pred_port_backup']\n",
        "    else:\n",
        "      return row['pred_port']\n",
        "\n",
        "  elif row['pred_port_backup'] in ([115, 54]):\n",
        "    if ((dist < 15) & (row['heading_sequence_time'] > 12)):\n",
        "      return row['pred_port_backup']\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  elif dist < 2:\n",
        "    if ((duration > 16) & (dist <2)):\n",
        "      return row['pred_port_backup']\n",
        "    else:\n",
        "      return row['pred_port']\n",
        "\n",
        "  elif row['heading_sequence_time'] > 30:\n",
        "    if dist <= 10:\n",
        "      return row['pred_port_backup']\n",
        "    else:\n",
        "      return row['pred_port']\n",
        "  \n",
        "  elif row['heading_sequence_time'] > 6:\n",
        "    if ((duration >25) & (dist <=15)):\n",
        "      return row['pred_port_backup']\n",
        "    else:\n",
        "      return row['pred_port']\n",
        "\n",
        "  else:\n",
        "    return row['pred_port']"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x2drUA6JrXt"
      },
      "source": [
        "def fix_close_ports(testdf):\n",
        "  \"\"\"\n",
        "  compares adjacent port assignments minimum distances and returns a new series\n",
        "  with ports reassigned where appropriate\n",
        "\n",
        "  parameters\n",
        "  ----------\n",
        "      df: a pandas DataFrame\n",
        "\n",
        "  returns\n",
        "  -------\n",
        "      df: a pandas Series\n",
        "  \"\"\" \n",
        "\n",
        "  new_destinations = []\n",
        "\n",
        "  for seq in range(1, len(testdf['port_sequence'].unique()) +1):\n",
        "    seq1_port = testdf[testdf['port_sequence'] == seq].pred_port\n",
        "    seq2_port = testdf[testdf['port_sequence'] == seq + 1].pred_port\n",
        "    seq1_mindist = testdf[testdf['port_sequence'] == seq].pred_port_dist\n",
        "    seq2_mindist = testdf[testdf['port_sequence'] == seq+1].pred_port_dist\n",
        "    new_ports = []\n",
        "\n",
        "    if (seq1_port.max() <= 0) or (seq2_port.max() <= 0):\n",
        "      new_ports.append([seq1_port.max()] * len(seq1_port))\n",
        "    \n",
        "    elif seq2_mindist.min() < seq1_mindist.min():\n",
        "      true_port = seq2_port\n",
        "      new_ports.append([true_port.max()] * len(seq1_port))\n",
        "    else:\n",
        "      new_ports.append([seq1_port.max()] * len(seq1_port))\n",
        "    \n",
        "    new_destinations.append(new_ports[0])\n",
        "  \n",
        "  new_dest = []\n",
        "\n",
        "  for dest in new_destinations:\n",
        "    for d in dest:\n",
        "      new_dest.append(d)\n",
        "\n",
        "  return new_dest  "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jydaj-qScpp"
      },
      "source": [
        "def get_prior_port(df):\n",
        "  \"\"\"\n",
        "  iterate through the each vessel's predicted ports to get the last predicted\n",
        "  port\n",
        "  \"\"\"\n",
        "\n",
        "  p = df['pred_port'][::-1].values\n",
        "\n",
        "  prior_ports = []\n",
        "\n",
        "  for i in range(len(p)):\n",
        "    s = p[i]\n",
        "    for n in p[i:]:\n",
        "      if (s != n) & (n >0) :\n",
        "       prior_ports.append(n)\n",
        "       break\n",
        "\n",
        "# padding zeros at the end to indicate no next port \n",
        "  zeroes = [0] * (len(p) - len(prior_ports))\n",
        "  prior_ports = prior_ports + zeroes\n",
        "  \n",
        "  prior_ports = prior_ports[::-1]\n",
        "  \n",
        "  return prior_ports "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4gOeftL1KN0"
      },
      "source": [
        "def get_angle(loc1=[1.2, 103], loc2=[99.5,-32]):\n",
        "  \"\"\"\n",
        "  get the angle of the bearing needed to directly approach the nearest port.\n",
        "  running out of ideas!\n",
        "\n",
        "  parameters\n",
        "  ----------\n",
        "        lists: lat, longitude of ship (in dict as such)\n",
        "\n",
        "  returns\n",
        "  -------\n",
        "        float: bearing in degrees with 0 as due North\n",
        "  \"\"\"\n",
        "  \n",
        "  dLon = (loc2[1] - loc1[1])\n",
        "\n",
        "  y = math.sin(dLon) * math.cos(loc2[0])\n",
        "  x = math.cos(loc1[0]) * math.sin(loc2[0]) - math.sin(loc1[0]) * math.cos(loc2[0]) * math.cos(dLon)\n",
        "\n",
        "  brng = math.atan2(y, x)\n",
        "\n",
        "  brng = math.degrees(brng)\n",
        "  brng = (brng + 360) % 360\n",
        "  brng = 360 - brng # count degrees clockwise - remove to make counter-clockwise\n",
        "\n",
        "  return brng"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbHcYBVQcWst"
      },
      "source": [
        "# calculating the distance between each row using the vincenty function above.\n",
        "# note it only calcs within each vessel group (see function). the elapsed time\n",
        "# and the total distance travelled implies a speed and that speed creates a \n",
        "# simple filter \n",
        "\n",
        "df2['vin_diff'] = df2.apply(vincent_distance, axis=1)\n",
        "df2['vin_per_hour'] = df2['vin_diff'] / df2['hour_delta']\n",
        "df2 = df2.query('vin_per_hour <= 50')\n",
        "df2 = df2.sort_values(by=['vessel', 'datetime'])\n",
        "\n",
        "# time deltas to be used later to filter voyages and a new lat/long calc \n",
        "\n",
        "df2['time_delta'] = df2.groupby('vessel')['datetime'].transform(lambda x: x - x.shift(-1))\n",
        "df2['hour_delta'] = [abs(n.total_seconds()/3600) for n in df2['time_delta']]\n",
        "df2['lat_long_1back'] = df2.groupby('vessel')['lat_long'].transform(lambda x: x.shift())\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0M6rssmoH4G"
      },
      "source": [
        "# calculating draft forwards and backwards \n",
        "\n",
        "df2['draft_raw'] = df2.groupby('vessel')['draft'].transform(lambda x: x.diff())\n",
        "df2['draft_delta_back'] = df2.groupby('vessel')['draft'].transform(lambda x: abs(x.diff()).ge(0.69)).astype(int)\n",
        "df2['draft_delta_ahead'] = df2.groupby('vessel')['draft'].transform(lambda x: abs(x.diff(-1)).ge(0.69)).astype(int)\n",
        "df2['draft_change'] = ((df2['draft_delta_back'] + df2['draft_delta_ahead']) >= 1).astype(int)\n",
        "\n",
        "df2['heading_change'] = df2.groupby('vessel')['heading'].transform(lambda x: abs(x.diff()))\n",
        "df2['heading_change'] = [360 - x if x > 180 else x for x in df2['heading_change']]\n",
        "df2['heading_seq'] = df2.groupby('vessel')['heading'].transform(lambda x: abs(x.diff()).gt(3).cumsum()+1)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJFUdD56oZ-_"
      },
      "source": [
        "# assigning ports using the nearest neighbor model. decided against the use of \n",
        "# a mask\n",
        "\n",
        "df2['pred_port'] = df2.apply(nearest_port, axis=1)\n",
        "df2['pred_port_backup'] = df2['pred_port']\n",
        "df2['port_sequence'] = df2.groupby('vessel')['pred_port'].transform(lambda x: x.diff().ne(0).cumsum())"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fsLG0KDn0os"
      },
      "source": [
        "df2['consec_port_sequence'] = df2.groupby('vessel')['pred_port_backup'].transform(lambda x: x.gt(0).astype(int).diff().ne(0).cumsum())"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wmbGxlEpA_k"
      },
      "source": [
        "# calculating the distance from the predicted port using the more precise \n",
        "# vincenty distance. again, a mask is applied to speed it up.\n",
        "\n",
        "df2['port_coords'] = [list(ports[k]) if k in ports else -99 for k in df2['pred_port']]\n",
        "\n",
        "vin_mask = df2['pred_port'] > 0\n",
        "temp_vin = df2[vin_mask]\n",
        "\n",
        "df2['pred_port_dist'] = 0\n",
        "df2.loc[vin_mask, 'pred_port_dist'] = temp_vin.apply(vincenty_port, axis=1)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0VvF85yBNHo"
      },
      "source": [
        "df2['max_min_distance'] = df2.groupby(['vessel', 'port_sequence'])['pred_port_dist'].transform(lambda x: x.max() - x.min())\n",
        "df2['port_sequence_time'] = df2.groupby(['vessel', 'port_sequence'])['hour_delta'].transform(lambda x: abs(x).sum())\n",
        "df2['heading_sequence_time'] = df2.groupby(['vessel', 'heading_seq'])['hour_delta'].transform(lambda x: abs(x).sum())\n",
        "df2['consec_port_min_dist'] = df2.groupby(['vessel', 'consec_port_sequence'])['pred_port_dist'].transform(lambda x: x.min())"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpyFy66-4l3r"
      },
      "source": [
        "df2['consec_port_min_dist'] = round(df2['consec_port_min_dist'], 2)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJQlMP_Kpm-8"
      },
      "source": [
        "# getting the last port with a function and then flattening the lists it\n",
        "# returned for each vessel and appending them to the dataframe\n",
        "\n",
        "last_ports = df2.groupby(\"vessel\").apply(get_prior_port)\n",
        "last_ports_col = []\n",
        "\n",
        "for lps in last_ports:\n",
        "  for lp in lps:\n",
        "    last_ports_col.append(lp)\n",
        "\n",
        "df2['prior_port'] = last_ports_col\n",
        "df2['dist_last_port'] = [vincenty(l, ports[p]) if p>0 else 0 for l, p in zip(df2['lat_long'], df2['prior_port'])]"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QKDBR5yFIfI"
      },
      "source": [
        "df2['rolling_unique_vals'] = df2.groupby('vessel')['pred_port_backup'].apply(lambda x: x.rolling(8, center=True).apply(lambda x: x[x>0].nunique()))\n",
        "df2['window_min_dist'] = df2.groupby('vessel')['pred_port_dist'].apply(lambda x: x.rolling(8, center=True).apply(lambda x: x[x>0].min()))"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WV_uIjuq_35"
      },
      "source": [
        "# processing the dataframes with conditions. it is setup this way to allow for\n",
        "# fast iteration\n",
        "\n",
        "processed_dfs = {}\n",
        "\n",
        "for df in df2.vessel.unique():\n",
        "  df_ = df2.query(f'vessel == {df}').set_index('datetime')\n",
        "  df_['pred_port'] = np.where(df_['draft_change'] < 1, 0, df_['pred_port'])\n",
        "  \n",
        "  condition = ((df_['pred_port'].isin(really_close)) & (df_['pred_port_dist'] >13))\n",
        "  df_['pred_port'] = np.where(condition, 0, df_['pred_port'])\n",
        "\n",
        "  # df_['pred_port'] = df_.apply(fix_really_close_cluster, axis=1)\n",
        "\n",
        "  df_['pred_port'] = np.where(df_['port_sequence_time'] < 16, 0, df_['pred_port'])\n",
        "\n",
        "  df_['fixed_ports'] = fix_close_ports(df_)\n",
        "  df_['pred_port'] = [x if x == y else 0 for x, y in zip(df_['pred_port_backup'], df_['fixed_ports'])]\n",
        "\n",
        "  condition2 = (df_['pred_port'].isin([115, 54]) & (df_['pred_port_dist'] >16))\n",
        "  df_['pred_port'] = np.where(condition2, 0, df_['pred_port'])\n",
        "\n",
        "  df_['pred_port'] = df_.apply(fix_really_close_cluster, axis=1)\n",
        "\n",
        "  last_ports = df_.groupby('vessel').apply(get_prior_port)\n",
        "  last_ports_col = []\n",
        "\n",
        "  for lps in last_ports:\n",
        "    for lp in lps:\n",
        "      last_ports_col.append(lp)\n",
        "\n",
        "  condition = ((df_['heading_sequence_time'] < 6) & (df_['pred_port'] >0) & (df_['draft_change'] <1))\n",
        "  df_['pred_port'] = np.where(condition, 0, df_['pred_port'])\n",
        "  \n",
        "  df_['prior_port'] = last_ports_col\n",
        "  df_['dist_last_port'] = [vincenty(l, ports[p]) if p>0 else 0 for l, p in zip(df_['lat_long'], df_['prior_port'])]\n",
        "  \n",
        "  processed_dfs[df] = df_"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SIs4v7TvD-a"
      },
      "source": [
        "voyages_df = pd.concat([get_voyages(processed_dfs[key]) for key in processed_dfs.keys()])\n",
        "voyages_df['begin_date'] = voyages_df['begin_date'].dt.date\n",
        "voyages_df['end_date'] = voyages_df['end_date'].dt.date\n",
        "# voyages_df['len_voyage'] = voyages_df['end_date'] - voyages_df['begin_date']\n",
        "# voyages_df['begin_coords'] = [ports[key] for key in voyages_df['begin_port_id']]\n",
        "# voyages_df['end_coords'] = [ports[key] for key in voyages_df['end_port_id']]\n",
        "# voyages_df['voyage_dist'] = [vincenty(x, y) for x, y in zip(voyages_df['begin_coords'], voyages_df['end_coords'])]\n",
        "voyages_df.shape"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZR-g7o0KH6H"
      },
      "source": [
        "# creating a simple clustering model of vessels using KMeans\n",
        "\n",
        "vessel_hours = df2.groupby(['vessel', 'quad'])['hour_delta'].sum().abs().reset_index()\n",
        "vessel_df = vessel_hours.pivot(index='vessel', columns='quad', values='hour_delta').fillna(0)\n",
        "vessel_df = vessel_df.div(vessel_df.sum(axis=1), axis=0)\n",
        "vessel_df = vessel_df.merge(voyages_df.groupby('vessel')['voyage_dist'].mean(), left_index=True, right_index=True)\n",
        "\n",
        "# scaling the values\n",
        "scaler = StandardScaler()\n",
        "scaled_vessel_df = scaler.fit_transform(vessel_df)\n",
        "\n",
        "# using a loop to determine the number of clusters to use\n",
        "kmeans_inertias = []\n",
        "\n",
        "for n in range(2, 10):\n",
        "  kmeans_vessels = KMeans(n_clusters=n)\n",
        "  kmeans_vessels.fit(scaled_vessel_df)\n",
        "  kmeans_inertias.append(kmeans_vessels.inertia_)\n",
        "\n",
        "\n",
        "plt.plot(range(2,10), kmeans_inertias)\n",
        "plt.title(\"Elbow Plot\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7kICzxY9Enr"
      },
      "source": [
        "# the kmeans model that's used in the xgboost model\n",
        "\n",
        "kmeans_vessels = KMeans(n_clusters = 3)\n",
        "kmeans_vessels.fit(scaled_vessel_df)\n",
        "\n",
        "kmeans_vessels.labels_\n",
        "\n",
        "vessel_df['labels'] = kmeans_vessels.labels_\n",
        "\n",
        "# creating a dictionary with the labels\n",
        "kmeans_labels = {v:label for v, label in zip(vessel_df.index, vessel_df['labels'])}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF-vL7n3WKGb"
      },
      "source": [
        "def prepare_data(df, n_input = 3):\n",
        "  \"\"\"\n",
        "  preparing the sequences for window based models\n",
        "  \"\"\"\n",
        "\n",
        "  df = get_voyages(df)\n",
        "  vessel = df['vessel'].iloc[0]\n",
        "  ports_ = np.array(df['begin_port_id'].append(pd.Series(df['end_port_id'].iloc[-1])))  \n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "  start = 0\n",
        "\n",
        "  for i in range(len(ports_)):\n",
        "    last_input = start + n_input\n",
        "    last_output = last_input + 3\n",
        "    if last_output <= len(ports_):\n",
        "      x = ports_[start:last_input]\n",
        "      y = ports_[last_input: last_output]\n",
        "      X.append(x)\n",
        "      Y.append(y)\n",
        "      start += 1\n",
        "  try:\n",
        "    df = pd.concat([pd.DataFrame(X),\n",
        "                  pd.DataFrame(Y, columns=['port_1ahead', 'port_2ahead', 'port_3ahead'])], axis=1)\n",
        "    \n",
        "  except:\n",
        "    df = pd.DataFrame()\n",
        "    \n",
        "  # X = []\n",
        "\n",
        "  # for x in X:\n",
        "  #   for n in x:\n",
        "  #     if n == -75:\n",
        "  #       port_coords = [33, 140]\n",
        "  #     else:\n",
        "  #       port_coords = list(ports[n])\n",
        "  #     port = [n]\n",
        "  #     port.extend(port_coords)\n",
        "  #     new_X.append(port)\n",
        "  \n",
        "  df['vessel'] = len(df) * [vessel]\n",
        "  df['kmeans_label'] = [kmeans_labels[n] for n in df['vessel']]\n",
        "  \n",
        "  return df.astype(int)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtTQNF2qY-RB"
      },
      "source": [
        "def build_model(target='port_1ahead', min_samples=1, n_back = 3):\n",
        "\n",
        "  model_df = pd.concat([prepare_data(processed_dfs[key], n_back) for key in processed_dfs.keys()]) \n",
        "\n",
        "  model_df['cluster_1back'] = [db_labels[n] for n in model_df[0]]\n",
        "  model_df['cluster_2back'] = [db_labels[n] for n in model_df[1]]\n",
        "  model_df['cluster_3back'] = [db_labels[n] for n in model_df[2]]\n",
        "\n",
        "  model_df['samples'] = model_df.groupby('vessel')['vessel'].transform(lambda x: x.count())\n",
        "  filtered_df = model_df.query('samples > @min_samples')\n",
        "\n",
        "  vessels_excluded = set(model_df['vessel'].unique()).difference(set(filtered_df['vessel'].unique()))\n",
        "\n",
        "  features = [n for n in range(n_back)] + ['cluster_1back', 'cluster_2back', 'cluster_3back', 'kmeans_label'] \n",
        "  target = target\n",
        "\n",
        "  X = filtered_df[features]\n",
        "  y = filtered_df[target]\n",
        "  model = XGBClassifier()\n",
        "\n",
        "  param_grid = {\n",
        "      'learning_rate': [0.01, 0.05, 0.1]\n",
        "  }\n",
        "\n",
        "  grid_search = GridSearchCV(model, param_grid, cv=3)\n",
        "  grid_result = grid_search.fit(X, y)\n",
        "\n",
        "  print('The training excluded vessels:', vessels_excluded)\n",
        "  print('The best model params were:', grid_result.best_params_)\n",
        "  print('The best accuracy achieved was:', grid_result.best_score_)\n",
        "  \n",
        "  return grid_result"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtEHbOIdTCDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f4bf00-f960-47e8-efc0-e79b1191a44d"
      },
      "source": [
        "model_1ahead = build_model(target='port_1ahead', min_samples=2, n_back=3)\n",
        "model_2ahead = build_model(target='port_2ahead', min_samples=2, n_back=3)\n",
        "model_3ahead = build_model(target='port_3ahead', min_samples=2, n_back=3)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The training excluded vessels: {107, 75, 85}\n",
            "The best model params were: {'learning_rate': 0.05}\n",
            "The best accuracy achieved was: 0.39956830447776515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The training excluded vessels: {107, 75, 85}\n",
            "The best model params were: {'learning_rate': 0.01}\n",
            "The best accuracy achieved was: 0.3821208863331455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The training excluded vessels: {107, 75, 85}\n",
            "The best model params were: {'learning_rate': 0.05}\n",
            "The best accuracy achieved was: 0.3538963914193894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5ERpuNpF_WT"
      },
      "source": [
        "def get_pred_data(df, n_input = 3):\n",
        "  \"\"\"\n",
        "  preparing the sequences for predictions with the XGBClassifier model\n",
        "  \"\"\"\n",
        "\n",
        "  df = get_voyages(df)\n",
        "  vessel = df['vessel'].iloc[0]\n",
        "  ports_ = np.array(df['begin_port_id'].append(pd.Series(df['end_port_id'].iloc[-1])))\n",
        "  \n",
        "  pred_seq = ports_[-n_input:]\n",
        "\n",
        "  if len(pred_seq) < n_input:\n",
        "    pred_seq = np.insert(pred_seq, 0, pred_seq[-1])\n",
        "  \n",
        "  return pred_seq"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NlGujqAv2FW"
      },
      "source": [
        "# creating a dictionary with the most recent ports visited for each vessel\n",
        "\n",
        "window_data = {key:get_pred_data(processed_dfs[key], n_input=3) for key in processed_dfs.keys()}"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJkGCyNIwvvS"
      },
      "source": [
        "# creating a dataframe with the features used in the models\n",
        "\n",
        "sub = pd.DataFrame.from_dict(window_data, orient='index')\n",
        "\n",
        "sub['cluster_1back'] = [db_labels[n] for n in sub[0]]\n",
        "sub['cluster_2back'] = [db_labels[n] for n in sub[1]]\n",
        "sub['cluster_3back'] = [db_labels[n] for n in sub[2]]\n",
        "sub['kmeans_label'] = [kmeans_labels[n] for n in sub.index]"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i6_80Y91LAe"
      },
      "source": [
        "# predicting the next port. also including the second most likely port in case\n",
        "# the model predicts duplicates. \n",
        "\n",
        "port_1 = model_1ahead.predict(sub)\n",
        "port_2 = model_2ahead.predict(sub)\n",
        "port_2_alt = [model_2ahead.best_estimator_.classes_[np.argsort(n)[-2]] for n in model_2ahead.predict_proba(sub)]\n",
        "port_3 = model_3ahead.predict(sub)\n",
        "port_3_alt = [model_3ahead.best_estimator_.classes_[np.argsort(n)[-2]] for n in model_3ahead.predict_proba(sub)]\n",
        "sub['port_1ahead'] = port_1\n",
        "sub['port_2ahead'] = port_2\n",
        "sub['port_2ahead_2nd'] = port_2_alt\n",
        "sub['port_3ahead'] = port_3\n",
        "sub['port_3ahead_2nd'] = port_3_alt"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VJNB5MI0E0a"
      },
      "source": [
        "# using conditional assignment to replace port predictions with the second most\n",
        "# likely\n",
        "\n",
        "sub.loc[sub['port_1ahead'] == sub['port_2ahead'], 'port_2ahead'] = sub['port_2ahead_2nd']\n",
        "sub.loc[sub['port_2ahead'] == sub['port_3ahead'], 'port_3ahead'] = sub['port_3ahead_2nd']"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3SrpcaTKtDo"
      },
      "source": [
        "# changing the shape of the dataframe so it conforms to what's required\n",
        "\n",
        "# resetting the index and renaming the column\n",
        "sub = sub.reset_index()\n",
        "sub.rename(columns={'index':'vessel'}, inplace=True)\n",
        "\n",
        "# limiting columns to those required and renaming\n",
        "sub = sub[['vessel', 2, 'port_1ahead', 'port_2ahead', 'port_3ahead']]\n",
        "sub.rename(columns={2:'final_port'}, inplace=True)\n",
        "\n",
        "# using melt to narrow the DataFrame and put the voyages into the same column\n",
        "sub = pd.melt(sub, id_vars='vessel').sort_values(by=['vessel', 'variable'])\n",
        "sub['end_port_id'] = sub.groupby('vessel')['value'].transform(lambda x: x.shift(-1))\n",
        "sub = sub.dropna()\n",
        "\n",
        "# adding a voyage count, more renaming\n",
        "sub['voyage'] = sub.groupby('vessel').cumcount()+1\n",
        "sub.rename(columns={'value' : 'begin_port_id'}, inplace=True)\n",
        "sub.drop(columns=['variable'], inplace=True)\n",
        "sub['end_port_id'] = sub['end_port_id'].astype(int)\n",
        "sub = sub.reset_index(drop=True)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_6avCrtDDhQ"
      },
      "source": [
        "Creating an LSTM model to predict the future voyages. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1wikN3M42_m"
      },
      "source": [
        "# creating a dataset to train the LSTM model. i had to do a bit of troubleshooting,\n",
        "# hence the try/except\n",
        "\n",
        "lstm_data = []\n",
        "\n",
        "for i in processed_dfs.keys():\n",
        "  try:\n",
        "    x = prepare_data(processed_dfs[i], n_input=6)\n",
        "    lstm_data.append(x)\n",
        "  except:\n",
        "    print(i)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj9dvByke8iK"
      },
      "source": [
        "# a dictionary to encode the ports for the model\n",
        "\n",
        "encoder = {key:value for key, value in zip(df1['port'], df1.index)}"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWPWg-FVSLyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65eaf105-9d72-43ad-cd74-f0af3032c011"
      },
      "source": [
        "# concatenating the LSTM data\n",
        "lstm_df = pd.concat(lstm_data)\n",
        "\n",
        "# defining the number of ports\n",
        "total_ports = len(encoder.keys())\n",
        "\n",
        "# slicing off the feature array\n",
        "X = lstm_df[[0, 1, 2, 3, 4, 5]]\n",
        "\n",
        "# encoding each port to create a \"vocabulary\" of ports starting at index 0\n",
        "for col in X.columns:\n",
        "  X.loc[:,col] = X[col].map(encoder)\n",
        "\n",
        "# creating the target array with shape (samples, 3, 1) and converting to category\n",
        "y = lstm_df[['port_1ahead', 'port_2ahead', 'port_3ahead']]\n",
        "y = to_categorical(y)\n",
        "\n",
        "# train and test split to validate model during training - could use 'validation_split' in .fit()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1944)\n",
        "\n",
        "# initializing the Sequential class\n",
        "model = Sequential()\n",
        "\n",
        "# adding an embedding layer to embed each port in a 3 dimensional space\n",
        "model.add(Embedding(total_ports, 3, input_length=6))\n",
        "\n",
        "# adding an LSTM layer to process the embedded vector sequences\n",
        "model.add(LSTM(100, activation='relu', return_sequences=False))\n",
        "\n",
        "# adding a crucial layer to allows the output sequence to be of a diff length\n",
        "model.add(RepeatVector(3))\n",
        "\n",
        "# another LSTM layer, this one repeating the sequence\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
        "\n",
        "# model.add(Dense(50, activation='relu'))                                  <-------- layer i added/subtracted\n",
        "\n",
        "# adding a TimeDistributed Dense layer to output predictions. note the # of \n",
        "# categories is not 'efficient' but it does make decoding the prediction take one\n",
        "# fewer step\n",
        "\n",
        "model.add(TimeDistributed(Dense(179, activation='softmax')))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1781: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoIgnQNPV0V4"
      },
      "source": [
        "# fitting the model with early stopping\n",
        "\n",
        "history = model.fit(X_train,y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=32,\n",
        "                    epochs=250,\n",
        "                    callbacks=EarlyStopping(monitor='val_accuracy',\n",
        "                                            patience=30,\n",
        "                                            restore_best_weights=True));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDOT2rQdKS-L"
      },
      "source": [
        "break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1D1OdzHisXW"
      },
      "source": [
        "lstm_window = {key:get_pred_data(processed_dfs[key], n_input=6) for key in processed_dfs.keys()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBLlbXF6lqyi"
      },
      "source": [
        "# getting the sequences and encoding them so the model can use them as inputs\n",
        "seq_for_pred = np.array([[encoder[j] for j in n] for n in lstm_window.values()])\n",
        "\n",
        "# padding the sequences with fewer than 6 \n",
        "seq_for_pred = pad_sequences(seq_for_pred, maxlen=6, value=0)\n",
        "\n",
        "# predicting the next 3 ports visited\n",
        "preds = model.predict(seq_for_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBQApzdGwu1q"
      },
      "source": [
        "# assigning the predictions and back-up predictions to variables. if a port\n",
        "# repeats, i replace it with the second most likely\n",
        "first_port = pd.Series([np.argmax(n[0]) for n in preds])\n",
        "second_port = pd.Series([np.argmax(n[1]) for n in preds])\n",
        "alt_second = pd.Series([np.argsort(n[1])[-2] for n in preds])\n",
        "third_port = pd.Series([np.argmax(n[2]) for n in preds])\n",
        "alt_third = pd.Series([np.argsort(n[2])[-2] for n in preds])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOqRO78LoVr6"
      },
      "source": [
        "# creating a dataframe of the above\n",
        "last_port = pd.Series(seq_for_pred[:,-1])\n",
        "lstm_pred = pd.concat([last_port, first_port, second_port, alt_second, third_port, alt_third], axis=1)\n",
        "lstm_pred.index = window_data.keys()\n",
        "lstm_pred = lstm_pred.reset_index()\n",
        "lstm_pred.columns = ['vessel', 'last_port', 'pred1', 'pred2', 'alt2', 'pred3', 'alt3']\n",
        "lstm_pred['pred2'] = np.where(lstm_pred['pred1'] == lstm_pred['pred2'], lstm_pred['alt2'], lstm_pred['pred2'])\n",
        "lstm_pred['pred3'] = np.where(lstm_pred['pred2'] == lstm_pred['pred3'], lstm_pred['alt3'], lstm_pred['pred3'])\n",
        "lstm_pred.drop(columns=['alt2', 'alt3'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPZZ6EX_ANdP"
      },
      "source": [
        "reverse_encoder = {v:k for k, v in encoder.items()}\n",
        "lstm_pred['last_port'] = lstm_pred['last_port'].map(reverse_encoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGyKkzQgrbAT"
      },
      "source": [
        "lstm_pred = pd.melt(lstm_pred, id_vars='vessel').sort_values(by=['vessel', 'variable'])\n",
        "\n",
        "lstm_pred['end_port_id'] = lstm_pred.groupby('vessel')['value'].transform(lambda x: x.shift(-1))\n",
        "lstm_pred.dropna(inplace=True)\n",
        "lstm_pred.drop(columns='variable', inplace=True)\n",
        "lstm_pred.rename(columns={'value':'begin_port_id'}, inplace=True)\n",
        "lstm_pred['voyage'] = lstm_pred.groupby('vessel').cumcount()+1\n",
        "lstm_pred = lstm_pred.astype(int).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksfEgenhtQJs"
      },
      "source": [
        "# i think i'm messing up, but the XGB model is fine - review this\n",
        "lstm_pred.head(25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lipU-tqdU_Va"
      },
      "source": [
        "sub.to_csv('predict.csv', index=False)\n",
        "# lstm_pred.to_csv('lstm_predict.csv', index=False)\n",
        "voyages_df.to_csv('voyages.csv', index=False)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd_OvZ0lenDm"
      },
      "source": [
        "def show_routes(vessel=1, start='2019-01-01', end='2019-12-28'): \n",
        "  \n",
        "  df_ = df2.query(f'vessel == {vessel}').set_index('datetime')\n",
        "\n",
        "  fig = px.scatter_geo(df_.loc[start: end], lat='lat', lon='long', color='draft',\n",
        "                       hover_name=df_.loc[start: end].index)\n",
        "\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCU2YOfOdJda"
      },
      "source": [
        "def draft_and_voyages(vessel=103):\n",
        "\n",
        "  df = alldf.query(f'vessel == {vessel}')\n",
        "  \n",
        "  in_port = df[df['pred_port'] > 0].index\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(20,5))\n",
        "  \n",
        "  df[['port_dist', 'draft']].plot(ax=ax)\n",
        "  \n",
        "  for p in in_port:\n",
        "    plt.axvline(p, ls='--', lw=0.5, c='r', label='port')\n",
        "  \n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QScIRJFV7CuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "949a1508-c1f2-4693-c309-6b201b19dc20"
      },
      "source": [
        "alldf = pd.concat(processed_dfs)\n",
        "\n",
        "alldf.query('pred_port >0 & heading_sequence_time <7').shape"
      ],
      "execution_count": 605,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39889, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 605
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUUt_u9OKhbU"
      },
      "source": [
        "testdf = processed_dfs[67]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMULBQ0nv13N"
      },
      "source": [
        "testdf[['draft', 'pred_port']].plot(figsize=(24,8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLZqUK8KLdMu"
      },
      "source": [
        "print(testdf[['draft', 'pred_port', 'pred_port_backup', 'pred_port_dist', 'port_sequence_time', 'consec_port_sequence', 'hour_delta', 'direction', 'heading_seq', 'lat_long', 'dist_last_port']].to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwv5Kno16m8Z"
      },
      "source": [
        "fig = px.scatter_geo(df2.query('vessel == 152'), lat='lat', lon='long', color='direction', hover_name='pred_port')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}