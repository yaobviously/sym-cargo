{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yaobviously/sym-cargo/blob/main/sym_cargo_alt_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRudeILZCNAh",
    "outputId": "6271a896-b401-40d8-904d-b94372eee8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for vincenty (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |████████████████████████████████| 67.4 MB 27 kB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install plotly-express --quiet\n",
    "!pip install vincenty --quiet\n",
    "!pip install --upgrade catboost --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bPzNedJbteyr"
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrMMphhGyTIp"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KFygxcBXBsUT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, RepeatVector, LSTM, Dense, TimeDistributed\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from xgboost import XGBClassifier\n",
    "from vincenty import vincenty\n",
    "import plotly_express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERdgnPI_B8xV"
   },
   "outputs": [],
   "source": [
    "port_file = '/content/drive/MyDrive/Ports/ports.csv'\n",
    "tracking_file = '/content/drive/MyDrive/Ports/tracking.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGQ3oW9dCGF6"
   },
   "outputs": [],
   "source": [
    "def wrangle():\n",
    "  \n",
    "  df1 = pd.read_csv(port_file)\n",
    "\n",
    "  # converting lat and long to radians to compute haversine distance\n",
    "  df1['lat_rad'] = np.radians(df1['lat'])\n",
    "  df1['long_rad'] = np.radians(df1['long'])\n",
    "  \n",
    "  # rounding lat and long in port df\n",
    "  df1['lat'] = df1['lat']\n",
    "  df1['long'] = df1['long']\n",
    "  df1['lat_long'] = [[x,y] for x, y in zip(df1['lat'], df1['long'])]\n",
    "\n",
    "  df2 = pd.read_csv(tracking_file, parse_dates=['datetime'])\n",
    "  df2 = df2.drop_duplicates()\n",
    "  df2 = df2.sort_values(['vessel', 'datetime'])\n",
    "  df2['vessel_1back'] = df2['vessel'].shift()\n",
    "  \n",
    "  # converting lat and long to radians to compute haversine distance  \n",
    "  df2['lat_rad'] = np.radians(df2['lat'])\n",
    "  df2['long_rad'] = np.radians(df2['long'])\n",
    "\n",
    "  # adding lat/long column and lat/long 1 back to later compute delta\n",
    "  df2['lat_long'] = [[x,y] for x, y in zip(df2['lat'], df2['long'])]\n",
    "  df2['lat_long_1back'] = df2.groupby('vessel')['lat_long'].transform(lambda x: x.shift())\n",
    "  df2['direction'] = pd.cut(df2['heading'],\n",
    "                            bins=[0, 22.5, 67.5, 112.5, 157.5, 202.5, 247.5,\n",
    "                                  292.5, 337.5, 360],\n",
    "                            labels=['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW', 'N'],\n",
    "                            ordered=False,\n",
    "                            include_lowest=True)\n",
    "  \n",
    "  # time delta and hour delta that will be used for filtering - i do it again\n",
    "  # after the filter\n",
    "\n",
    "  df2['time_delta'] = df2.groupby('vessel')['datetime'].transform(lambda x: x - x.shift())\n",
    "  df2['hour_delta'] = [n.total_seconds()/3600 for n in df2['time_delta']]\n",
    "\n",
    "  # i divide the map into quadrants to calculate the proportion of the time each\n",
    "  # vessel was in each quadrant\n",
    "\n",
    "  conditions = [((df2['lat'] > 0) & (df2['long'] > 0)),\n",
    "                ((df2['lat'] < 0) & (df2['long'] > 0)), \n",
    "                ((df2['lat'] > 0) & (df2['long'] < 0)), \n",
    "                ((df2['lat'] < 0) & (df2['long'] < 0))\n",
    "  ]\n",
    "\n",
    "  labels = ['quad1', 'quad4', 'quad2', 'quad3']\n",
    "\n",
    "  df2['quad'] = np.select(conditions, labels)\n",
    "  \n",
    "\n",
    "  # filtering using query to eliminate unneeded/impossible values\n",
    "  df2 = df2.query('speed <30 & heading <=360 & draft < 13.5')\n",
    "  df2 = df2.reset_index(drop=True)\n",
    "\n",
    "  return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZJrWQ6eCIqV"
   },
   "outputs": [],
   "source": [
    "df1, df2 = wrangle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tL74j_2a7LR"
   },
   "outputs": [],
   "source": [
    "def vincent_distance(row):\n",
    "  \"\"\" \n",
    "  returns the vincenty distance for contiguous rows - will be used to identify\n",
    "  impossible distances travelled\n",
    "  \"\"\"\n",
    "  if row['vessel'] != row['vessel_1back']:\n",
    "    return -99\n",
    "\n",
    "  loc1 = row['lat_long']\n",
    "  loc2 = row['lat_long_1back']\n",
    "\n",
    "  try:\n",
    "    distance = vincenty(loc1, loc2)\n",
    "    return distance\n",
    "  except:\n",
    "    return -99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1P_JxyybKHc"
   },
   "outputs": [],
   "source": [
    "# creating a dictionary of ports with their lat and longs \n",
    "\n",
    "ports = {port:(lat, long) for port, lat, long in zip(df1['port'], df1['lat'], df1['long'])}\n",
    "\n",
    "# a dictionary to retrieve the port id from the index\n",
    "idx_ports = {idx:port for idx, port in zip(df1.index, df1.port)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvA-nfJqtqAQ"
   },
   "outputs": [],
   "source": [
    "# getting the vincenty distances for each pair of ports in the ports.csv file\n",
    "# extracting those that are within 100km of each other\n",
    "\n",
    "close_ones = []\n",
    "\n",
    "for x in df1['lat_long']:\n",
    "  distances = []\n",
    "  for y in df1['lat_long']:\n",
    "    vdist = vincenty(x, y)\n",
    "    distances.append(vdist)\n",
    "  close_ones.append(distances)\n",
    "\n",
    "disters = [[(df1['port'].iloc[n], z) for n, z in zip(np.argsort(p)[:5], sorted(p)[:5])] for p in close_ones]\n",
    "\n",
    "close_ones = {}\n",
    "\n",
    "for n in disters:\n",
    "  port = n[0][0]\n",
    "  dees = {d:v for d, v in n[1:] if v < 100}\n",
    "  close_ones[port] = dees\n",
    "\n",
    "close_ones = {k:v for k,v in close_ones.items() if len(v) >= 1}\n",
    "\n",
    "really_close = [30, 109, 42, 51, 65, 71, 108, 139, 63, 152, 102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Rg5F1xcTElh",
    "outputId": "4b4cd1ee-f0be-4e1a-b8e3-bbdc3cb00aaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.30931026  46.44757565 255.13837716]\n",
      "[82, 113, 44]\n"
     ]
    }
   ],
   "source": [
    "# training a nearest neighbor model to  find the closest port when the \n",
    "# conditions indicating an extended stop have occurred. the metric is haversine\n",
    "# in order to compute the 'great circle' distance. so i don't forget, the model\n",
    "# returns the *index* of the port, not the port's identifying label\n",
    "\n",
    "ports_train = df1[['lat_rad', 'long_rad']]\n",
    "\n",
    "neigh_ports = NearestNeighbors(n_neighbors=3, algorithm='ball_tree', metric='haversine')\n",
    "neigh_ports.fit(ports_train)\n",
    "\n",
    "dist, n = neigh_ports.kneighbors(np.array([0.677565, 0.469731]).reshape(1,-1))\n",
    "\n",
    "print(dist[0] * 6370)\n",
    "print([idx_ports[n] for n in n[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YC92dd_FI7MT"
   },
   "outputs": [],
   "source": [
    "def nearest_port(df, radius=0.015):\n",
    "  \"\"\"\n",
    "  returns the port identifier of the nearest port using the nearest neighbors\n",
    "  model \n",
    "  \"\"\"\n",
    "\n",
    "  data = np.array([df['lat_rad'], df['long_rad']]).reshape(1, -1)\n",
    "  dist, pred = neigh_ports.radius_neighbors(data, radius=radius, sort_results = True) \n",
    "\n",
    "  if len(dist[0]) == 0:\n",
    "    return -1\n",
    "  \n",
    "  else:\n",
    "    return idx_ports[pred[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2cHgfSNZbx2"
   },
   "outputs": [],
   "source": [
    "def nearest_distance(df, radius=0.015):\n",
    "  \"\"\"\n",
    "  returns the distance of the nearest port in the dataset\n",
    "  \"\"\"\n",
    "  \n",
    "  data = np.array([df['lat_rad'], df['long_rad']]).reshape(1, -1)\n",
    "  dist, pred = neigh_ports.radius_neighbors(data, radius=radius, sort_results = True) \n",
    "\n",
    "  if len(dist[0]) == 0:\n",
    "    return -1\n",
    "  \n",
    "  else:\n",
    "    return dist[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KoYZuM6lqJIa"
   },
   "outputs": [],
   "source": [
    "def vincenty_port(row):\n",
    "  \"\"\"\n",
    "  a function that computes the vincenty distance between the assigned port\n",
    "  and the latitude and longitude of the location data\n",
    "  \"\"\"\n",
    "  port = row['port_coords']\n",
    "  loc = row['lat_long']\n",
    "  return vincenty(port, loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLCHF2I5CII2"
   },
   "outputs": [],
   "source": [
    "def train_dbscan(df=df1, eps=0.1, min_samples=4):\n",
    "  \"\"\"\n",
    "  use the dbscan clustering algorithm to find groupss of ports\n",
    "\n",
    "  params\n",
    "  ------\n",
    "      df: pandas df\n",
    "      eps: min distance between points in cluster\n",
    "      min_samples: min members in a cluster\n",
    "\n",
    "  returns\n",
    "  -------\n",
    "      labels: labels matching index of long/lat input pairs\n",
    "  \"\"\"\n",
    "  \n",
    "  coords = df[['long_rad', 'lat_rad']].values\n",
    "  db = DBSCAN(eps=eps, min_samples=min_samples, algorithm='ball_tree', metric='haversine')\n",
    "\n",
    "  db.fit(coords)\n",
    "\n",
    "  return db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PkBxR8F_UykW"
   },
   "outputs": [],
   "source": [
    "def fix_ports(testdf):\n",
    "  \"\"\"\n",
    "  fills out port sequences if there's a draft change in the sequence. this will\n",
    "  help get better arrival and departure dates. it should be applied to \n",
    "  groupby DataFrames \n",
    "\n",
    "  parameters\n",
    "  ----------\n",
    "      df: a pandas DataFrame\n",
    "\n",
    "  returns\n",
    "  -------\n",
    "      df: a pandas Series\n",
    "  \"\"\"\n",
    "  \n",
    "  ugh = []\n",
    "\n",
    "  for x in testdf['port_sequence'].unique():\n",
    "    df_ = testdf.query(f'port_sequence == {x}')\n",
    "    ports = df_['pred_port']\n",
    "    new_ports = []\n",
    "    if not all(ports <= 0):\n",
    "      new_ports.append([ports.max()] * len(ports))\n",
    "    else:\n",
    "      new_ports.append(ports)\n",
    "  \n",
    "    ugh.append(new_ports[0])\n",
    "  \n",
    "  \n",
    "  thisthis = []\n",
    "\n",
    "  for n in ugh:\n",
    "    for p in n:\n",
    "      thisthis.append(p)\n",
    "\n",
    "  return thisthis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sU_Co92uMDoL"
   },
   "outputs": [],
   "source": [
    "# creating a dictionary of labels from the dbscan model\n",
    "\n",
    "df1['labels'] = train_dbscan()\n",
    "db_labels = {port:cluster for port, cluster in zip(df1['port'], df1['labels'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDnoQ4hnfhce"
   },
   "outputs": [],
   "source": [
    "def get_voyages(df):\n",
    "  \"\"\"\n",
    "  converts the port sequences in each dataframe into voyages\n",
    "  with the proper formatting\n",
    "\n",
    "  param:\n",
    "  -----\n",
    "      df: pandas DataFrame\n",
    "  \n",
    "  returns:\n",
    "  -------\n",
    "      df: processed pandas DataFrame\n",
    "      \n",
    "  \"\"\"\n",
    "  # filtering out rows without an assigned port\n",
    "  nz = df[(df['pred_port'] > 0) | (df['pred_port'] == -75)].reset_index()\n",
    "\n",
    "  vessel = nz['vessel'][0]\n",
    "  dt = nz['datetime']\n",
    "  pred = nz['pred_port']\n",
    "\n",
    "  records = []\n",
    "\n",
    "  for i in range(len(dt)-1):\n",
    "    if pred[i] != pred[i+1]:\n",
    "      start_port = pred[i]\n",
    "      end_port = pred[i+1]\n",
    "      begin_date = dt[i]\n",
    "      end_date = dt[i+1]\n",
    "      records.append([vessel, begin_date, end_date, start_port, end_port])\n",
    "\n",
    "  df = pd.DataFrame.from_records(records, columns = ['vessel', 'begin_date', 'end_date', 'begin_port_id', 'end_port_id'])  \n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Gr1MtPzAGrP"
   },
   "outputs": [],
   "source": [
    "def fix_really_close_cluster(row):\n",
    "  \"\"\"\n",
    "  Applies filters to ports: come back to this.\n",
    "\n",
    "  \"\"\"\n",
    "  \n",
    "  duration = row['port_sequence_time']\n",
    "  dist = row['pred_port_dist']\n",
    "\n",
    "  if row['pred_port_backup'] in ([72, 152]):\n",
    "    if ((duration > 48) & (dist < 50) & (row['heading_sequence_time'] > 8)):\n",
    "      return row['pred_port_backup']\n",
    "    elif dist < 5:\n",
    "      return row['pred_port_backup']\n",
    "    elif duration > 100:\n",
    "      return row['pred_port_backup']\n",
    "    else:\n",
    "      return row['pred_port']\n",
    "\n",
    "  elif row['pred_port_backup'] == 99:\n",
    "    if ((dist >20) & (row['draft_change'] < 1)):\n",
    "      return 0\n",
    "    else:\n",
    "      return row['pred_port']\n",
    "\n",
    "  elif row['pred_port_backup'] in ([115, 54]):\n",
    "    if ((dist < 15) & (row['heading_sequence_time'] > 12)):\n",
    "      return row['pred_port_backup']\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "  elif dist < 2:\n",
    "    if ((duration > 16) & (dist <2)):\n",
    "      return row['pred_port_backup']\n",
    "    else:\n",
    "      return row['pred_port']\n",
    "\n",
    "  elif row['pred_port'] == 21:\n",
    "    if dist > 25:\n",
    "      return 0\n",
    "    else:\n",
    "      return row['pred_port']\n",
    "\n",
    "  elif row['heading_sequence_time'] > 30:\n",
    "    if dist <= 10:\n",
    "      return row['pred_port_backup']\n",
    "    else:\n",
    "      return row['pred_port']\n",
    "  \n",
    "  elif row['heading_sequence_time'] > 6:\n",
    "    if ((duration >25) & (dist <=15)):\n",
    "      return row['pred_port_backup']\n",
    "    else:\n",
    "      return row['pred_port']\n",
    "\n",
    "  else:\n",
    "    return row['pred_port']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7x2drUA6JrXt"
   },
   "outputs": [],
   "source": [
    "def fix_close_ports(testdf):\n",
    "  \"\"\"\n",
    "  compares adjacent port assignments minimum distances and returns a new series\n",
    "  with ports reassigned where appropriate\n",
    "\n",
    "  parameters\n",
    "  ----------\n",
    "      df: a pandas DataFrame\n",
    "\n",
    "  returns\n",
    "  -------\n",
    "      df: a pandas Series\n",
    "  \"\"\" \n",
    "\n",
    "  new_destinations = []\n",
    "\n",
    "  for seq in range(1, len(testdf['port_sequence'].unique()) +1):\n",
    "    seq1_port = testdf[testdf['port_sequence'] == seq].pred_port\n",
    "    seq2_port = testdf[testdf['port_sequence'] == seq + 1].pred_port\n",
    "    seq1_mindist = testdf[testdf['port_sequence'] == seq].pred_port_dist\n",
    "    seq2_mindist = testdf[testdf['port_sequence'] == seq+1].pred_port_dist\n",
    "    new_ports = []\n",
    "\n",
    "    if (seq1_port.max() <= 0) or (seq2_port.max() <= 0):\n",
    "      new_ports.append([seq1_port.max()] * len(seq1_port))\n",
    "    \n",
    "    elif seq2_mindist.min() < seq1_mindist.min():\n",
    "      true_port = seq2_port\n",
    "      new_ports.append([true_port.max()] * len(seq1_port))\n",
    "    else:\n",
    "      new_ports.append([seq1_port.max()] * len(seq1_port))\n",
    "    \n",
    "    new_destinations.append(new_ports[0])\n",
    "  \n",
    "  new_dest = []\n",
    "\n",
    "  for dest in new_destinations:\n",
    "    for d in dest:\n",
    "      new_dest.append(d)\n",
    "\n",
    "  return new_dest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Jydaj-qScpp"
   },
   "outputs": [],
   "source": [
    "def get_prior_port(df):\n",
    "  \"\"\"\n",
    "  iterate through each vessel's predicted ports to get the last predicted\n",
    "  port\n",
    "  \"\"\"\n",
    "\n",
    "  p = df['pred_port'][::-1].values\n",
    "\n",
    "  prior_ports = []\n",
    "\n",
    "  for i in range(len(p)):\n",
    "    s = p[i]\n",
    "    for n in p[i:]:\n",
    "      if (s != n) & (n >0) :\n",
    "       prior_ports.append(n)\n",
    "       break\n",
    "\n",
    "# padding zeros at the end to indicate no next port \n",
    "  zeroes = [0] * (len(p) - len(prior_ports))\n",
    "  prior_ports = prior_ports + zeroes\n",
    "  \n",
    "  prior_ports = prior_ports[::-1]\n",
    "  \n",
    "  return prior_ports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4gOeftL1KN0"
   },
   "outputs": [],
   "source": [
    "def get_angle(loc1=[1.2, 103], loc2=[99.5,-32]):\n",
    "  \"\"\"\n",
    "  get the angle of the bearing needed to directly approach one location from\n",
    "  another\n",
    "\n",
    "  parameters\n",
    "  ----------\n",
    "        lists: lat, longitude of ship (in dict as such)\n",
    "\n",
    "  returns\n",
    "  -------\n",
    "        float: bearing in degrees with 0 as due North\n",
    "  \"\"\"\n",
    "  \n",
    "  dLon = (loc2[1] - loc1[1])\n",
    "\n",
    "  y = math.sin(dLon) * math.cos(loc2[0])\n",
    "  x = math.cos(loc1[0]) * math.sin(loc2[0]) - math.sin(loc1[0]) * math.cos(loc2[0]) * math.cos(dLon)\n",
    "\n",
    "  brng = math.atan2(y, x)\n",
    "\n",
    "  brng = math.degrees(brng)\n",
    "  brng = (brng + 360) % 360\n",
    "  brng = 360 - brng # count degrees clockwise - remove to make counter-clockwise\n",
    "\n",
    "  return brng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbHcYBVQcWst"
   },
   "outputs": [],
   "source": [
    "# calculating the distance between each row using the vincenty function above.\n",
    "# note it only calcs within each vessel group (see function). the elapsed time\n",
    "# and the total distance travelled implies a speed and that speed creates a \n",
    "# simple filter \n",
    "\n",
    "df2['vin_diff'] = df2.apply(vincent_distance, axis=1)\n",
    "df2['vin_per_hour'] = df2['vin_diff'] / df2['hour_delta']\n",
    "df2 = df2.query('vin_per_hour <= 50')\n",
    "df2 = df2.sort_values(by=['vessel', 'datetime'])\n",
    "\n",
    "# time deltas to be used later to filter voyages and a new lat/long calc \n",
    "\n",
    "df2['time_delta'] = df2.groupby('vessel')['datetime'].transform(lambda x: x - x.shift(-1))\n",
    "df2['hour_delta'] = [abs(n.total_seconds()/3600) for n in df2['time_delta']]\n",
    "df2['lat_long_1back'] = df2.groupby('vessel')['lat_long'].transform(lambda x: x.shift())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0M6rssmoH4G"
   },
   "outputs": [],
   "source": [
    "# calculating draft forwards and backwards \n",
    "\n",
    "df2['draft_raw'] = df2.groupby('vessel')['draft'].transform(lambda x: x.diff())\n",
    "df2['draft_delta_back'] = df2.groupby('vessel')['draft'].transform(lambda x: abs(x.diff()).ge(0.69)).astype(int)\n",
    "df2['draft_delta_ahead'] = df2.groupby('vessel')['draft'].transform(lambda x: abs(x.diff(-1)).ge(0.69)).astype(int)\n",
    "df2['draft_change'] = ((df2['draft_delta_back'] + df2['draft_delta_ahead']) >= 1).astype(int)\n",
    "\n",
    "# calculating heading change and \n",
    "df2['heading_change'] = df2.groupby('vessel')['heading'].transform(lambda x: abs(x.diff()))\n",
    "df2['heading_change'] = [360 - x if x > 180 else x for x in df2['heading_change']]\n",
    "df2['heading_seq'] = df2.groupby('vessel')['heading'].transform(lambda x: abs(x.diff()).gt(3).cumsum()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJFUdD56oZ-_"
   },
   "outputs": [],
   "source": [
    "# assigning ports using the nearest neighbor model\n",
    "\n",
    "df2['pred_port'] = df2.apply(nearest_port, axis=1)\n",
    "df2['pred_port_backup'] = df2['pred_port']\n",
    "\n",
    "# defining sequences of rows with with the same port predicted\n",
    "df2['port_sequence'] = df2.groupby('vessel')['pred_port'].transform(lambda x: x.diff().ne(0).cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fsLG0KDn0os"
   },
   "outputs": [],
   "source": [
    "# defining sequences of rows with a port predicted - finds movement from\n",
    "# one port to another and so identifies sequences w/ambiguous intended port\n",
    "\n",
    "df2['consec_port_sequence'] = df2.groupby('vessel')['pred_port_backup'].transform(lambda x: x.gt(0).astype(int).diff().ne(0).cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wmbGxlEpA_k"
   },
   "outputs": [],
   "source": [
    "# calculating the distance from the predicted port using the more precise \n",
    "# vincenty distance. again, a mask is applied to speed it up.\n",
    "\n",
    "df2['port_coords'] = [list(ports[k]) if k in ports else -99 for k in df2['pred_port']]\n",
    "\n",
    "vin_mask = df2['pred_port'] > 0\n",
    "temp_vin = df2[vin_mask]\n",
    "\n",
    "df2['pred_port_dist'] = 0\n",
    "df2.loc[vin_mask, 'pred_port_dist'] = temp_vin.apply(vincenty_port, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0VvF85yBNHo"
   },
   "outputs": [],
   "source": [
    "df2['port_sequence_min_dist'] = df2.groupby(['vessel', 'port_sequence'])['pred_port_dist'].transform(lambda x: x.min())\n",
    "df2['port_sequence_time'] = df2.groupby(['vessel', 'port_sequence'])['hour_delta'].transform(lambda x: abs(x).sum())\n",
    "df2['heading_sequence_time'] = df2.groupby(['vessel', 'heading_seq'])['hour_delta'].transform(lambda x: abs(x).sum())\n",
    "df2['consec_port_min_dist'] = df2.groupby(['vessel', 'consec_port_sequence'])['pred_port_dist'].transform(lambda x: round(x.min(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJQlMP_Kpm-8"
   },
   "outputs": [],
   "source": [
    "# getting the last port with a function and then flattening the lists it\n",
    "# returned for each vessel and appending them to the dataframe\n",
    "\n",
    "last_ports = df2.groupby(\"vessel\").apply(get_prior_port)\n",
    "last_ports_col = []\n",
    "\n",
    "for lps in last_ports:\n",
    "  for lp in lps:\n",
    "    last_ports_col.append(lp)\n",
    "\n",
    "df2['prior_port'] = last_ports_col\n",
    "df2['dist_last_port'] = [vincenty(l, ports[p]) if p>0 else 0 for l, p in zip(df2['lat_long'], df2['prior_port'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QKDBR5yFIfI"
   },
   "outputs": [],
   "source": [
    "df2['rolling_unique_vals'] = df2.groupby('vessel')['pred_port_backup'].apply(lambda x: x.rolling(8, center=True).apply(lambda x: x[x>0].nunique()))\n",
    "df2['window_min_dist'] = df2.groupby('vessel')['pred_port_dist'].apply(lambda x: x.rolling(8, center=True).apply(lambda x: x[x>0].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6WV_uIjuq_35"
   },
   "outputs": [],
   "source": [
    "# processing the dataframes with conditions. it is setup this way to allow for\n",
    "# fast iteration\n",
    "\n",
    "processed_dfs = {}\n",
    "\n",
    "for df in df2.vessel.unique():\n",
    "  df_ = df2.query(f'vessel == {df}').set_index('datetime')\n",
    "  df_['pred_port'] = np.where(df_['draft_change'] < 1, 0, df_['pred_port'])\n",
    "  \n",
    "  condition = ((df_['pred_port'].isin(really_close)) & (df_['pred_port_dist'] >13))\n",
    "  df_['pred_port'] = np.where(condition, 0, df_['pred_port'])\n",
    "\n",
    "  # df_['pred_port'] = df_.apply(fix_really_close_cluster, axis=1)\n",
    "\n",
    "  df_['pred_port'] = np.where(df_['port_sequence_time'] < 16, 0, df_['pred_port'])\n",
    "\n",
    "  df_['fixed_ports'] = fix_close_ports(df_)\n",
    "  df_['pred_port'] = [x if x == y else 0 for x, y in zip(df_['pred_port_backup'], df_['fixed_ports'])]\n",
    "\n",
    "  condition2 = (df_['pred_port'].isin([115, 54]) & (df_['pred_port_dist'] >16))\n",
    "  df_['pred_port'] = np.where(condition2, 0, df_['pred_port'])\n",
    "\n",
    "  df_['pred_port'] = df_.apply(fix_really_close_cluster, axis=1)\n",
    "\n",
    "  last_ports = df_.groupby('vessel').apply(get_prior_port)\n",
    "  last_ports_col = []\n",
    "\n",
    "  for lps in last_ports:\n",
    "    for lp in lps:\n",
    "      last_ports_col.append(lp)\n",
    "\n",
    "  condition = ((df_['heading_sequence_time'] < 6) & (df_['pred_port'] >0) & (df_['draft_change'] <1))\n",
    "  df_['pred_port'] = np.where(condition, 0, df_['pred_port'])\n",
    "\n",
    "  condition2 = ((df_['pred_port_dist'] - df_['consec_port_min_dist']) > 10)\n",
    "  df_['pred_port'] = np.where(condition2, 0, df_['pred_port'])\n",
    "\n",
    "  condition3 = (df_['pred_port_dist'] > 80)\n",
    "  df_['pred_port'] = np.where(condition3, 0, df_['pred_port'])\n",
    "\n",
    "  df_['prior_port'] = last_ports_col\n",
    "  df_['dist_last_port'] = [vincenty(l, ports[p]) if p>0 else 0 for l, p in zip(df_['lat_long'], df_['prior_port'])]\n",
    "  \n",
    "  processed_dfs[df] = df_\n",
    "\n",
    "alldf = pd.concat(processed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7SIs4v7TvD-a",
    "outputId": "b339cb84-6101-402c-ff72-f4a8ddc2e94f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3331, 9)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voyages_df = pd.concat([get_voyages(processed_dfs[key]) for key in processed_dfs.keys()])\n",
    "voyages_df['begin_date'] = voyages_df['begin_date'].dt.date\n",
    "voyages_df['end_date'] = voyages_df['end_date'].dt.date\n",
    "voyages_df['len_voyage'] = voyages_df['end_date'] - voyages_df['begin_date']\n",
    "voyages_df['begin_coords'] = [ports[key] for key in voyages_df['begin_port_id']]\n",
    "voyages_df['end_coords'] = [ports[key] for key in voyages_df['end_port_id']]\n",
    "voyages_df['voyage_dist'] = [vincenty(x, y) for x, y in zip(voyages_df['begin_coords'], voyages_df['end_coords'])]\n",
    "voyages_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "qZR-g7o0KH6H",
    "outputId": "1ee1fe31-8a06-43d7-fc0b-ea9e47915b09"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXRV5b3/8fc3AwkQkjCEKQkkQQYZKiIiyCBqa52qdNbaahXB3tJqa28He+9dt/21vdf22tp6bb0yqFjnOlXR1loVJChoQGUQh5AwJCCEKRAgEML398fZwYBAEjLsnHM+r7XOyt7P3vucb1iLz3nynH2ex9wdERGJLQlhFyAiIi1P4S4iEoMU7iIiMUjhLiISgxTuIiIxSOEuIhKDFO4SE8zsm2ZWWG/fzeyUMGuqY2aTzaws7DokvijcJWqY2Voz22dmVfUed4ZdFxx+c6kNatplZm+b2aUn8Tz3mdkvW6NGiS9JYRcg0kSfc/d/hl3Ecbzu7hPMLAGYATxmZtlhFyXxST13iWUXm1mJmW01s/8JQhczSzCzfzezdWa2xczuN7OM4NhcM/tBsJ0dDO/MCPYHmNn2uuc5Hnc/BNwDdAQGHH3czE41s/lmttPMVpnZZUH7dOAq4EfBXwDPtuC/hcQZhbvEss8Do4FRwOXAdUH7N4PHuUABkAbUDe8sACYH2+cAJcCkevsLg/A+LjNLAq4HqoAPjzqWDDwL/APoCXwXeNDMBrv7TOBB4Dfunubun2vqLyxSR+Eu0ebpoMdb95h2gnN/7e7b3X098HvgyqD9KuB37l7i7lXALcAVQSgvAOqGViYBvwHGB9edExw/nrFmthP4KHitz7t75dHnEHkzudXdD7j7y8C8erWJtAiNuUu0mdKEMfcN9bbXAX2D7b7Bfv1jSUAvd19jZnuAkcBE4BfAVDMbTCTc7zjB6y129wkN1NQX2HBU738doLF5aVHquUssy6233Q/YGGxvBPofdewgsDnYXwB8Cejg7uXB/jVAV+DtZta0Ecg9aty+H1AebGuaVmkRCneJZT80s65mlgvcBDwatD8MfN/M8s0sDfgv4FF3PxgcXwB8B3g12J8f7Be6e20za1oC7CXyoWmymU0GPgc8EhzfTORzAJFmUbhLtHn2qPvcnzrBuX8FlhLpbT8HzAna7wH+TCS8S4FqIh9s1lkAdOHjcC8EOtXbP2nufoBImF8EbAX+BFzt7u8Fp8wBhgafJzzd3NeT+GVarENEJPao5y4iEoMU7iIiMUjhLiISgxTuIiIxqF18ialHjx6el5cXdhkiIlFl6dKlW90961jH2kW45+XlUVRUFHYZIiJRxczWHe+YhmVERGKQwl1EJAYp3EVEYpDCXUQkBincRURikMJdRCQGKdxFRGJQVId7SUUVP392FTW1J1zSUkQk7jQq3M1srZmtMLO3zawoaOtmZi+a2YfBz65Bu5nZHWZWbGbLzWxUaxW/dtse7l20lnnLNzZ8sohIHGlKz/1cdx/p7qOD/Z8AL7n7QOClYB8iixAMDB7TgbtaqtijTR7Uk0G90rh7QQmal15E5GPNGZa5HJgbbM8FptRrv98jFgOZZtanGa9zXAkJxrSJBbz30W5e/XBra7yEiEhUamy4O/APM1tqZtODtl7uvinY/gjoFWxnc+Sq82W04srul4/Mpld6CjNfXdNaLyEiEnUaG+4T3H0UkSGXGWY2qf5Bj4yJNGlcxMymm1mRmRVVVFQ05dIjdEhK4Lrx+Swq3sbK8sqTfh4RkVjSqHB39/Lg5xbgKWAMsLluuCX4uSU4vRzIrXd5TtB29HPOdPfR7j46K+uYM1Y22pVn9SMtJYm7Xy1p1vOIiMSKBsPdzDqbWZe6beACYCXwDHBNcNo1RFaaJ2i/OrhrZixQWW/4plWkpybztbP68fyKTWzYvrc1X0pEJCo0pufeCyg0s3eAN4Dn3P3vwK3AZ8zsQ+DTwT7A80AJUAzMAr7d4lUfw7Xj80gwmFNY2hYvJyLSrjW4WIe7lwCnHaN9G3D+MdodmNEi1TVBn4yOXHZaNo++uYGbzh9I184d2roEEZF2I6q/oXq06ZMK2FdTywOLj7s4iYhIXIipcB/cuwuTB2cx9/W1VNfUhl2OiEhoYircAW6YNICtVQd4YllZ2KWIiIQm5sJ9bEE3PpWTweyFpdQe0pQEIhKfYi7czYzpkwoo3bqHF9/dHHY5IiKhiLlwB7hwWG/6devE3a+u0YRiIhKXYjLckxITuH5iPm+t30nRuh1hlyMi0uZiMtwBvnxGLl07JXP3Ak1JICLxJ2bDvWOHRK4el8c/V2+meMvusMsREWlTMRvuAFeP609KUgKzXtWUBCISX2I63LunpfDl0Tk89VY5W3ZVh12OiEibielwB7h+QgE1hw5x32trwy5FRKTNxHy45/XozEXDe/Pnxeuo2n8w7HJERNpEzIc7wPRJA9hdfZBH3lgfdikiIm0iLsJ9ZG4mY/K7cU9hKTW1h8IuR0Sk1cVFuAN865wCNlZWM2/5xrBLERFpdXET7pMH9WRgzzTuXlCiKQlEJObFTbgnJBjTJhXw3ke7Wfjh1rDLERFpVXET7gCXj+xLzy4p3P3qmrBLERFpVY0OdzNLNLO3zGxesH+fmZWa2dvBY2TQbmZ2h5kVm9lyMxvVWsU3VUpSItdNyGdR8TZWlleGXY6ISKtpSs/9JmD1UW0/dPeRwePtoO0iYGDwmA7c1fwyW87XzupHWkoSM1/VhGIiErsaFe5mlgNcAsxuxOmXA/d7xGIg08z6NKPGFpWemsyVY3J5bsUmNmzfG3Y5IiKtorE9998DPwKOvkn8V8HQy+1mlhK0ZQMb6p1TFrQdwcymm1mRmRVVVFQ0te5muW5CPgbMKdSEYiISmxoMdzO7FNji7kuPOnQLMAQ4E+gG/LgpL+zuM919tLuPzsrKasqlzdYnoyOXjezLo29uYOfeA2362iIibaExPffxwGVmthZ4BDjPzB5w903B0Mt+4F5gTHB+OZBb7/qcoK1dmT6pgH01tTyweF3YpYiItLgGw93db3H3HHfPA64AXnb3r9eNo5uZAVOAlcElzwBXB3fNjAUq3X1T65R/8ob0Tmfy4Czue20t1TW1YZcjItKimnOf+4NmtgJYAfQAfhm0Pw+UAMXALODbzaqwFU2fVMDWqgM8uazd/WEhItIsSU052d3nA/OD7fOOc44DM5pbWFsYV9CdEdkZzF5YwlfPzCUxwcIuSUSkRcTVN1SPZmZMn1RAydY9vPju5rDLERFpMXEd7gAXDe9NbreOzNSUBCISQ+I+3JMSE7h+QgHL1u+kaO32sMsREWkRcR/uAF8enUNmp2Tu1pQEIhIjFO5Apw5JXD0ujxff3UzxlqqwyxERaTaFe+Cacf1JSUpg9kL13kUk+incA93TUvjSGTk8uaycLburwy5HRKRZFO71TJtYQM2hQ9y3aG3YpYiINIvCvZ68Hp25cFhvHli8jqr9B8MuR0TkpCncjzJ9UgG7qg/y6JsbGj5ZRKSdUrgf5fR+XRmT1417CkupqT16+noRkeigcD+GG84poHznPp5b3u4msxQRaRSF+zGcO7gnp/RM4+5XS4jMgyYiEl0U7seQkGBMn1jA6k27KCzeGnY5IiJNpnA/jstP70vPLincvUBfahKR6KNwP46UpESuHZ9PYfFWVpZXhl2OiEiTKNxP4Gtn9aNzh0RmaUoCEYkyCvcTyOiYzJVj+jFv+SbKduwNuxwRkUZTuDfgugn5GDCnsDTsUkREGq3R4W5miWb2lpnNC/bzzWyJmRWb2aNm1iFoTwn2i4Pjea1Tetvom9mRy07ry6NvbqByb03Y5YiINEpTeu43Aavr7f8auN3dTwF2AFOD9qnAjqD99uC8qDZtUgF7D9TywJJ1YZciItIojQp3M8sBLgFmB/sGnAc8HpwyF5gSbF8e7BMcPz84P2qd2iedcwZlce+itVTX1IZdjohIgxrbc/898COgbrKV7sBOd6+bOrEMyA62s4ENAMHxyuD8I5jZdDMrMrOiioqKkyy/7dwwqYCtVft56q3ysEsREWlQg+FuZpcCW9x9aUu+sLvPdPfR7j46KyurJZ+6VYwb0J3h2enMerWEQ4c0JYGItG+N6bmPBy4zs7XAI0SGY/4AZJpZUnBODlDXpS0HcgGC4xnAthasORRmxg2TBlCydQ8vrt4cdjkiIifUYLi7+y3unuPuecAVwMvufhXwCvCl4LRrgL8G288E+wTHX/YYmX3rouG9yenakZmv6ktNItK+Nec+9x8DN5tZMZEx9TlB+xyge9B+M/CT5pXYfiQlJnD9hHyWrttB0drtYZcjInJcSQ2f8jF3nw/MD7ZLgDHHOKca+HIL1NYufeXMXH7/0ofc/WoJo/O6hV2OiMgx6RuqTdSpQxJXj+3PP1dvZk1FVdjliIgck8L9JFx9dh4dEhOYrQnFRKSdUrifhB5pKXzxjByeWFbOlt3VYZcjIvIJCveTNG1iATW1h5j72tqwSxER+QSF+0nK79GZzw7tzQOL17Nn/8GGLxARaUMK92aYfk4BlftqePTNDWGXIiJyBIV7M4zq15Uxed2YU1hKTe2hhi8QEWkjCvdmmj6pgPKd+3h+xaawSxEROUzh3kznDenJgKzO3L2ghBiZZUFEYoDCvZkSEozpkwp4d9MuCou3hl2OiAigcG8RU07PJqtLiiYUE5F2Q+HeAlKSErl2fB4LP9zKqo2VYZcjIqJwbylXndWfzh0SmaXeu4i0Awr3FpLRMZkrx/Tj2eWbKNuxN+xyRCTOKdxb0HUT8jHgnsK1YZciInFO4d6C+mZ25HOn9eWRN9dTubcm7HJEJI4p3FvYtIkF7D1QywNL1oVdiojEMYV7CxvaN51Jg7K4d9Faqmtqwy5HROKUwr0V3DCpgK1V+3n6rfKwSxGRONVguJtZqpm9YWbvmNkqM/t50H6fmZWa2dvBY2TQbmZ2h5kVm9lyMxvV2r9Ee3P2gO4M65vOzIUlHDqkKQlEpO01pue+HzjP3U8DRgIXmtnY4NgP3X1k8Hg7aLsIGBg8pgN3tXTR7Z2ZccM5Ayip2MM/V28OuxwRiUMNhrtH1K0EnRw8TtQdvRy4P7huMZBpZn2aX2p0uXh4b3K6dtSUBCISikaNuZtZopm9DWwBXnT3JcGhXwVDL7ebWUrQlg3UX72iLGg7+jmnm1mRmRVVVFQ041don5ISE5g6IZ+idTtYum572OWISJxpVLi7e627jwRygDFmNhy4BRgCnAl0A37clBd295nuPtrdR2dlZTWx7Ojw1TNzyeyUzN0L1HsXkbbVpLtl3H0n8ApwobtvCoZe9gP3AmOC08qB3HqX5QRtcadThyS+MbY/L67eTElFVcMXiIi0kMbcLZNlZpnBdkfgM8B7dePoZmbAFGBlcMkzwNXBXTNjgUp3j9tliq4el0dyYgKzFpaGXYqIxJHG9Nz7AK+Y2XLgTSJj7vOAB81sBbAC6AH8Mjj/eaAEKAZmAd9u8aqjSFaXFL44KocnlpVRsXt/2OWISJxIaugEd18OnH6M9vOOc74DM5pfWuyYNjGfR95cz9zX1vKvnx0cdjkiEgf0DdU2UJCVxgVDe/HnxevYs/9g2OWISBxQuLeR6ZMGULmvhnsKNfYuIq1P4d5GzujflU+f2ovfvvgB//70CvYf1KRiItJ6FO5t6K6vj+KGSQU8sHg9X7rrdTZs14pNItI6FO5tKDkxgVsuPpWZ3ziDtdv2cMkdC/nnu5p7RkRansI9BBcM681z351Iv+6duP7+Iv77b6s5WHso7LJEJIYo3EPSr3snHv/W2Vx1Vj/uXlDC12YtYfOu6rDLEpEYoXAPUWpyIr/6/Ah+/9WRrCiv5JI7FvJa8dawyxKRGKBwbwemnJ7NM98ZT2anDnx9zhL+96UPtciHiDSLwr2dGNirC3+dMZ7LTuvLb1/8gGvve5Ptew6EXZaIRCmFezvSOSWJ2786kl9OGc7ra7Zx6R0LWbZ+R9hliUgUUri3M2bG18f254l/OZvEROMr//c69xSWEpmyR0SkcRTu7dSInAzmfWcikwf35P/Ne5cZDy1jd3VN2GWJSJRQuLdjGZ2SmXX1Gdxy0RBeWLWZy+5cxOpNu8IuS0SigMK9nTMzbjhnAA9PG8veAweZ8sdFPPbmhoYvFJG4pnCPEmPyu/HcjRMZndeVHz2xnH/9yzvsO6DJx0Tk2BTuUaRHWgr3X3cWN553Ck8sK+Pzf1qktVlF5JgU7lEmMcG4+YLB3HftGDbvquayOxfx3PK4XaJWRI6jMQtkp5rZG2b2jpmtMrOfB+35ZrbEzIrN7FEz6xC0pwT7xcHxvNb9FeLTOYOyeO7GiQzqlcaMh5bxs2dWceCgJh8TkYjG9Nz3A+e5+2nASOBCMxsL/Bq43d1PAXYAU4PzpwI7gvbbg/OkFfTN7Mgj08cxdUI+9722lq/c/TrlO/eFXZaItAMNhrtH1A3sJgcPB84DHg/a5wJTgu3Lg32C4+ebmbVYxXKEDkkJ/MelQ7nrqlGs2VLFJXcs5JX3t4RdloiErFFj7maWaGZvA1uAF4E1wE53r1vtuQzIDrazgQ0AwfFKoHtLFi2fdNGIPjz73Qn0yejItfe+yW0vvE+tJh8TiVuNCnd3r3X3kUAOMAYY0twXNrPpZlZkZkUVFRXNfToB8np05qlvn80VZ+Zy5yvFfH32Erbs1hzxIvGoSXfLuPtO4BVgHJBpZknBoRygPNguB3IBguMZwLZjPNdMdx/t7qOzsrJOsnw5WmpyIrd+8VPc9uXTeGvDDi65o5DFJZ/45xeRGNeYu2WyzCwz2O4IfAZYTSTkvxScdg3w12D7mWCf4PjLrlmv2tyXzsjh6Rnj6ZKSxNdmLeau+Ws0R7xIHGlMz70P8IqZLQfeBF5093nAj4GbzayYyJj6nOD8OUD3oP1m4CctX7Y0xpDe6Tzz3QlcPKIPv/77e0y7v4idezVHvEg8sPbQqR49erQXFRWFXUbMcnf+vHgdv5j3Lj27pPKnq0ZxWm5m2GWJSDOZ2VJ3H32sY/qGahwwM64el8dfvnU2AF/+v9f58+trNUe8SAxTuMeRkbmZPHfjBCYM7MF//HUVNz7yNlX7DzZ8oYhEHYV7nMns1IHZV4/mRxcO5rnlG7nszkI+2Lw77LJEpIUp3ONQQoLx7cmn8NC0seyuPsjldy7iyWVlYZclIi1I4R7HxhZ057kbJ3BabgY3P/YOtzy5nOoazREvEgsU7nGuZ5dUHph6FjPOHcDDb2zgC396jXXb9oRdlog0k8JdSEpM4IefHcK93zyTjZX7uPR/C/n7yo/CLktEmkHhLoedO6Qn8747gYKsNL71wFJ+Me9d9h7Q3TQi0UjhLkfI6dqJv9wwjm+encecwlLOvW0+j725QTNMikQZhbt8QoekBH522TAe/9Y4+mZ25EdPLOeSOxay4APN3ikSLRTuclyj87rx5L+czR+/Noq9B2q55p43+MacJazetCvs0kSkAQp3OSEz45JP9eHFmyfxH5cOZXlZJRffsZAf/uUdPqrUXPEi7ZUmDpMmqdxbwx/nF3PforUkJMC0iQXccM4A0lKSGr5YRFqUJg6TFpPRKZmfXnwqL/3gHC4Y2pv/fbmYyf/zCg8sXsfB2kNhlyciAYW7nJTcbp2448rTeXrGeAp6pPHvT6/kwj8s5KXVmzXbpEg7oHCXZhmZm8mjN4xl5jfO4NAhZ+rcIq6ctZgVZZVhlyYS1xTu0mxmxgXDevPC9yfxi8uH8cHmKj53ZyHfe+QtynbsDbs8kbikD1Slxe2qruH/5q9hTmEpDlw7Po9vTz6FjI7JYZcmElNO9IGqwl1azcad+7jtH+/z1FvlZHZM5sbzB3LVWf3pkKQ/GEVaQrPuljGzXDN7xczeNbNVZnZT0P4zMys3s7eDx8X1rrnFzIrN7H0z+2zL/SoSTfpmduR3XxnJs9+ZwKl90vn5s+9ywe0L+NuKTfrQVaSVNdhzN7M+QB93X2ZmXYClwBTgK0CVu9921PlDgYeBMUBf4J/AIHc/7kTh6rnHPndn/vsV/Nfzq/lwSxVn9O/Kv11yKqP6dQ27NJGo1ayeu7tvcvdlwfZuYDWQfYJLLgcecff97l4KFBMJeoljZsa5Q3ryt5sm8t9fGMH67Xv5wp9eY8ZDy1i/TR+6irS0Jg1+mlkecDqwJGj6jpktN7N7zKyuC5YNbKh3WRnHeDMws+lmVmRmRRUVmpAqXiQlJnDlmH7M/9fJ3HT+QF5evYXzfzefX8x7l517D4RdnkjMaHS4m1ka8ATwPXffBdwFDABGApuA3zblhd19pruPdvfRWVlZTblUYkDnlCS+/5lBzP/hZL44Kod7F5Uy6TevMOvVEvYf1FJ/Is3VqHA3s2Qiwf6guz8J4O6b3b3W3Q8Bs/h46KUcyK13eU7QJvIJvdJTufWLn+L5myZyer+u/Or51Zz/2wU8885Gfegq0gyNuVvGgDnAanf/Xb32PvVO+zywMth+BrjCzFLMLB8YCLzRciVLLBrSO525143hz1PH0CU1mRsffospf1zEkpJtYZcmEpUac7fMBGAhsAKomxnqp8CVRIZkHFgL3ODum4Jr/g24DjhIZBjnbyd6Dd0tI/XVHnKeequc2154n492VXPB0F78+KIhDMhKC7s0kXZFX2KSqLTvQC33LCrlT68UU33wEFed1Y+bzh9I97SUsEsTaRcU7hLVKnbv5w8vfcDDb2ygY3Ii/zJ5AFMn5JOanBh2aSKh0nzuEtWyuqTwyykjeOF7kxhb0J3/eeF9zrttPk8sLeOQFu4WOSaFu0SNU3qmMfua0TwyfSw9uqTwg7+8w+fuLGRR8dawSxNpdxTuEnXGFnTn6W+P5w9XjGTn3hqumr2Ea+99g5XlmkNepI7G3CWqVdfUMve1tdz5SjG7qw9y9oDuXD8xn8mDepKQYGGXJ9Kq9IGqxLzKfTU8/MZ67lu0lo92VTMgqzNTJxTwhVHZ+uBVYpbCXeJGTe0hnl+xiVkLS1hZvotunTvw9bH9+cbY/mR10S2UElsU7hJ33J0lpduZvbCUl97bTHJCAlNO78v1EwsY1KtL2OWJtIgThXtSWxcj0hbMjLEF3Rlb0J2SiiruWVTK40vLeKyojEmDspg2MZ8Jp/QgMruGSOxRz13ixo49B3hwyTrmvr6Oit37GdyrC1Mn5nP5yL6kJGlcXqKPhmVE6tl/sJZn39nE7IUlvPfRbnqkpXDNuP5cNbY/3Tp3CLs8kUZTuIscg7uzqHgbswtLmP9+BSlJCXzxjBymTsjXJGUSFTTmLnIMZsaEgT2YMLAHH2zezT2FkXH5h5as5/whPZk6MZ9xBd01Li9RST13kXq2Vu3ngcXr+PPr69i25wDD+qZz/cR8LhnRlw5J+kK3tC8alhFpouqaWp5+q5zZhaUUb6mid3oq15ydx9fG9COjU3LY5YkACneRk3bokLPgwwrmLCylsHgrnTok8pXRuVw7Po/+3TuHXZ7EOYW7SAt4d+Mu5hSW8sw75Rw85FwwtBfTJhZwRv+uGpeXUCjcRVrQll3VzH19LQ8sXk/lvhpOy81k2sR8LhzWm6REjctL21G4i7SCvQcO8sSycu4pLKV06x6yMzty7fg8vnpmLl1SNS4vra9Z4W5mucD9QC8ii2HPdPc/mFk34FEgj8gC2V9x9x0W+fv0D8DFwF7gm+6+7ESvoXCXaHbokPPSe1uYvbCEJaXbSUtJ4oozc/nm+DxyunYKuzyJYc0N9z5AH3dfZmZdgKXAFOCbwHZ3v9XMfgJ0dfcfm9nFwHeJhPtZwB/c/awTvYbCXWLF8rKdzCksZd7yTQBcNLw3108sYGRuZsiVSSxq0WEZM/srcGfwmOzum4I3gPnuPtjM7g62Hw7Of7/uvOM9p8JdYs3GnfuY+9paHnpjPburDzK6f1eun5jPZ4b2JlGLiEgLabEFss0sDzgdWAL0qhfYHxEZtgHIBjbUu6wsaDv6uaabWZGZFVVUVDSlDJF2r29mR265+FRev+V8/vNzQ9m8u5pvPbCMc2+bz32LStmz/2DYJUqMa3TP3czSgAXAr9z9STPb6e6Z9Y7vcPeuZjYPuNXdC4P2l4Afu/txu+bquUusqz3k/GPVR8wuLGXpuh107pDImfndDk9LPLxvuu60kSZr9twyZpYMPAE86O5PBs2bzaxPvWGZLUF7OZBb7/KcoE0kbiUmGBeN6MNFI/qwbP0OnlxWxpKS7dz6t/cAFPbS4hoM9+DulznAanf/Xb1DzwDXALcGP/9ar/07ZvYIkQ9UK0803i4Sb0b168qofl0BqNi9nzdKt7O4ZBuLS7YdEfaj8+rCvhsjsjMU9tIkjblbZgKwEFgBHAqaf0pk3P0xoB+wjsitkNuDN4M7gQuJ3Ap57YmGZEDDMiJ1jg77D7dUAZ8M++HZGSQr7OOevsQkEqUU9nIiCneRGLG16siw/2BzJOw7HQ77SOCPUNjHBYW7SIxS2Mc3hbtInFDYxxeFu0icOlHYn9G/6+FbLz+Vo7CPRgp3EQFg2xFhv533N+8GFPbRSuEuIsfUuLCP3I2TkpQYcrVyNIW7iDTK8cI+OdEY1KsLI7IzGJadwYjsDIb07kJqsgI/TAp3ETkpdWH/TlklqzZWsqK8kp17a4DIlAoDe6YxIjuDETkZDOubwdA+6XTsoMBvKwp3EWkR7k7Zjn2Hg35F+S5Wlleyfc8BABIMBvbswrDs9EjoZ2dwap90Oqc0ahoraaJmTxwmIgJgZuR260Rut05cOLwPEAn8TZXVrCivZFV5JPRf/WArTy4rD66BAVmRHv6wvumHh3bSFPitSv+6ItIsZkbfzI70zezIZ4f1Pty+eVc1K8oqWbmxkpXllby2ZitPvfVx4Od378zwoHc/LDud4dkZpGvt2RajcBeRVtErPZVeQ1P59NBeh9u27K5mVfkuVpRHAr9o7XaeeWfj4eN53Tsd/sC2rqef2alDGOVHPYW7iLSZnl1S6TkklXOH9Dzctq1qPys3RsbuV5RV8s6GnTy3/ONZwnO7dWR434zDvfzh2Rl066zAb4jCXURC1UpRIlQAAAdfSURBVD0thXMGZXHOoKzDbTv2HGDVxo97+Cs3VvK3lR8dPp6d2ZHh2elH3JrZIy0ljPLbLYW7iLQ7XTt3YMLAHkwY2ONwW+XeGlZtjAR93V06L6zafPh47/RUhgdDOQN6pjEgqzMFPdLi9tZMhbuIRIWMTsmcfUoPzj7l48DfXV3DqmBIZ2Vwp85L722m/h3efTNSGdAzjYIenSnISmNAVhoFWZ3pk5FKZG2h2KRwF5Go1SU1+fB8OHWqa2pZu20Pa7bsoaSiipKte1hTUcUTy8qp2n/w8HkdkxMpyIoEfkGPzvXeADrTqUP0R2P0/wYiIvWkJicypHc6Q3qnH9Hu7lTs3k9xRRUlFXsoqYiE/tsbdjBv+cZP9PYLgh5+XU+/ICuNPumpJCRER29f4S4iccHM6JmeSs/0VM4e0OOIY3W9/UjoV7Em+PnkMXr7+UHvfkC98M/v0bndfQu3wWrM7B7gUmCLuw8P2n4GTAMqgtN+6u7PB8duAaYCtcCN7v5CK9QtItJiGurtrwl6+SUVeyjZWsU7ZTt5bsWmI3r7fTJSPw79uvH9nuH19hvzVnMfcCdw/1Htt7v7bfUbzGwocAUwDOgL/NPMBrl7bQvUKiLSpur39scN6H7EseqaWtZt2xuEftXhYZ6nlpWzu15vPzU5gfwewd07WZGfbdHbb/CZ3f1VM8tr5PNdDjzi7vuBUjMrBsYAr590hSIi7VBqciKDe3dhcO8uR7TX7+2XbK2KfLC7tYrlZZWf6O33Tk9l6oR8pk0qaPH6mvO28R0zuxooAn7g7juAbGBxvXPKgrZPMLPpwHSAfv36NaMMEZH2ozG9/ci4fqS33zO9db58dbLhfhfwC8CDn78FrmvKE7j7TGAmRKb8Pck6RESixvF6+63hpBZJdPfN7l7r7oeAWUSGXgDKgdx6p+YEbSIi0oZOKtzNrE+93c8DK4PtZ4ArzCzFzPKBgcAbzStRRESaqjG3Qj4MTAZ6mFkZ8J/AZDMbSWRYZi1wA4C7rzKzx4B3gYPADN0pIyLS9rTMnohIlDrRMnsnNSwjIiLtm8JdRCQGKdxFRGKQwl1EJAa1iw9UzawCWHeSl/cAtrZgOa0tmuqNplohuuqNplohuuqNplqhefX2d/esYx1oF+HeHGZWdLxPi9ujaKo3mmqF6Ko3mmqF6Ko3mmqF1qtXwzIiIjFI4S4iEoNiIdxnhl1AE0VTvdFUK0RXvdFUK0RXvdFUK7RSvVE/5i4iIp8UCz13ERE5isJdRCQGRW24m1mumb1iZu+a2Sozuynsmk7EzFLN7A0zeyeo9+dh19QQM0s0s7fMbF7YtZyIma01sxVm9raZtfsZ6Mws08weN7P3zGy1mY0Lu6ZjMbPBwb9p3WOXmX0v7LpOxMy+H/z/WmlmD5tZatg1HY+Z3RTUuao1/l2jdsw9mFO+j7svM7MuwFJgiru/G3Jpx2RmBnR29yozSwYKgZvcfXEDl4bGzG4GRgPp7n5p2PUcj5mtBUa7e1R8ccXM5gIL3X22mXUAOrn7zrDrOhEzSySy8M5Z7n6yXzhsVWaWTeT/1VB33xdMP/68u98XbmWfZGbDgUeILHR0APg78C13L26p14janru7b3L3ZcH2bmA1x1mvtT3wiKpgNzl4tNt3VjPLAS4BZoddSywxswxgEjAHwN0PtPdgD5wPrGmvwV5PEtDRzJKATsDGkOs5nlOBJe6+190PAguAL7TkC0RtuNdnZnnA6cCScCs5sWCY421gC/Ciu7fnen8P/Ag4FHYhjeDAP8xsabDwenuWD1QA9wZDXrPNrHPYRTXCFcDDYRdxIu5eDtwGrAc2AZXu/o9wqzqulcBEM+tuZp2AizlyidJmi/pwN7M04Ange+6+K+x6TiRYd3YkkbVlxwR/mrU7ZnYpsMXdl4ZdSyNNcPdRwEXADDObFHZBJ5AEjALucvfTgT3AT8It6cSCoaPLgL+EXcuJmFlX4HIib6B9gc5m9vVwqzo2d18N/Br4B5EhmbeBFl21LqrDPRi7fgJ40N2fDLuexgr+DH8FuDDsWo5jPHBZMJb9CHCemT0QbknHF/TYcPctwFN8vGB7e1QGlNX7q+1xImHfnl0ELHP3zWEX0oBPA6XuXuHuNcCTwNkh13Rc7j7H3c9w90nADuCDlnz+qA334APKOcBqd/9d2PU0xMyyzCwz2O4IfAZ4L9yqjs3db3H3HHfPI/Ln+Mvu3i57QGbWOfhAnWB44wI+XrC93XH3j4ANZjY4aDqfyJrD7dmVtPMhmcB6YKyZdQry4Xwin8W1S2bWM/jZj8h4+0Mt+fwNLpDdjo0HvgGsCMaxAX7q7s+HWNOJ9AHmBncdJACPuXu7vsUwSvQCnor8XyYJeMjd/x5uSQ36LvBgMNxRAlwbcj3HFbxhfga4IexaGuLuS8zscWAZcBB4i/Y9FcETZtYdqAFmtPQH61F7K6SIiBxf1A7LiIjI8SncRURikMJdRCQGKdxFRGKQwl1EJAYp3EVEYpDCXUQkBv1/bOOdRM1A6fcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating a simple clustering model of vessels using KMeans\n",
    "\n",
    "vessel_hours = df2.groupby(['vessel', 'quad'])['hour_delta'].sum().abs().reset_index()\n",
    "vessel_df = vessel_hours.pivot(index='vessel', columns='quad', values='hour_delta').fillna(0)\n",
    "vessel_df = vessel_df.div(vessel_df.sum(axis=1), axis=0)\n",
    "vessel_df = vessel_df.merge(voyages_df.groupby('vessel')['voyage_dist'].mean(), left_index=True, right_index=True)\n",
    "\n",
    "# scaling the values\n",
    "scaler = StandardScaler()\n",
    "scaled_vessel_df = scaler.fit_transform(vessel_df)\n",
    "\n",
    "# using a loop to determine the number of clusters to use\n",
    "kmeans_inertias = []\n",
    "\n",
    "for n in range(2, 10):\n",
    "  kmeans_vessels = KMeans(n_clusters=n)\n",
    "  kmeans_vessels.fit(scaled_vessel_df)\n",
    "  kmeans_inertias.append(kmeans_vessels.inertia_)\n",
    "\n",
    "\n",
    "plt.plot(range(2,10), kmeans_inertias)\n",
    "plt.title(\"Elbow Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7kICzxY9Enr"
   },
   "outputs": [],
   "source": [
    "# the kmeans model that's used in the models - 3 works better than 6 \n",
    "# when incorporated into the model\n",
    "\n",
    "kmeans_vessels = KMeans(n_clusters = 3)\n",
    "kmeans_vessels.fit(scaled_vessel_df)\n",
    "\n",
    "kmeans_vessels.labels_\n",
    "\n",
    "vessel_df['labels'] = kmeans_vessels.labels_\n",
    "\n",
    "# creating a dictionary with the labels\n",
    "kmeans_labels = {v:label for v, label in zip(vessel_df.index, vessel_df['labels'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kF-vL7n3WKGb"
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, n_input = 3):\n",
    "  \"\"\"\n",
    "  preparing the sequences for window based models\n",
    "  \"\"\"\n",
    "\n",
    "  df = get_voyages(df)\n",
    "  vessel = df['vessel'].iloc[0]\n",
    "  ports_ = np.array(df['begin_port_id'].append(pd.Series(df['end_port_id'].iloc[-1])))  \n",
    "\n",
    "  X = []\n",
    "  Y = []\n",
    "  start = 0\n",
    "\n",
    "  for i in range(len(ports_)):\n",
    "    last_input = start + n_input\n",
    "    last_output = last_input + 3\n",
    "    if last_output <= len(ports_):\n",
    "      x = ports_[start:last_input]\n",
    "      y = ports_[last_input: last_output]\n",
    "      X.append(x)\n",
    "      Y.append(y)\n",
    "      start += 1\n",
    "  try:\n",
    "    df = pd.concat([pd.DataFrame(X),\n",
    "                  pd.DataFrame(Y, columns=['port_1ahead', 'port_2ahead', 'port_3ahead'])], axis=1)\n",
    "    \n",
    "  except:\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "  # X = []\n",
    "\n",
    "  # for x in X:\n",
    "  #   for n in x:\n",
    "  #     if n == -75:\n",
    "  #       port_coords = [33, 140]\n",
    "  #     else:\n",
    "  #       port_coords = list(ports[n])\n",
    "  #     port = [n]\n",
    "  #     port.extend(port_coords)\n",
    "  #     new_X.append(port)\n",
    "  \n",
    "  df['vessel'] = len(df) * [vessel]\n",
    "  df['kmeans_label'] = [kmeans_labels[n] for n in df['vessel']]\n",
    "  \n",
    "  return df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtTQNF2qY-RB"
   },
   "outputs": [],
   "source": [
    "def build_model(target='port_1ahead', min_samples=1, n_back = 3, min_examples=2):  \n",
    "\n",
    "  model_df = pd.concat([prepare_data(processed_dfs[key], n_back) for key in processed_dfs.keys()]) \n",
    "\n",
    "  for i in range(0, n_back):\n",
    "    model_df[f'cluster_{i+1}back'] = [db_labels[n] for n in model_df[i]]\n",
    "\n",
    "  examples = model_df[target].value_counts()\n",
    "  singles = examples[examples < min_examples].index\n",
    "\n",
    "  model_df = model_df[~model_df[target].isin(singles)]\n",
    "\n",
    "  model_df['samples'] = model_df.groupby('vessel')['vessel'].transform(lambda x: x.count())\n",
    "  filtered_df = model_df.query('samples > @min_samples')\n",
    "\n",
    "  vessels_excluded = set(model_df['vessel'].unique()).difference(set(filtered_df['vessel'].unique()))\n",
    "\n",
    "  features = [n for n in range(n_back)] + ['cluster_1back', 'cluster_2back', 'cluster_3back', 'kmeans_label'] \n",
    "  target = target\n",
    "\n",
    "  X = filtered_df[features]\n",
    "  y = filtered_df[target]\n",
    "  model = XGBClassifier()\n",
    "\n",
    "  param_grid = {\n",
    "      'learning_rate': [0.01, 0.05],\n",
    "      'max_depth' : [3, 4]\n",
    "  }\n",
    "\n",
    "  grid_search = GridSearchCV(model, param_grid,cv=3)\n",
    "  grid_result = grid_search.fit(X, y)\n",
    "\n",
    "  print('The training excluded vessels:', vessels_excluded)\n",
    "  print('The best model params were:', grid_result.best_params_)\n",
    "  print('The best accuracy achieved was:', grid_result.best_score_)\n",
    "  \n",
    "  return grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jtEHbOIdTCDW",
    "outputId": "ee3562b4-9ad8-4519-cf75-d97275ab4932"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training excluded vessels: {64, 107, 75, 85}\n",
      "The best model params were: {'learning_rate': 0.05, 'max_depth': 4}\n",
      "The best accuracy achieved was: 0.4235726984022148\n",
      "The training excluded vessels: {107, 75, 85}\n",
      "The best model params were: {'learning_rate': 0.01, 'max_depth': 4}\n",
      "The best accuracy achieved was: 0.40961860778634024\n",
      "The training excluded vessels: {107, 75, 85}\n",
      "The best model params were: {'learning_rate': 0.05, 'max_depth': 3}\n",
      "The best accuracy achieved was: 0.35948542467750855\n"
     ]
    }
   ],
   "source": [
    "model_1ahead = build_model(target='port_1ahead', min_samples=2, n_back=3, min_examples=5)\n",
    "model_2ahead = build_model(target='port_2ahead', min_samples=2, n_back=3, min_examples=5)\n",
    "model_3ahead = build_model(target='port_3ahead', min_samples=2, n_back=3, min_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNr535_OkB3F"
   },
   "outputs": [],
   "source": [
    "def build_cat_model(target='port_1ahead', n_back=3, n_iterations=250):\n",
    "\n",
    "  cat_df = pd.concat([prepare_data(processed_dfs[key], n_back) for key in processed_dfs.keys()])\n",
    "  \n",
    "  for i in range(0, n_back):\n",
    "    cat_df[f'cluster_{i+1}back'] = [db_labels[n] for n in cat_df[i]]\n",
    "  \n",
    "  examples = cat_df[target].value_counts()\n",
    "  singles = examples[examples < 3].index\n",
    "\n",
    "  cat_df = cat_df[~cat_df[target].isin(singles)]\n",
    "  features = [0, 1, 2, 'kmeans_label', 'cluster_1back', 'cluster_2back', 'cluster_3back']\n",
    "\n",
    "  cat_train = cat_df[features].astype(np.int8)\n",
    "\n",
    "  cat_train_targets = cat_df[target]\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(cat_train, cat_train_targets, test_size=0.2)\n",
    "\n",
    "  cat_features = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "  cat_train = Pool(X_train,\n",
    "                  label=y_train,\n",
    "                  cat_features=cat_features)\n",
    "\n",
    "  cat_eval = Pool(X_test,\n",
    "                  label=y_test,\n",
    "                  cat_features=cat_features)\n",
    "  \n",
    "\n",
    "  cat = CatBoostClassifier(iterations=n_iterations,\n",
    "                           learning_rate=0.25,\n",
    "                           loss_function='MultiClass')\n",
    "\n",
    "  cat.fit(cat_train,\n",
    "          eval_set=cat_eval,\n",
    "          early_stopping_rounds=15,\n",
    "          use_best_model=True)\n",
    "\n",
    "                                \n",
    "  print('The feature importances of the model are:', cat.feature_importances_)\n",
    "  print('The accuracy of the model on the test set is:', cat.eval_metrics(cat_eval, metrics='Accuracy'))\n",
    "  \n",
    "  return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ic7VuPlEmdYp"
   },
   "outputs": [],
   "source": [
    "# cat_model_1ahead = build_cat_model(target='port_1ahead')\n",
    "cat_model_2ahead = build_cat_model(target='port_2ahead')\n",
    "# cat_model_3ahead = build_cat_model(target='port_3ahead') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5ERpuNpF_WT"
   },
   "outputs": [],
   "source": [
    "def get_pred_data(df, n_input = 3):\n",
    "  \"\"\"\n",
    "  preparing the sequences for predictions with the XGBClassifier model\n",
    "  \"\"\"\n",
    "\n",
    "  df = get_voyages(df)\n",
    "  vessel = df['vessel'].iloc[0]\n",
    "  ports_ = np.array(df['begin_port_id'].append(pd.Series(df['end_port_id'].iloc[-1])))\n",
    "  \n",
    "  pred_seq = ports_[-n_input:]\n",
    "\n",
    "  if len(pred_seq) < n_input:\n",
    "    pred_seq = np.insert(pred_seq, 0, pred_seq[-1])\n",
    "  \n",
    "  return pred_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NlGujqAv2FW"
   },
   "outputs": [],
   "source": [
    "# creating a dictionary with the most recent ports visited for each vessel\n",
    "\n",
    "window_data = {key:get_pred_data(processed_dfs[key], n_input=3) for key in processed_dfs.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJkGCyNIwvvS"
   },
   "outputs": [],
   "source": [
    "# creating a dataframe with the features used in the models\n",
    "\n",
    "sub = pd.DataFrame.from_dict(window_data, orient='index')\n",
    "\n",
    "sub['cluster_1back'] = [db_labels[n] for n in sub[0]]\n",
    "sub['cluster_2back'] = [db_labels[n] for n in sub[1]]\n",
    "sub['cluster_3back'] = [db_labels[n] for n in sub[2]]\n",
    "sub['kmeans_label'] = [kmeans_labels[n] for n in sub.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6i6_80Y91LAe"
   },
   "outputs": [],
   "source": [
    "# predicting the next port. also including the second most likely port in case\n",
    "# the model predicts duplicates. \n",
    "\n",
    "port_1 = model_1ahead.predict(sub)\n",
    "port_2 = model_2ahead.predict(sub)\n",
    "port_2_alt = [model_2ahead.best_estimator_.classes_[np.argsort(n)[-2]] for n in model_2ahead.predict_proba(sub)]\n",
    "port_3 = model_3ahead.predict(sub)\n",
    "port_3_alt = [model_3ahead.best_estimator_.classes_[np.argsort(n)[-2]] for n in model_3ahead.predict_proba(sub)]\n",
    "sub['port_1ahead'] = port_1\n",
    "sub['port_2ahead'] = port_2\n",
    "sub['port_2ahead_2nd'] = port_2_alt\n",
    "sub['port_3ahead'] = port_3\n",
    "sub['port_3ahead_2nd'] = port_3_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VJNB5MI0E0a"
   },
   "outputs": [],
   "source": [
    "# using conditional assignment to replace port predictions with the second most\n",
    "# likely\n",
    "\n",
    "sub.loc[sub['port_1ahead'] == sub['port_2ahead'], 'port_2ahead'] = sub['port_2ahead_2nd']\n",
    "sub.loc[sub['port_2ahead'] == sub['port_3ahead'], 'port_3ahead'] = sub['port_3ahead_2nd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3SrpcaTKtDo"
   },
   "outputs": [],
   "source": [
    "# changing the shape of the dataframe so it conforms to what's required\n",
    "\n",
    "# resetting the index and renaming the column\n",
    "sub = sub.reset_index()\n",
    "sub.rename(columns={'index':'vessel'}, inplace=True)\n",
    "\n",
    "# limiting columns to those required and renaming\n",
    "sub = sub[['vessel', 2, 'port_1ahead', 'port_2ahead', 'port_3ahead']]\n",
    "sub.rename(columns={2:'final_port'}, inplace=True)\n",
    "\n",
    "# using melt to narrow the DataFrame and put the voyages into the same column\n",
    "sub = pd.melt(sub, id_vars='vessel').sort_values(by=['vessel', 'variable'])\n",
    "sub['end_port_id'] = sub.groupby('vessel')['value'].transform(lambda x: x.shift(-1))\n",
    "sub = sub.dropna()\n",
    "\n",
    "# adding a voyage count, more renaming\n",
    "sub['voyage'] = sub.groupby('vessel').cumcount()+1\n",
    "sub.rename(columns={'value' : 'begin_port_id'}, inplace=True)\n",
    "sub.drop(columns=['variable'], inplace=True)\n",
    "sub['end_port_id'] = sub['end_port_id'].astype(int)\n",
    "sub = sub.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lipU-tqdU_Va"
   },
   "outputs": [],
   "source": [
    "sub.to_csv('predict.csv', index=False)\n",
    "# lstm_pred.to_csv('lstm_predict.csv', index=False)\n",
    "voyages_df.to_csv('voyages.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hd_OvZ0lenDm"
   },
   "outputs": [],
   "source": [
    "def show_routes(vessel=1, start='2019-01-01', end='2019-12-28'): \n",
    "  \n",
    "  df_ = df2.query(f'vessel == {vessel}').set_index('datetime')\n",
    "\n",
    "  fig = px.scatter_geo(df_.loc[start: end], lat='lat', lon='long', color='direction',\n",
    "                       hover_name=df_.loc[start: end].index)\n",
    "\n",
    "  fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCU2YOfOdJda"
   },
   "outputs": [],
   "source": [
    "def draft_and_voyages(vessel=103):\n",
    "\n",
    "  df = alldf.query(f'vessel == {vessel}')\n",
    "  \n",
    "  in_port = df[df['pred_port'] > 0].index\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(20,5))\n",
    "  \n",
    "  df[['port_dist', 'draft']].plot(ax=ax)\n",
    "  \n",
    "  for p in in_port:\n",
    "    plt.axvline(p, ls='--', lw=0.5, c='r', label='port')\n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QScIRJFV7CuS"
   },
   "outputs": [],
   "source": [
    "alldf = pd.concat(processed_dfs)\n",
    "\n",
    "alldf.query('pred_port >0 & pred_port_dist >50').vessel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMmS0SBQHstg"
   },
   "outputs": [],
   "source": [
    "v1 = processed_dfs[160]\n",
    "\n",
    "print(v1[['pred_port', 'draft', 'direction', 'port_sequence_time', 'pred_port_dist', 'pred_port_backup', 'heading_seq', 'heading_sequence_time', 'dist_last_port']].to_string())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOWqLnequK4V8H5v3u5E0KZ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1bTzsC2_o8Jg772hCJWDRqrHnkqeQuRQx",
   "name": "sym_cargo_alt_cleaned.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
