{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sym_cargo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bTzsC2_o8Jg772hCJWDRqrHnkqeQuRQx",
      "authorship_tag": "ABX9TyMeWCMRFohjaxr19lSCajhA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaobviously/sym-cargo/blob/main/sym_cargo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRudeILZCNAh"
      },
      "source": [
        "!pip install plotly-express --quiet\n",
        "!pip install vincenty --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M5J6bV0HQAk"
      },
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrMMphhGyTIp"
      },
      "source": [
        "I'll clean up this repo and provide visualizations. I also want to figure out how to get an LSTM model working with multiple embeddings. Trying things out as I learn.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFygxcBXBsUT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.cluster import DBSCAN\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, RepeatVector, LSTM, Dense\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import EarlyStopping\n",
        "from xgboost import XGBClassifier\n",
        "from vincenty import vincenty\n",
        "from sklearn.model_selection import train_test_split\n",
        "import plotly_express as px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERdgnPI_B8xV"
      },
      "source": [
        "port_file = '/content/drive/MyDrive/Ports/ports.csv'\n",
        "tracking_file = '/content/drive/MyDrive/Ports/tracking.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGQ3oW9dCGF6"
      },
      "source": [
        "def wrangle():\n",
        "  \n",
        "  df1 = pd.read_csv(port_file)\n",
        "\n",
        "  # converting lat and long to radians to compute haversine distance\n",
        "  df1['lat_rad'] = np.radians(df1['lat'])\n",
        "  df1['long_rad'] = np.radians(df1['long'])\n",
        "  \n",
        "  # rounding lat and long in port df\n",
        "  df1['lat'] = df1['lat'].round(1)\n",
        "  df1['long'] = df1['long'].round(1)\n",
        "\n",
        "  df2 = pd.read_csv(tracking_file, parse_dates=['datetime'])\n",
        "  df2 = df2.drop_duplicates()\n",
        "  df2 = df2.sort_values(['vessel', 'datetime'])\n",
        "  df2['vessel_1back'] = df2['vessel'].shift()\n",
        "  \n",
        "  # converting lat and long to radians to compute haversine distance  \n",
        "  df2['lat_rad'] = np.radians(df2['lat'])\n",
        "  df2['long_rad'] = np.radians(df2['long'])\n",
        "\n",
        "  # adding lat/long column and lat/long 1 back to later compute delta\n",
        "  df2['lat_long'] = [[x,y] for x, y in zip(df2['lat'], df2['long'])]\n",
        "  df2['lat_long_1back'] = df2.groupby('vessel')['lat_long'].transform(lambda x: x.shift())\n",
        "  \n",
        "  # time deltas to compute impossible distances travelled\n",
        "  df2['time_delta'] = df2.groupby('vessel')['datetime'].transform(lambda x: x - x.shift(1))\n",
        "  df2['hour_delta'] = df2['time_delta'].apply(lambda x: x.seconds / 3600)\n",
        "\n",
        "  # filtering using query to eliminate unneeded/impossible values\n",
        "  df2 = df2.query('hour_delta > 0.25 & speed <30 & heading <=360 & draft < 12.5')\n",
        "  df2 = df2.reset_index(drop=True)\n",
        "\n",
        "  return df1, df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZJrWQ6eCIqV"
      },
      "source": [
        "df1, df2 = wrangle()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tL74j_2a7LR"
      },
      "source": [
        "def vincent_distance(row):\n",
        "  \"\"\" \n",
        "  returns the vincenty distance for contiguous rows - will be used to identify\n",
        "  impossible distances travelled, and so on. could be used to create distance\n",
        "  matrix, but this may not be worthwhile \n",
        "  \"\"\"\n",
        "  if row['vessel'] != row['vessel_1back']:\n",
        "    return -99\n",
        "\n",
        "  loc1 = row['lat_long']\n",
        "  loc2 = row['lat_long_1back']\n",
        "\n",
        "  try:\n",
        "    distance = vincenty(loc1, loc2)\n",
        "    return distance\n",
        "  except:\n",
        "    return -99"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1P_JxyybKHc"
      },
      "source": [
        "# creating a dictionary of ports with their lat and longs - will be used\n",
        "# repeatedly to explore data and assign values\n",
        "\n",
        "ports = {port:(lat, long) for port, lat, long in zip(df1['port'], df1['lat'], df1['long'])}\n",
        "\n",
        "# a dictionary to retrieve the port id from the index\n",
        "idx_ports = {idx:port for idx, port in zip(df1.index, df1.port)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rg5F1xcTElh",
        "outputId": "127ad33c-9633-4f21-ec2e-49d0310c8787"
      },
      "source": [
        "# training a nearest neighbor model to  find the closest port when the \n",
        "# conditions indicating an extended stop have occurred. the metric is haversine\n",
        "# in order to compute the 'great circle' distance. so i don't forget, the model\n",
        "# returns the *index* of the port, not the port's identifying label\n",
        "\n",
        "ports_train = df1[['lat_rad', 'long_rad']]\n",
        "\n",
        "neigh_ports = NearestNeighbors(n_neighbors=3, algorithm='ball_tree', metric='haversine')\n",
        "neigh_ports.fit(ports_train)\n",
        "\n",
        "dist, n = neigh_ports.kneighbors(np.array([0.677565, 0.469731]).reshape(1,-1))\n",
        "\n",
        "print(dist[0] * 6370)\n",
        "print([idx_ports[n] for n in n[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  3.30931026  46.44757565 255.13837716]\n",
            "[82, 113, 44]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC92dd_FI7MT"
      },
      "source": [
        "def nearest_port(df, radius=0.01):\n",
        "  \"\"\"\n",
        "  returns the port identifier of the nearest port using the nearest neighbors\n",
        "  model \n",
        "  \"\"\"\n",
        "\n",
        "  data = np.array([df['lat_rad'], df['long_rad']]).reshape(1, -1)\n",
        "  dist, pred = neigh_ports.radius_neighbors(data, radius=radius, sort_results = True) \n",
        "\n",
        "  if len(dist[0]) == 0:\n",
        "    return -1\n",
        "  \n",
        "  else:\n",
        "    return idx_ports[pred[0][0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2cHgfSNZbx2"
      },
      "source": [
        "def nearest_distance(df, radius=0.0125):\n",
        "  \"\"\"\n",
        "  returns the distance of the nearest port in the dataset\n",
        "  \"\"\"\n",
        "  \n",
        "  data = np.array([df['lat_rad'], df['long_rad']]).reshape(1, -1)\n",
        "  dist, pred = neigh_ports.radius_neighbors(data, radius=radius, sort_results = True) \n",
        "\n",
        "  if len(dist[0]) == 0:\n",
        "    return -1\n",
        "  \n",
        "  else:\n",
        "    return dist[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoYZuM6lqJIa"
      },
      "source": [
        "def vincenty_port(row):\n",
        "  \"\"\"\n",
        "  a function that computes the vincenty distance between the assigned port\n",
        "  and the latitude and longitude of the location data\n",
        "  \"\"\"\n",
        "  port = row['port_coords']\n",
        "  loc = row['lat_long']\n",
        "  return vincenty(port, loc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLCHF2I5CII2"
      },
      "source": [
        "def train_dbscan(df=df1, eps=0.1, min_samples=2):\n",
        "  \"\"\"\n",
        "  use the dbscan clustering algorithm to find groupss of ports\n",
        "\n",
        "  params\n",
        "  ------\n",
        "      df: pandas df\n",
        "      eps: min distance between points in cluster\n",
        "      min_samples: min members in a cluster\n",
        "\n",
        "  returns\n",
        "  -------\n",
        "      labels: labels matching index of long/lat input pairs\n",
        "  \"\"\"\n",
        "  \n",
        "  coords = df[['long_rad', 'lat_rad']].values\n",
        "  db = DBSCAN(eps=eps, min_samples=min_samples, algorithm='ball_tree', metric='haversine')\n",
        "\n",
        "  db.fit(coords)\n",
        "\n",
        "  return db.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU_Co92uMDoL"
      },
      "source": [
        "# creating a dictionary of labels\n",
        "df1['labels'] = train_dbscan()\n",
        "db_labels = {port:cluster for port, cluster in zip(df1['port'], df1['labels'])}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxCo8-h_g9E8"
      },
      "source": [
        "def assign_ports(df):\n",
        "  \"\"\"\n",
        "  prepares a dataframe for port assignment by resampling  and filtering\n",
        "  it\n",
        "\n",
        "  params:\n",
        "  -----\n",
        "        df: pandas dataframe\n",
        "  \n",
        "  returns:\n",
        "  -------\n",
        "        df: processed pandas dataframe\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # resampling the data to standardize time intervals\n",
        "  df = df.resample('4H').mean().ffill()\n",
        "  df['lat_rad'] = df['lat_rad'].resample('4H').median().ffill()\n",
        "  df['long_rad'] = df['long_rad'].resample('4H').median().ffill()\n",
        "  \n",
        "  # applying a mask to limit the rows the predict function is applied to\n",
        "  mask = (df['speed'] <= 5)\n",
        "  df_temp = df[mask]\n",
        "\n",
        "  df['pred_port'] = 0\n",
        "  df.loc[mask, 'pred_port'] = df_temp.apply(nearest_port, axis=1)  \n",
        "  df['port_coords'] = [list(ports[k]) if k in ports else -99 for k in df['pred_port']]\n",
        "  df['lat_long'] = [[x,y] for x, y in zip(df['lat'], df['long'])]\n",
        "\n",
        "  # applying a mask to limit the rows vincenty func is applied to\n",
        "  vin_mask = (df['pred_port'] > 0)\n",
        "  vin_temp = df[vin_mask]\n",
        "  \n",
        "  df['port_dist'] = 0\n",
        "  df.loc[vin_mask, 'port_dist'] = vin_temp.apply(vincenty_port, axis=1)\n",
        "\n",
        "  # eliminating entries in sequences where max distance greatly differs from min\n",
        "  # indicates 'waiting to enter port'\n",
        "  df['seq'] = df['pred_port'].diff().ne(0).cumsum()\n",
        "  df['seq_count'] = df.groupby('seq')['seq'].transform('count')\n",
        "  df['dist_diff'] = df.groupby('seq')['port_dist'].transform(lambda x: x - x.min())\n",
        "  df['pred_port'] = np.where(df['dist_diff'] >= 15, 0, df['pred_port'])     # 15km away from closest point this trip to the port \n",
        "\n",
        "  # determining whether a block contains or is adjacent to a change in draft\n",
        "  df['draft_delta_back'] = df['draft'].transform(lambda x: abs(x.diff()).ge(0.5))\n",
        "  df['draft_delta_ahead'] = df['draft'].transform(lambda x: abs(x.diff(-1)).ge(0.5))\n",
        "  df['sum_draft_back'] = df.groupby('seq')['draft_delta_back'].transform('sum')\n",
        "  df['sum_draft_ahead'] = df.groupby('seq')['draft_delta_ahead'].transform('sum')\n",
        "  df['sum_draft'] = df['sum_draft_ahead'] + df['sum_draft_back']\n",
        "\n",
        "  condition = (df['seq_count'] <= 4) & (df['sum_draft'] <1)\n",
        "  df['pred_port'] = np.where(condition, 0, df['pred_port'])\n",
        "\n",
        "  # recasting vessel and pred_port columns as integers\n",
        "  df[['vessel', 'pred_port']] = df[['vessel', 'pred_port']].astype(int)\n",
        "\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDnoQ4hnfhce"
      },
      "source": [
        "def get_voyages(df):\n",
        "  \"\"\"\n",
        "  converts the port sequences in each dataframe into voyages\n",
        "  with the proper formatting\n",
        "\n",
        "  param:\n",
        "  -----\n",
        "      df: pandas DataFrame\n",
        "  \n",
        "  returns:\n",
        "  -------\n",
        "      df: processed pandas DataFrame\n",
        "      \n",
        "  \"\"\"\n",
        "  # filtering out columns without an assigned port\n",
        "  nz = df[(df['pred_port'] > 0) | (df['pred_port'] == -75)].reset_index()\n",
        "\n",
        "  vessel = nz['vessel'][0]\n",
        "  dt = nz['datetime']\n",
        "  pred = nz['pred_port']\n",
        "\n",
        "  records = []\n",
        "\n",
        "  for i in range(len(dt)-1):\n",
        "    if pred[i] != pred[i+1]:\n",
        "      start_port = pred[i]\n",
        "      end_port = pred[i+1]\n",
        "      begin_date = dt[i]\n",
        "      end_date = dt[i+1]\n",
        "      records.append([vessel, begin_date, end_date, start_port, end_port])\n",
        "\n",
        "  df = pd.DataFrame.from_records(records, columns = ['vessel', 'begin_date', 'end_date', 'begin_port_id', 'end_port_id'])\n",
        "  \n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RO8RBNQqWb3"
      },
      "source": [
        "def find_next_port(df):\n",
        "  \"\"\"\n",
        "  find the next port visited for each row in the DataFrame, excluding the current \n",
        "  port. the value 0 is used to indicate that there is no next port in the data\n",
        "  \n",
        "  params\n",
        "  ------\n",
        "      df : pandas DataFrame\n",
        "\n",
        "  return\n",
        "  ------\n",
        "      df: pandas DataFrame \n",
        "  \n",
        "  \"\"\"\n",
        "\n",
        "  ports = df['pred_port']\n",
        "\n",
        "  next_port = []\n",
        "\n",
        "  for i in range(len(ports)):\n",
        "    p = ports[i]\n",
        "    for n in ports[i:]:\n",
        "      if (p != n) & (n >0) :\n",
        "        next_port.append(n)\n",
        "        break\n",
        "\n",
        "  # padding zeros at the end to indicate no next port \n",
        "  zeroes = [0] * (len(ports) - len(next_port))\n",
        "  next_ports = next_port + zeroes\n",
        "  \n",
        "  df['next_port'] = next_ports\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbHcYBVQcWst"
      },
      "source": [
        "# calculating the distance between each row using the vincenty function above.\n",
        "# note it only calcs within each vessel group (see function). the elapsed time\n",
        "# and the total distance travelled implies a speed and that speed allows for\n",
        "# effetcive filtering of impossible routes\n",
        "\n",
        "df2['vin_diff'] = df2.apply(vincent_distance, axis=1)\n",
        "df2['vin_per_hour'] = df2['vin_diff'] / df2['hour_delta']\n",
        "df2 = df2.query('vin_per_hour <= 50')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9tCbNDQiRfQ"
      },
      "source": [
        "# creating a dictionary of vessel dataframes with a datetime index\n",
        "\n",
        "vessel_dfs = {}\n",
        "\n",
        "for vessel in df2.vessel.unique():\n",
        "  df_ = df2[df2['vessel'] == vessel]\n",
        "  vessel_dfs[vessel] = df_.set_index('datetime')\n",
        "\n",
        "# assigning ports to each dataframe\n",
        "processed_dfs = {key:assign_ports(vessel_dfs[key]) for key in vessel_dfs.keys()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irWz30hWlesV"
      },
      "source": [
        "alldf = pd.concat(processed_dfs[key] for key in processed_dfs.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_TnV_EudLEQ"
      },
      "source": [
        "# creating a dictionary of dataframes for each port and then extracting the min,\n",
        "# max, and max_draft distances for assigned ports\n",
        "\n",
        "ports_dfs = {}\n",
        "\n",
        "for port in alldf.pred_port.unique():\n",
        "  ports_dfs[port] = alldf[alldf['pred_port'] == port]\n",
        "\n",
        "del ports_dfs[-1]\n",
        "del ports_dfs[0]\n",
        "\n",
        "min_max = {}\n",
        "\n",
        "for df in ports_dfs.keys():\n",
        "  draft_max = ports_dfs[df].query('sum_draft >=1').port_dist.max()\n",
        "  min_max[df] = [ports_dfs[df]['port_dist'].max(), ports_dfs[df]['port_dist'].min(), draft_max]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SIs4v7TvD-a"
      },
      "source": [
        "voyages_df = pd.concat([get_voyages(processed_dfs[key]) for key in processed_dfs.keys()])\n",
        "voyages_df['begin_date'] = voyages_df['begin_date'].dt.date\n",
        "voyages_df['end_date'] = voyages_df['end_date'].dt.date\n",
        "# voyages_df['len_voyage'] = voyages_df['end_date'] - voyages_df['begin_date']\n",
        "# voyages_df['begin_coords'] = [ports[key] for key in voyages_df['begin_port_id']]\n",
        "# voyages_df['end_coords'] = [ports[key] for key in voyages_df['end_port_id']]\n",
        "# voyages_df['voyage_dist'] = [vincenty(x, y) for x, y in zip(voyages_df['begin_coords'], voyages_df['end_coords'])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUI1F3FtqaKT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "ec408ad0-42ca-4b06-fdd6-61af9e9f6431"
      },
      "source": [
        "voyages_df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vessel</th>\n",
              "      <th>begin_date</th>\n",
              "      <th>end_date</th>\n",
              "      <th>begin_port_id</th>\n",
              "      <th>end_port_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>2019-01-16</td>\n",
              "      <td>138</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>2019-02-02</td>\n",
              "      <td>102</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2019-02-14</td>\n",
              "      <td>2019-03-01</td>\n",
              "      <td>138</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   vessel  begin_date    end_date  begin_port_id  end_port_id\n",
              "0       1  2019-01-01  2019-01-16            138          102\n",
              "1       1  2019-01-17  2019-02-02            102          138\n",
              "2       1  2019-02-14  2019-03-01            138           33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF-vL7n3WKGb"
      },
      "source": [
        "def prepare_data(df, n_input = 3):\n",
        "  \"\"\"\n",
        "  preparing the sequences for window based models\n",
        "  \"\"\"\n",
        "\n",
        "  df = get_voyages(df)\n",
        "  vessel = df['vessel'].iloc[0]\n",
        "  ports_ = np.array(df['begin_port_id'].append(pd.Series(df['end_port_id'].iloc[-1])))  \n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "  start = 0\n",
        "\n",
        "  for i in range(len(ports_)):\n",
        "    last_input = start + n_input\n",
        "    last_output = last_input + 3\n",
        "    if last_output <= len(ports_):\n",
        "      x = ports_[start:last_input]\n",
        "      y = ports_[last_input: last_output]\n",
        "      X.append(x)\n",
        "      Y.append(y)\n",
        "      start += 1\n",
        "  try:\n",
        "    df = pd.concat([pd.DataFrame(X),\n",
        "                  pd.DataFrame(Y, columns=['port_1ahead', 'port_2ahead', 'port_3ahead'])], axis=1)\n",
        "    \n",
        "  except:\n",
        "    df = pd.DataFrame()\n",
        "    \n",
        "  # X = []\n",
        "\n",
        "  # for x in X:\n",
        "  #   for n in x:\n",
        "  #     if n == -75:\n",
        "  #       port_coords = [33, 140]\n",
        "  #     else:\n",
        "  #       port_coords = list(ports[n])\n",
        "  #     port = [n]\n",
        "  #     port.extend(port_coords)\n",
        "  #     new_X.append(port)\n",
        "  \n",
        "  df['vessel'] = len(df) * [vessel]\n",
        "  \n",
        "  return df.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MldbZ9EkYdqU"
      },
      "source": [
        "model_df = pd.concat([prepare_data(processed_dfs[key], 6) for key in processed_dfs.keys()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtTQNF2qY-RB"
      },
      "source": [
        "def build_model(target='port_1ahead', min_samples=5, n_back = 6):\n",
        "\n",
        "  model_df = pd.concat([prepare_data(processed_dfs[key], n_back) for key in processed_dfs.keys()]) \n",
        "\n",
        "  model_df['cluster_1back'] = [db_labels[n] for n in model_df[0]]\n",
        "  model_df['cluster_2back'] = [db_labels[n] for n in model_df[1]]\n",
        "  model_df['cluster_3back'] = [db_labels[n] for n in model_df[2]]\n",
        "\n",
        "  model_df['samples'] = model_df.groupby('vessel')['vessel'].transform(lambda x: x.count())\n",
        "  filtered_df = model_df.query('samples > @min_samples')\n",
        "\n",
        "  vessels_excluded = set(model_df['vessel'].unique()).difference(set(filtered_df['vessel'].unique()))\n",
        "\n",
        "  features = [n for n in range(n_back)] + ['cluster_1back', 'cluster_2back', 'cluster_3back'] \n",
        "  target = target\n",
        "\n",
        "  X = filtered_df[features]\n",
        "  y = filtered_df[target]\n",
        "  model = XGBClassifier()\n",
        "\n",
        "  param_grid = {\n",
        "      'learning_rate': [0.01, 0.02, 0.03]\n",
        "  }\n",
        "\n",
        "  grid_search = GridSearchCV(model, param_grid, cv=3)\n",
        "  grid_result = grid_search.fit(X, y)\n",
        "\n",
        "  print('The training excluded vessels:', vessels_excluded)\n",
        "  print('The best model params were:', grid_result.best_params_)\n",
        "  print('The best accuracy achieved was:', grid_result.best_score_)\n",
        "  \n",
        "  return grid_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtEHbOIdTCDW"
      },
      "source": [
        "model_1ahead = build_model(target='port_1ahead', min_samples=5, n_back=3)\n",
        "model_2ahead = build_model(target='port_2ahead', min_samples=5, n_back=3)\n",
        "model_3ahead = build_model(target='port_3ahead', min_samples=5, n_back=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5ERpuNpF_WT"
      },
      "source": [
        "def get_pred_data(df, n_input = 3):\n",
        "  \"\"\"\n",
        "  preparing the sequences for predictions\n",
        "  \"\"\"\n",
        "\n",
        "  df = get_voyages(df)\n",
        "  vessel = df['vessel'].iloc[0]\n",
        "  ports_ = np.array(df['begin_port_id'].append(pd.Series(df['end_port_id'].iloc[-1])))  \n",
        "\n",
        "  return ports_[-n_input:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NlGujqAv2FW"
      },
      "source": [
        "# creating a dictionary with the most recent ports visited for each vessel\n",
        "\n",
        "window_data = {key:get_pred_data(processed_dfs[key], n_input=6) for key in processed_dfs.keys()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJkGCyNIwvvS"
      },
      "source": [
        "# creating a dataframe with the features used in the models\n",
        "\n",
        "sub = pd.DataFrame.from_dict(window_data, orient='index')\n",
        "\n",
        "sub['cluster_1back'] = [db_labels[n] for n in sub[0]]\n",
        "sub['cluster_2back'] = [db_labels[n] for n in sub[1]]\n",
        "sub['cluster_3back'] = [db_labels[n] for n in sub[2]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i6_80Y91LAe"
      },
      "source": [
        "# predicting the next port. also including the second most likely port in case\n",
        "# the model predicts duplicates. \n",
        "\n",
        "port_1 = model_1ahead.predict(sub)\n",
        "port_2 = model_2ahead.predict(sub)\n",
        "port_2_alt = [model_2ahead.best_estimator_.classes_[np.argsort(n)[-2]] for n in model_2ahead.predict_proba(sub)]\n",
        "port_3 = model_3ahead.predict(sub)\n",
        "port_3_alt = [model_3ahead.best_estimator_.classes_[np.argsort(n)[-2]] for n in model_3ahead.predict_proba(sub)]\n",
        "sub['port_1ahead'] = port_1\n",
        "sub['port_2ahead'] = port_2\n",
        "sub['port_2ahead_2nd'] = port_2_alt\n",
        "sub['port_3ahead'] = port_3\n",
        "sub['port_3ahead_2nd'] = port_3_alt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VJNB5MI0E0a"
      },
      "source": [
        "# using conditional assignment to replace port predictions with the second most\n",
        "# likely\n",
        "\n",
        "sub.loc[sub['port_1ahead'] == sub['port_2ahead'], 'port_2ahead'] = sub['port_2ahead_2nd']\n",
        "sub.loc[sub['port_2ahead'] == sub['port_3ahead'], 'port_3ahead'] = sub['port_3ahead_2nd']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3SrpcaTKtDo"
      },
      "source": [
        "# changing the shape of the dataframe so it conforms to what's required\n",
        "\n",
        "# resetting the index and renaming the column\n",
        "sub = sub.reset_index()\n",
        "sub.rename(columns={'index':'vessel'}, inplace=True)\n",
        "\n",
        "# limiting columns to those required and renaming\n",
        "sub = sub[['vessel', 2, 'port_1ahead', 'port_2ahead', 'port_3ahead']]\n",
        "sub.rename(columns={2:'final_port'}, inplace=True)\n",
        "\n",
        "# using melt to narrow the DataFrame and put the voyages into the same column\n",
        "sub = pd.melt(sub, id_vars='vessel').sort_values(by=['vessel', 'variable'])\n",
        "sub['end_port_id'] = sub.groupby('vessel')['value'].transform(lambda x: x.shift(-1))\n",
        "sub = sub.dropna()\n",
        "\n",
        "# adding a voyage count, more renaming\n",
        "sub['voyage'] = sub.groupby('vessel').cumcount()+1\n",
        "sub.rename(columns={'value' : 'begin_port_id'}, inplace=True)\n",
        "sub.drop(columns=['variable'], inplace=True)\n",
        "sub['end_port_id'] = sub['end_port_id'].astype(int)\n",
        "sub = sub.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_6avCrtDDhQ"
      },
      "source": [
        "Creating an LSTM model to predict the future voyages. I will come back to this!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj9dvByke8iK"
      },
      "source": [
        "encoder = {key:value for key, value in zip(df1['port'], df1.index)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWPWg-FVSLyH"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, RepeatVector, LSTM, Dense\n",
        "\n",
        "model_df = model_df.astype(int)\n",
        "total_ports = 122\n",
        "\n",
        "X = model_df[[0, 1, 2, 3, 4, 5]]\n",
        "\n",
        "for col in X.columns:\n",
        "  X.loc[:,col] = X[col].map(encoder)\n",
        "\n",
        "y = model_df[['port_1ahead', 'port_2ahead', 'port_3ahead']]\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1944)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(total_ports, 3, input_length=6))\n",
        "model.add(LSTM(75, activation='relu', return_sequences=False))\n",
        "model.add(RepeatVector(3))\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(179, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoIgnQNPV0V4"
      },
      "source": [
        "history = model.fit(X_train,y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=32,\n",
        "                    epochs=250,\n",
        "                    callbacks=EarlyStopping(monitor='val_accuracy',\n",
        "                                            patience=15,\n",
        "                                            restore_best_weights=True));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBLlbXF6lqyi"
      },
      "source": [
        "seq_for_pred = (np.array([encoder[j] for j in n]) for k, n in window_data.values()])\n",
        "seq_for_pred = pad_sequences(seq_for_pred, maxlen=6, value=0)\n",
        "preds = model.predict(seq_for_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBQApzdGwu1q"
      },
      "source": [
        "first_port = pd.Series([np.argmax(n[0]) for n in preds])\n",
        "second_port = pd.Series([np.argmax(n[1]) for n in preds])\n",
        "alt_second = pd.Series([np.argsort(n[1])[-2] for n in preds])\n",
        "third_port = pd.Series([np.argmax(n[2]) for n in preds])\n",
        "alt_third = pd.Series([np.argsort(n[2])[-2] for n in preds])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOqRO78LoVr6"
      },
      "source": [
        "\n",
        "last_port = pd.Series(seq_for_pred[:,-1])\n",
        "lstm_pred = pd.concat([last_port, first_port, second_port, alt_second, third_port, alt_third], axis=1)\n",
        "lstm_pred.index = window_data.keys()\n",
        "lstm_pred = lstm_pred.reset_index()\n",
        "lstm_pred.columns = ['vessel', 'last_port', 'pred1', 'pred2', 'alt2', 'pred3', 'alt3']\n",
        "lstm_pred['pred2'] = np.where(lstm_pred['pred1'] == lstm_pred['pred2'], lstm_pred['alt2'], f['pred2'])\n",
        "lstm_pred['pred3'] = np.where(lstm_pred['pred2'] == lstm_pred['pred3'], lstm_pred['alt3'], lstm_pred['pred3'])\n",
        "lstm_pred.drop(columns=['alt2', 'alt3'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "zPZZ6EX_ANdP",
        "outputId": "7edd056c-5cb8-4400-f94e-b30fdedaf9cd"
      },
      "source": [
        "lstm_pred.head(3)                             # what's with the 91s?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vessel</th>\n",
              "      <th>last_port</th>\n",
              "      <th>pred1</th>\n",
              "      <th>pred2</th>\n",
              "      <th>pred3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>92</td>\n",
              "      <td>91</td>\n",
              "      <td>138</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>36</td>\n",
              "      <td>91</td>\n",
              "      <td>57</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>57</td>\n",
              "      <td>149</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   vessel  last_port  pred1  pred2  pred3\n",
              "0       1         92     91    138     91\n",
              "1       2         36     91     57    138\n",
              "2       3         13     57    149     75"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lipU-tqdU_Va"
      },
      "source": [
        "sub.to_csv('predict.csv', index=False)\n",
        "voyages_df.to_csv('voyages.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd_OvZ0lenDm"
      },
      "source": [
        "fig = px.scatter_geo(alldf[alldf['vessel'] == 138], lat='lat', lon='long', size='port_dist',\n",
        "                     hover_name='pred_port')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnaJpiELRKK4"
      },
      "source": [
        "# submissions\n",
        "\n",
        "voyages = pd.DataFrame(columns= ['vessel', 'begin_date', 'end_date', 'begin_port_id', 'end_port_id'])\n",
        "predict = pd.DataFrame(columns= ['vessel', 'begin_port_id', 'end_port_id', 'voyage'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}