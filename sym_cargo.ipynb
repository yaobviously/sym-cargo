{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sym_cargo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bTzsC2_o8Jg772hCJWDRqrHnkqeQuRQx",
      "authorship_tag": "ABX9TyPSa8r4oAsAtDSeOXITjGmc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaobviously/sym-cargo/blob/main/sym_cargo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRudeILZCNAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04c7ad0d-f8d5-4bc9-b3c0-ea9302ce64e9"
      },
      "source": [
        "!pip install plotly-express --quiet\n",
        "!pip install vincenty --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for vincenty (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrMMphhGyTIp"
      },
      "source": [
        "I'll clean up this repo and provide visualizations. \n",
        "\n",
        "I used many quick plots to figure out heuristics to exclude ships travelling near ports with no intention of docking, but I excluded them from his notebook because it was messy. I'll clean up a few and put them in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFygxcBXBsUT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, RepeatVector, LSTM, Dense, TimeDistributed\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import EarlyStopping\n",
        "from xgboost import XGBClassifier\n",
        "from vincenty import vincenty\n",
        "from sklearn.model_selection import train_test_split\n",
        "import plotly_express as px"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERdgnPI_B8xV"
      },
      "source": [
        "port_file = '/content/drive/MyDrive/Ports/ports.csv'\n",
        "tracking_file = '/content/drive/MyDrive/Ports/tracking.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGQ3oW9dCGF6"
      },
      "source": [
        "def wrangle():\n",
        "  \n",
        "  df1 = pd.read_csv(port_file)\n",
        "\n",
        "  # converting lat and long to radians to compute haversine distance\n",
        "  df1['lat_rad'] = np.radians(df1['lat'])\n",
        "  df1['long_rad'] = np.radians(df1['long'])\n",
        "  \n",
        "  # rounding lat and long in port df\n",
        "  df1['lat'] = df1['lat']\n",
        "  df1['long'] = df1['long']\n",
        "  df1['lat_long'] = [[x,y] for x, y in zip(df1['lat'], df1['long'])]\n",
        "\n",
        "  df2 = pd.read_csv(tracking_file, parse_dates=['datetime'])\n",
        "  df2 = df2.drop_duplicates()\n",
        "  df2 = df2.sort_values(['vessel', 'datetime'])\n",
        "  df2['vessel_1back'] = df2['vessel'].shift()\n",
        "  \n",
        "  # converting lat and long to radians to compute haversine distance  \n",
        "  df2['lat_rad'] = np.radians(df2['lat'])\n",
        "  df2['long_rad'] = np.radians(df2['long'])\n",
        "\n",
        "  # adding lat/long column and lat/long 1 back to later compute delta\n",
        "  df2['lat_long'] = [[x,y] for x, y in zip(df2['lat'], df2['long'])]\n",
        "  df2['lat_long_1back'] = df2.groupby('vessel')['lat_long'].transform(lambda x: x.shift())\n",
        "  \n",
        "  # time deltas to compute impossible distances travelled\n",
        "  df2['time_delta'] = df2.groupby('vessel')['datetime'].transform(lambda x: x - x.shift(1))\n",
        "  df2['hour_delta'] = [(n.days * 24) + (n.seconds / 3600) for n in df2['time_delta']]\n",
        "\n",
        "  # filtering using query to eliminate unneeded/impossible values\n",
        "  df2 = df2.query('speed <30 & heading <=360 & draft < 13.5')\n",
        "  df2 = df2.reset_index(drop=True)\n",
        "\n",
        "  return df1, df2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZJrWQ6eCIqV"
      },
      "source": [
        "df1, df2 = wrangle()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tL74j_2a7LR"
      },
      "source": [
        "def vincent_distance(row):\n",
        "  \"\"\" \n",
        "  returns the vincenty distance for contiguous rows - will be used to identify\n",
        "  impossible distances travelled, and so on. could be used to create distance\n",
        "  matrix, but this may not be worthwhile \n",
        "  \"\"\"\n",
        "  if row['vessel'] != row['vessel_1back']:\n",
        "    return -99\n",
        "\n",
        "  loc1 = row['lat_long']\n",
        "  loc2 = row['lat_long_1back']\n",
        "\n",
        "  try:\n",
        "    distance = vincenty(loc1, loc2)\n",
        "    return distance\n",
        "  except:\n",
        "    return -99"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1P_JxyybKHc"
      },
      "source": [
        "# creating a dictionary of ports with their lat and longs - will be used\n",
        "# repeatedly to explore data and assign values\n",
        "\n",
        "ports = {port:(lat, long) for port, lat, long in zip(df1['port'], df1['lat'], df1['long'])}\n",
        "\n",
        "# a dictionary to retrieve the port id from the index\n",
        "idx_ports = {idx:port for idx, port in zip(df1.index, df1.port)}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvA-nfJqtqAQ"
      },
      "source": [
        "# getting the vincenty distances for each pair of ports in the ports.csv file\n",
        "# extracting those that are within 100km of each other\n",
        "\n",
        "close_ones = []\n",
        "\n",
        "for x in df1['lat_long']:\n",
        "  distances = []\n",
        "  for y in df1['lat_long']:\n",
        "    vdist = vincenty(x, y)\n",
        "    distances.append(vdist)\n",
        "  close_ones.append(distances)\n",
        "\n",
        "disters = [[(df1['port'].iloc[n], z) for n, z in zip(np.argsort(p)[:5], sorted(p)[:5])] for p in close_ones]\n",
        "\n",
        "close_ones = {}\n",
        "\n",
        "for n in disters:\n",
        "  port = n[0][0]\n",
        "  dees = {d:v for d, v in n[1:] if v < 100}\n",
        "  close_ones[port] = dees\n",
        "\n",
        "close_ones = {k:v for k,v in close_ones.items() if len(v) >= 1}\n",
        "\n",
        "really_close = [30, 109, 42, 51, 65]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rg5F1xcTElh",
        "outputId": "3cb88fc9-8fc4-4911-8ed3-35820daa1eba"
      },
      "source": [
        "# training a nearest neighbor model to  find the closest port when the \n",
        "# conditions indicating an extended stop have occurred. the metric is haversine\n",
        "# in order to compute the 'great circle' distance. so i don't forget, the model\n",
        "# returns the *index* of the port, not the port's identifying label\n",
        "\n",
        "ports_train = df1[['lat_rad', 'long_rad']]\n",
        "\n",
        "neigh_ports = NearestNeighbors(n_neighbors=3, algorithm='ball_tree', metric='haversine')\n",
        "neigh_ports.fit(ports_train)\n",
        "\n",
        "dist, n = neigh_ports.kneighbors(np.array([0.677565, 0.469731]).reshape(1,-1))\n",
        "\n",
        "print(dist[0] * 6370)\n",
        "print([idx_ports[n] for n in n[0]])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  3.30931026  46.44757565 255.13837716]\n",
            "[82, 113, 44]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC92dd_FI7MT"
      },
      "source": [
        "def nearest_port(df, radius=0.0175):\n",
        "  \"\"\"\n",
        "  returns the port identifier of the nearest port using the nearest neighbors\n",
        "  model \n",
        "  \"\"\"\n",
        "\n",
        "  data = np.array([df['lat_rad'], df['long_rad']]).reshape(1, -1)\n",
        "  dist, pred = neigh_ports.radius_neighbors(data, radius=radius, sort_results = True) \n",
        "\n",
        "  if len(dist[0]) == 0:\n",
        "    return 0\n",
        "  \n",
        "  else:\n",
        "    return idx_ports[pred[0][0]]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2cHgfSNZbx2"
      },
      "source": [
        "def nearest_distance(df, radius=0.0175):\n",
        "  \"\"\"\n",
        "  returns the distance of the nearest port in the dataset\n",
        "  \"\"\"\n",
        "  \n",
        "  data = np.array([df['lat_rad'], df['long_rad']]).reshape(1, -1)\n",
        "  dist, pred = neigh_ports.radius_neighbors(data, radius=radius, sort_results = True) \n",
        "\n",
        "  if len(dist[0]) == 0:\n",
        "    return -1\n",
        "  \n",
        "  else:\n",
        "    return dist[0][0]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoYZuM6lqJIa"
      },
      "source": [
        "def vincenty_port(row):\n",
        "  \"\"\"\n",
        "  a function that computes the vincenty distance between the assigned port\n",
        "  and the latitude and longitude of the location data\n",
        "  \"\"\"\n",
        "  port = row['port_coords']\n",
        "  loc = row['lat_long']\n",
        "  return vincenty(port, loc)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLCHF2I5CII2"
      },
      "source": [
        "def train_dbscan(df=df1, eps=0.1, min_samples=2):\n",
        "  \"\"\"\n",
        "  use the dbscan clustering algorithm to find groupss of ports\n",
        "\n",
        "  params\n",
        "  ------\n",
        "      df: pandas df\n",
        "      eps: min distance between points in cluster\n",
        "      min_samples: min members in a cluster\n",
        "\n",
        "  returns\n",
        "  -------\n",
        "      labels: labels matching index of long/lat input pairs\n",
        "  \"\"\"\n",
        "  \n",
        "  coords = df[['long_rad', 'lat_rad']].values\n",
        "  db = DBSCAN(eps=eps, min_samples=min_samples, algorithm='ball_tree', metric='haversine')\n",
        "\n",
        "  db.fit(coords)\n",
        "\n",
        "  return db.labels_"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU_Co92uMDoL"
      },
      "source": [
        "# creating a dictionary of labels\n",
        "df1['labels'] = train_dbscan()\n",
        "db_labels = {port:cluster for port, cluster in zip(df1['port'], df1['labels'])}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxCo8-h_g9E8"
      },
      "source": [
        "def assign_ports(df):\n",
        "  \"\"\"\n",
        "  prepares a dataframe for port assignment by resampling  and filtering\n",
        "  it\n",
        "\n",
        "  params:\n",
        "  -----\n",
        "        df: pandas dataframe\n",
        "  \n",
        "  returns:\n",
        "  -------\n",
        "        df: processed pandas dataframe\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # resampling the data to standardize time intervals\n",
        "  df = df.resample('4H').mean()\n",
        "  df['isnan'] = df['lat'].isna().astype(int)\n",
        "  df['lat'] = df['lat'].interpolate(method='linear')\n",
        "  df['long'] = df['long'].interpolate(method='linear')\n",
        "  df['draft'] = df['draft'].ffill()\n",
        "  df = df.interpolate(method='linear')\n",
        "  df['lat_rad'] = np.radians(df['lat'])\n",
        "  df['long_rad'] = np.radians(df['long'])\n",
        "  df['heading1back'] = df['heading'].diff()\n",
        "  df['heading2back'] = df['heading'].diff(2)\n",
        "  df['heading1ahead'] = df['heading'].diff(-1)\n",
        "  df['heading2ahead'] = df['heading'].diff(-2)\n",
        "  # df['row_duration'] = (df.index.to_series().diff(-1)) / pd.Timedelta('1 hour')\n",
        "  df['lat_long'] = [[x,y] for x, y in zip(df['lat'], df['long'])]\n",
        "  df['lat_long_1back'] = df['lat_long'].shift()\n",
        "  df['vin_diff'] = df.apply(vincent_distance, axis=1)\n",
        "  df['vin_speed'] = (df['vin_diff'] * 0.539957) / 4\n",
        "\n",
        "  # determining whether a block contains or is adjacent to a change in draft\n",
        "  df['draft_delta_back'] = df['draft'].transform(lambda x: abs(x.diff()).ge(0.25)).astype(int)\n",
        "  df['draft_delta_ahead'] = df['draft'].transform(lambda x: abs(x.diff(-1)).ge(0.25)).astype(int)\n",
        "  df['draft_change'] = ((df['draft_delta_back'] + df['draft_delta_ahead']) >= 1).astype(int)\n",
        "  \n",
        "  # applying a mask to limit the rows the predict function is applied to\n",
        "  mask = ((df['vin_speed'] <5) | (df['draft_change'] > 1))\n",
        "  df_temp = df[mask]\n",
        "\n",
        "  df['pred_port'] = 0\n",
        "  df['kneigh_dist'] = 0\n",
        "  df.loc[mask, 'pred_port'] = df_temp.apply(nearest_port, axis=1)\n",
        "  df.loc[mask, 'kneigh_dist'] = df_temp.apply(nearest_distance, axis=1)\n",
        "  df['port_coords'] = [list(ports[k]) if k in ports else -99 for k in df['pred_port']]\n",
        "  df['bearing_port'] = [get_angle(x, y) if type(y) is list else np.nan for x, y in zip(df['lat_long'], df['port_coords'])]\n",
        "  df['heading_diff'] = abs(df['heading'] - df['bearing_port'])\n",
        "  df['heading_diff'] = np.where(df['heading_diff'] > 180, 360 - df['heading_diff'], df['heading_diff'])\n",
        "\n",
        "  # applying a mask to limit the rows vincenty func is applied to\n",
        "  vin_mask = (df['pred_port'] > 0)\n",
        "  vin_temp = df[vin_mask]\n",
        "  \n",
        "  df['port_dist'] = 0\n",
        "  df.loc[vin_mask, 'port_dist'] = vin_temp.apply(vincenty_port, axis=1)\n",
        "\n",
        "  # eliminating entries in sequences where max distance greatly differs from min\n",
        "  # indicates 'waiting to enter port'\n",
        "  df['pred_port_null'] = (df['pred_port'] > 0).astype(int)\n",
        "  df['kneigh_null'] = (df['kneigh_dist'] > 0).astype(int)\n",
        "  df['seq_port'] = df['pred_port'].diff().ne(0).cumsum()\n",
        "  df['seq_kneigh'] = df['kneigh_null'].diff().ne(0).cumsum()\n",
        "  df['sum_draft_change'] = df.groupby('seq_port')['draft_change'].transform(sum)\n",
        "  df['seq_count'] = df.groupby('seq_port')['seq_port'].transform('count')\n",
        "  df['dist_diff'] = df.groupby('seq_port')['port_dist'].transform(lambda x: x - x.min())\n",
        "  df['min_dist_for_seq'] = df.groupby('seq_port')['port_dist'].transform(lambda x: x.min())\n",
        "  df['min_speed_for_seq'] = df.groupby('seq_port')['vin_speed'].transform(lambda x: x.min())\n",
        "  df['nearest_port_dist'] = [[(v)[1] for v in close_ones[n].items()][0] if n in close_ones else 0 for n in df['pred_port']]\n",
        "  df['nearest_port_min'] = (df['port_dist'] > (df['nearest_port_dist']/2)).astype(int)\n",
        "  df['back_up_pred'] = df['pred_port']\n",
        "  # df['max_draft_change'] = [min_max[n][2] if n in min_max else 0 for n in df['pred_port']]\n",
        "  # df['dist_above_max'] = (df['port_dist'] > df['max_draft_change']).astype(int)\n",
        "  # df['pred_port'] = np.where(df['dist_above_max'] == 1, 0, df['pred_port'])\n",
        "\n",
        "\n",
        "  # getting the prior port\n",
        "  df['prior_port'] = get_prior_port(df)\n",
        "\n",
        "  # calcing distance from prior port\n",
        "  df['dist_last_port'] = [vincenty(l, ports[p]) if p>0 else 0 for l, p in zip(df['lat_long'], df['prior_port'])]\n",
        "\n",
        "  condition = ((df['port_dist'] > 20) & (df['vin_speed'] >1) & (df['dist_last_port'] <1000))\n",
        "  df.loc[condition, 'pred_port'] = 0\n",
        "\n",
        "  testcondition = ((df['pred_port']).isin(really_close) & (df['port_dist'] >1))\n",
        "  df.loc[testcondition, 'pred_port'] = 0\n",
        "\n",
        "  condition2 = ((df['pred_port'].isin(close_ones)) & (df['vin_speed'] > 2))\n",
        "  df.loc[condition2, 'pred_port'] = 0\n",
        "\n",
        "  condition3 = (df['seq_count'] <2)\n",
        "  df.loc[condition3, 'pred_port'] = 0\n",
        "\n",
        "  condition4 = ((df['pred_port'] == 54) & (df['min_dist_for_seq'] >8))\n",
        "  df.loc[condition4, 'pred_port'] = 0\n",
        "\n",
        "  condition5 = ((df['pred_port'] == 115) & (df['min_dist_for_seq'] > 9))\n",
        "  df.loc[condition5, 'pred_port'] = 0\n",
        "\n",
        "  condition6 = ((df['pred_port'] == 99) & (df['port_dist'] >10))\n",
        "  df.loc[condition6, 'pred_port'] = 0\n",
        "\n",
        "  condition7 = (df['min_dist_for_seq'] > 40)\n",
        "  df.loc[condition7, 'pred_port'] = 0\n",
        "\n",
        "  condition8 = ((df['pred_port'] == 34) & (df['sum_draft_change'] >0 ))\n",
        "  df.loc[condition8, 'pred_port'] = 0\n",
        "\n",
        "  df['pred_port'] = np.where(df['dist_diff'] >= 15, 0, df['pred_port']) \n",
        "\n",
        "  # recasting vessel and pred_port columns as integers\n",
        "  df[['vessel', 'pred_port']] = df[['vessel', 'pred_port']].astype(int)\n",
        "\n",
        "\n",
        "  return df"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDnoQ4hnfhce"
      },
      "source": [
        "def get_voyages(df):\n",
        "  \"\"\"\n",
        "  converts the port sequences in each dataframe into voyages\n",
        "  with the proper formatting\n",
        "\n",
        "  param:\n",
        "  -----\n",
        "      df: pandas DataFrame\n",
        "  \n",
        "  returns:\n",
        "  -------\n",
        "      df: processed pandas DataFrame\n",
        "      \n",
        "  \"\"\"\n",
        "  # filtering out columns without an assigned port\n",
        "  nz = df[(df['pred_port'] > 0) | (df['pred_port'] == -75)].reset_index()\n",
        "\n",
        "  vessel = nz['vessel'][0]\n",
        "  dt = nz['datetime']\n",
        "  pred = nz['pred_port']\n",
        "\n",
        "  records = []\n",
        "\n",
        "  for i in range(len(dt)-1):\n",
        "    if pred[i] != pred[i+1]:\n",
        "      start_port = pred[i]\n",
        "      end_port = pred[i+1]\n",
        "      begin_date = dt[i]\n",
        "      end_date = dt[i+1]\n",
        "      records.append([vessel, begin_date, end_date, start_port, end_port])\n",
        "\n",
        "  df = pd.DataFrame.from_records(records, columns = ['vessel', 'begin_date', 'end_date', 'begin_port_id', 'end_port_id'])\n",
        "  \n",
        "  return df"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jydaj-qScpp"
      },
      "source": [
        "def get_prior_port(df):\n",
        "  \"\"\"\n",
        "  iterate through the each vessel's predicted ports to get the last predicted\n",
        "  port\n",
        "  \"\"\"\n",
        "\n",
        "  p = df['pred_port'][::-1].values\n",
        "\n",
        "  prior_ports = []\n",
        "\n",
        "  for i in range(len(p)):\n",
        "    s = p[i]\n",
        "    for n in p[i:]:\n",
        "      if (s != n) & (n >0) :\n",
        "       prior_ports.append(n)\n",
        "       break\n",
        "\n",
        "# padding zeros at the end to indicate no next port \n",
        "  zeroes = [0] * (len(p) - len(prior_ports))\n",
        "  prior_ports = prior_ports + zeroes\n",
        "  \n",
        "  prior_ports = prior_ports[::-1]\n",
        "  \n",
        "  return prior_ports "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4gOeftL1KN0"
      },
      "source": [
        "def get_angle(loc1=[1.2, 103], loc2=[99.5,-32]):\n",
        "  \"\"\"\n",
        "  get the angle of the bearing needed to directly approach the nearest port.\n",
        "  running out of ideas!\n",
        "\n",
        "  parameters\n",
        "  ----------\n",
        "        lists: lat, longitude of ship (in dict as such)\n",
        "\n",
        "  returns\n",
        "  -------\n",
        "        float: bearing in degrees with 0 as due North\n",
        "  \"\"\"\n",
        "  \n",
        "  dLon = (loc2[1] - loc1[1])\n",
        "\n",
        "  y = math.sin(dLon) * math.cos(loc2[0])\n",
        "  x = math.cos(loc1[0]) * math.sin(loc2[0]) - math.sin(loc1[0]) * math.cos(loc2[0]) * math.cos(dLon)\n",
        "\n",
        "  brng = math.atan2(y, x)\n",
        "\n",
        "  brng = math.degrees(brng)\n",
        "  brng = (brng + 360) % 360\n",
        "  brng = 360 - brng # count degrees clockwise - remove to make counter-clockwise\n",
        "\n",
        "  return brng"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbHcYBVQcWst"
      },
      "source": [
        "# calculating the distance between each row using the vincenty function above.\n",
        "# note it only calcs within each vessel group (see function). the elapsed time\n",
        "# and the total distance travelled implies a speed and that speed allows for\n",
        "# effetcive filtering of impossible routes\n",
        "\n",
        "df2['vin_diff'] = df2.apply(vincent_distance, axis=1)\n",
        "df2['vin_per_hour'] = df2['vin_diff'] / df2['hour_delta']\n",
        "df2 = df2.query('vin_per_hour <= 50')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9tCbNDQiRfQ"
      },
      "source": [
        "# creating a dictionary of vessel dataframes with a datetime index\n",
        "\n",
        "vessel_dfs = {}\n",
        "\n",
        "for vessel in df2.vessel.unique():\n",
        "  df_ = df2[df2['vessel'] == vessel]\n",
        "  vessel_dfs[vessel] = df_.set_index('datetime')\n",
        "\n",
        "# assigning ports to each dataframe\n",
        "processed_dfs = {key:assign_ports(vessel_dfs[key]) for key in vessel_dfs.keys()}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRvtlQfvHvpc"
      },
      "source": [
        "alldf = pd.concat(processed_dfs)\n",
        "alldf = alldf.droplevel(0)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_TnV_EudLEQ"
      },
      "source": [
        "# creating a dictionary of dataframes for each port and then extracting the min,\n",
        "# max, and max_draft distances for assigned ports\n",
        "\n",
        "ports_dfs = {}\n",
        "\n",
        "for port in alldf.pred_port.unique():\n",
        "  ports_dfs[port] = alldf[alldf['pred_port'] == port]\n",
        "\n",
        "# del ports_dfs[-1]\n",
        "del ports_dfs[0]\n",
        "\n",
        "min_max = {}\n",
        "\n",
        "for df in ports_dfs.keys():\n",
        "  draft_max = ports_dfs[df].query('draft_change >=1').port_dist.max()\n",
        "  min_max[df] = [ports_dfs[df]['port_dist'].max(), ports_dfs[df]['port_dist'].min(), draft_max]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_P8jbtr994d"
      },
      "source": [
        "# using the minimum distances from above to add another filter\n",
        "\n",
        "for df in processed_dfs.keys():\n",
        "  df_ = processed_dfs[df]\n",
        "  df_['min_dist'] = [min_max[n][1] if n in min_max else 0 for n in df_['pred_port']]\n",
        "  df_['max_draft_change'] = [min_max[n][2] if n in min_max else 0 for n in df_['pred_port']]\n",
        "  df_['dist_above_min'] = df_['min_dist_for_seq'] - df_['min_dist']\n",
        "  df_['dist_above_max'] = (df_['port_dist'] > df_['max_draft_change']).astype(int)\n",
        "  df_['pred_port'] = np.where(df_['dist_above_max'] == 1, 0, df_['pred_port'])\n",
        "  test = ((df_['sum_draft_change'] <1) & (df_['dist_above_min'] > 35))\n",
        "  df_['pred_port'] = np.where(test, 0, df_['pred_port'])\n",
        "  processed_dfs[df] = df_\n",
        "  "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmb6rhNEWGZ_"
      },
      "source": [
        "alldf = pd.concat(processed_dfs)\n",
        "alldf = alldf.droplevel(0)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SIs4v7TvD-a"
      },
      "source": [
        "voyages_df = pd.concat([get_voyages(processed_dfs[key]) for key in processed_dfs.keys()])\n",
        "voyages_df['begin_date'] = voyages_df['begin_date'].dt.date\n",
        "voyages_df['end_date'] = voyages_df['end_date'].dt.date\n",
        "voyages_df['len_voyage'] = voyages_df['end_date'] - voyages_df['begin_date']\n",
        "voyages_df['begin_coords'] = [ports[key] for key in voyages_df['begin_port_id']]\n",
        "voyages_df['end_coords'] = [ports[key] for key in voyages_df['end_port_id']]\n",
        "voyages_df['voyage_dist'] = [vincenty(x, y) for x, y in zip(voyages_df['begin_coords'], voyages_df['end_coords'])]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd0hoOmBHd7c",
        "outputId": "00cd1b52-04af-44b8-f7f4-62dc37dccc05"
      },
      "source": [
        "voyages_df.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3120, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF-vL7n3WKGb"
      },
      "source": [
        "def prepare_data(df, n_input = 3):\n",
        "  \"\"\"\n",
        "  preparing the sequences for window based models\n",
        "  \"\"\"\n",
        "\n",
        "  df = get_voyages(df)\n",
        "  vessel = df['vessel'].iloc[0]\n",
        "  ports_ = np.array(df['begin_port_id'].append(pd.Series(df['end_port_id'].iloc[-1])))  \n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "  start = 0\n",
        "\n",
        "  for i in range(len(ports_)):\n",
        "    last_input = start + n_input\n",
        "    last_output = last_input + 3\n",
        "    if last_output <= len(ports_):\n",
        "      x = ports_[start:last_input]\n",
        "      y = ports_[last_input: last_output]\n",
        "      X.append(x)\n",
        "      Y.append(y)\n",
        "      start += 1\n",
        "  try:\n",
        "    df = pd.concat([pd.DataFrame(X),\n",
        "                  pd.DataFrame(Y, columns=['port_1ahead', 'port_2ahead', 'port_3ahead'])], axis=1)\n",
        "    \n",
        "  except:\n",
        "    df = pd.DataFrame()\n",
        "    \n",
        "  # X = []\n",
        "\n",
        "  # for x in X:\n",
        "  #   for n in x:\n",
        "  #     if n == -75:\n",
        "  #       port_coords = [33, 140]\n",
        "  #     else:\n",
        "  #       port_coords = list(ports[n])\n",
        "  #     port = [n]\n",
        "  #     port.extend(port_coords)\n",
        "  #     new_X.append(port)\n",
        "  \n",
        "  df['vessel'] = len(df) * [vessel]\n",
        "  \n",
        "  return df.astype(int)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtTQNF2qY-RB"
      },
      "source": [
        "def build_model(target='port_1ahead', min_samples=1, n_back = 3):\n",
        "\n",
        "  model_df = pd.concat([prepare_data(processed_dfs[key], n_back) for key in processed_dfs.keys()]) \n",
        "\n",
        "  model_df['cluster_1back'] = [db_labels[n] for n in model_df[0]]\n",
        "  model_df['cluster_2back'] = [db_labels[n] for n in model_df[1]]\n",
        "  model_df['cluster_3back'] = [db_labels[n] for n in model_df[2]]\n",
        "\n",
        "  model_df['samples'] = model_df.groupby('vessel')['vessel'].transform(lambda x: x.count())\n",
        "  filtered_df = model_df.query('samples > @min_samples')\n",
        "\n",
        "  vessels_excluded = set(model_df['vessel'].unique()).difference(set(filtered_df['vessel'].unique()))\n",
        "\n",
        "  features = [n for n in range(n_back)] + ['cluster_1back', 'cluster_2back', 'cluster_3back'] \n",
        "  target = target\n",
        "\n",
        "  X = filtered_df[features]\n",
        "  y = filtered_df[target]\n",
        "  model = XGBClassifier()\n",
        "\n",
        "  param_grid = {\n",
        "      'learning_rate': [0.1, 0.2, 0.3]\n",
        "  }\n",
        "\n",
        "  grid_search = GridSearchCV(model, param_grid, cv=3)\n",
        "  grid_result = grid_search.fit(X, y)\n",
        "\n",
        "  print('The training excluded vessels:', vessels_excluded)\n",
        "  print('The best model params were:', grid_result.best_params_)\n",
        "  print('The best accuracy achieved was:', grid_result.best_score_)\n",
        "  \n",
        "  return grid_result"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtEHbOIdTCDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1be56e-0087-4345-e928-622aaa1f999f"
      },
      "source": [
        "model_1ahead = build_model(target='port_1ahead', min_samples=2, n_back=3)\n",
        "model_2ahead = build_model(target='port_2ahead', min_samples=2, n_back=3)\n",
        "model_3ahead = build_model(target='port_3ahead', min_samples=2, n_back=3)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The training excluded vessels: {66, 133, 107, 85, 125}\n",
            "The best model params were: {'learning_rate': 0.1}\n",
            "The best accuracy achieved was: 0.39081964551206916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The training excluded vessels: {66, 133, 107, 85, 125}\n",
            "The best model params were: {'learning_rate': 0.1}\n",
            "The best accuracy achieved was: 0.3566810268276222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The training excluded vessels: {66, 133, 107, 85, 125}\n",
            "The best model params were: {'learning_rate': 0.1}\n",
            "The best accuracy achieved was: 0.3040233821984747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5ERpuNpF_WT"
      },
      "source": [
        "def get_pred_data(df, n_input = 3):\n",
        "  \"\"\"\n",
        "  preparing the sequences for predictions with the XGBClassifier model\n",
        "  \"\"\"\n",
        "\n",
        "  df = get_voyages(df)\n",
        "  vessel = df['vessel'].iloc[0]\n",
        "  ports_ = np.array(df['begin_port_id'].append(pd.Series(df['end_port_id'].iloc[-1])))\n",
        "  \n",
        "  pred_seq = ports_[-n_input:]\n",
        "\n",
        "  if len(pred_seq) < n_input:\n",
        "    pred_seq = np.insert(pred_seq, 0, pred_seq[-1])\n",
        "  \n",
        "  return pred_seq"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NlGujqAv2FW"
      },
      "source": [
        "# creating a dictionary with the most recent ports visited for each vessel\n",
        "\n",
        "window_data = {key:get_pred_data(processed_dfs[key], n_input=3) for key in processed_dfs.keys()}"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJkGCyNIwvvS"
      },
      "source": [
        "# creating a dataframe with the features used in the models\n",
        "\n",
        "sub = pd.DataFrame.from_dict(window_data, orient='index')\n",
        "\n",
        "sub['cluster_1back'] = [db_labels[n] for n in sub[0]]\n",
        "sub['cluster_2back'] = [db_labels[n] for n in sub[1]]\n",
        "sub['cluster_3back'] = [db_labels[n] for n in sub[2]]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i6_80Y91LAe"
      },
      "source": [
        "# predicting the next port. also including the second most likely port in case\n",
        "# the model predicts duplicates. \n",
        "\n",
        "port_1 = model_1ahead.predict(sub)\n",
        "port_2 = model_2ahead.predict(sub)\n",
        "port_2_alt = [model_2ahead.best_estimator_.classes_[np.argsort(n)[-2]] for n in model_2ahead.predict_proba(sub)]\n",
        "port_3 = model_3ahead.predict(sub)\n",
        "port_3_alt = [model_3ahead.best_estimator_.classes_[np.argsort(n)[-2]] for n in model_3ahead.predict_proba(sub)]\n",
        "sub['port_1ahead'] = port_1\n",
        "sub['port_2ahead'] = port_2\n",
        "sub['port_2ahead_2nd'] = port_2_alt\n",
        "sub['port_3ahead'] = port_3\n",
        "sub['port_3ahead_2nd'] = port_3_alt"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VJNB5MI0E0a"
      },
      "source": [
        "# using conditional assignment to replace port predictions with the second most\n",
        "# likely\n",
        "\n",
        "sub.loc[sub['port_1ahead'] == sub['port_2ahead'], 'port_2ahead'] = sub['port_2ahead_2nd']\n",
        "sub.loc[sub['port_2ahead'] == sub['port_3ahead'], 'port_3ahead'] = sub['port_3ahead_2nd']"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3SrpcaTKtDo"
      },
      "source": [
        "# changing the shape of the dataframe so it conforms to what's required\n",
        "\n",
        "# resetting the index and renaming the column\n",
        "sub = sub.reset_index()\n",
        "sub.rename(columns={'index':'vessel'}, inplace=True)\n",
        "\n",
        "# limiting columns to those required and renaming\n",
        "sub = sub[['vessel', 2, 'port_1ahead', 'port_2ahead', 'port_3ahead']]\n",
        "sub.rename(columns={2:'final_port'}, inplace=True)\n",
        "\n",
        "# using melt to narrow the DataFrame and put the voyages into the same column\n",
        "sub = pd.melt(sub, id_vars='vessel').sort_values(by=['vessel', 'variable'])\n",
        "sub['end_port_id'] = sub.groupby('vessel')['value'].transform(lambda x: x.shift(-1))\n",
        "sub = sub.dropna()\n",
        "\n",
        "# adding a voyage count, more renaming\n",
        "sub['voyage'] = sub.groupby('vessel').cumcount()+1\n",
        "sub.rename(columns={'value' : 'begin_port_id'}, inplace=True)\n",
        "sub.drop(columns=['variable'], inplace=True)\n",
        "sub['end_port_id'] = sub['end_port_id'].astype(int)\n",
        "sub = sub.reset_index(drop=True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "Pu1EubeDfaNt",
        "outputId": "c09c399e-6b1c-47f4-ee9a-8fcbe20e4b7a"
      },
      "source": [
        "sub.head(3)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vessel</th>\n",
              "      <th>begin_port_id</th>\n",
              "      <th>end_port_id</th>\n",
              "      <th>voyage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>95</td>\n",
              "      <td>138</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>138</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>138</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   vessel  begin_port_id  end_port_id  voyage\n",
              "0       1             95          138       1\n",
              "1       1            138           27       2\n",
              "2       1             27          138       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_6avCrtDDhQ"
      },
      "source": [
        "Creating an LSTM model to predict the future voyages. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1wikN3M42_m"
      },
      "source": [
        "# creating a dataset to train the LSTM model. i had to do a bit of troubleshooting,\n",
        "# hence the try/except\n",
        "\n",
        "lstm_data = []\n",
        "\n",
        "for i in processed_dfs.keys():\n",
        "  try:\n",
        "    x = prepare_data(processed_dfs[i], n_input=6)\n",
        "    lstm_data.append(x)\n",
        "  except:\n",
        "    print(i)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj9dvByke8iK"
      },
      "source": [
        "# a dictionary to encode the ports for the model\n",
        "\n",
        "encoder = {key:value for key, value in zip(df1['port'], df1.index)}"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWPWg-FVSLyH"
      },
      "source": [
        "# concatenating the LSTM data\n",
        "lstm_df = pd.concat(lstm_data)\n",
        "\n",
        "# defining the number of ports\n",
        "total_ports = len(encoder.keys())\n",
        "\n",
        "# slicing off the feature array\n",
        "X = lstm_df[[0, 1, 2, 3, 4, 5]]\n",
        "\n",
        "# encoding each port to create a \"vocabulary\" of ports starting at index 0\n",
        "for col in X.columns:\n",
        "  X.loc[:,col] = X[col].map(encoder)\n",
        "\n",
        "# creating the target array with shape (samples, 3, 1) and converting to category\n",
        "y = lstm_df[['port_1ahead', 'port_2ahead', 'port_3ahead']]\n",
        "y = to_categorical(y)\n",
        "\n",
        "# train and test split to validate model during training - could use 'validation_split' in .fit()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1944)\n",
        "\n",
        "# initializing the Sequential class\n",
        "model = Sequential()\n",
        "\n",
        "# adding an embedding layer to embed each port in a 3 dimensional space\n",
        "model.add(Embedding(total_ports, 3, input_length=6))\n",
        "\n",
        "# adding an LSTM layer to process the embedded vector sequences\n",
        "model.add(LSTM(100, activation='relu', return_sequences=False))\n",
        "\n",
        "# adding a crucial layer to allows the output sequence to be of a diff length\n",
        "model.add(RepeatVector(3))\n",
        "\n",
        "# another LSTM layer, this one repeating the sequence\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
        "\n",
        "# model.add(Dense(50, activation='relu'))                                  <-------- layer i added/subtracted\n",
        "\n",
        "# adding a TimeDistributed Dense layer to output predictions. note the # of \n",
        "# categories is not 'efficient' but it does make decoding the prediction take one\n",
        "# fewer step\n",
        "\n",
        "model.add(TimeDistributed(Dense(179, activation='softmax')))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoIgnQNPV0V4"
      },
      "source": [
        "# fitting the model with early stopping\n",
        "\n",
        "history = model.fit(X_train,y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=32,\n",
        "                    epochs=250,\n",
        "                    callbacks=EarlyStopping(monitor='val_accuracy',\n",
        "                                            patience=30,\n",
        "                                            restore_best_weights=True));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1D1OdzHisXW"
      },
      "source": [
        "lstm_window = {key:get_pred_data(processed_dfs[key], n_input=6) for key in processed_dfs.keys()}"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBLlbXF6lqyi"
      },
      "source": [
        "# getting the sequences and encoding them so the model can use them as inputs\n",
        "seq_for_pred = np.array([[encoder[j] for j in n] for n in lstm_window.values()])\n",
        "\n",
        "# padding the sequences with fewer than 6 \n",
        "seq_for_pred = pad_sequences(seq_for_pred, maxlen=6, value=0)\n",
        "\n",
        "# predicting the next 3 ports visited\n",
        "preds = model.predict(seq_for_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBQApzdGwu1q"
      },
      "source": [
        "# assigning the predictions and back-up predictions to variables. if a port\n",
        "# repeats, i replace it with the second most likely\n",
        "first_port = pd.Series([np.argmax(n[0]) for n in preds])\n",
        "second_port = pd.Series([np.argmax(n[1]) for n in preds])\n",
        "alt_second = pd.Series([np.argsort(n[1])[-2] for n in preds])\n",
        "third_port = pd.Series([np.argmax(n[2]) for n in preds])\n",
        "alt_third = pd.Series([np.argsort(n[2])[-2] for n in preds])"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOqRO78LoVr6"
      },
      "source": [
        "# creating a dataframe of the above\n",
        "last_port = pd.Series(seq_for_pred[:,-1])\n",
        "lstm_pred = pd.concat([last_port, first_port, second_port, alt_second, third_port, alt_third], axis=1)\n",
        "lstm_pred.index = window_data.keys()\n",
        "lstm_pred = lstm_pred.reset_index()\n",
        "lstm_pred.columns = ['vessel', 'last_port', 'pred1', 'pred2', 'alt2', 'pred3', 'alt3']\n",
        "lstm_pred['pred2'] = np.where(lstm_pred['pred1'] == lstm_pred['pred2'], lstm_pred['alt2'], lstm_pred['pred2'])\n",
        "lstm_pred['pred3'] = np.where(lstm_pred['pred2'] == lstm_pred['pred3'], lstm_pred['alt3'], lstm_pred['pred3'])\n",
        "lstm_pred.drop(columns=['alt2', 'alt3'], inplace=True)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPZZ6EX_ANdP"
      },
      "source": [
        "reverse_encoder = {v:k for k, v in encoder.items()}\n",
        "lstm_pred['last_port'] = lstm_pred['last_port'].map(reverse_encoder)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGyKkzQgrbAT"
      },
      "source": [
        "lstm_pred = pd.melt(lstm_pred, id_vars='vessel').sort_values(by=['vessel', 'variable'])\n",
        "\n",
        "lstm_pred['end_port_id'] = lstm_pred.groupby('vessel')['value'].transform(lambda x: x.shift(-1))\n",
        "lstm_pred.dropna(inplace=True)\n",
        "lstm_pred.drop(columns='variable', inplace=True)\n",
        "lstm_pred.rename(columns={'value':'begin_port_id'}, inplace=True)\n",
        "lstm_pred['voyage'] = lstm_pred.groupby('vessel').cumcount()+1\n",
        "lstm_pred = lstm_pred.astype(int).reset_index(drop=True)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksfEgenhtQJs"
      },
      "source": [
        "# i think i'm messing up, but the XGB model is fine - review this\n",
        "lstm_pred.head(25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lipU-tqdU_Va"
      },
      "source": [
        "sub.to_csv('predict.csv', index=False)\n",
        "lstm_pred.to_csv('lstm_predict.csv', index=False)\n",
        "voyages_df.to_csv('voyages.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd_OvZ0lenDm"
      },
      "source": [
        "def show_routes(vessel=1, start='2019-01-01', end='2019-12-28'): \n",
        "  df_ = alldf.query(f'vessel == {vessel}')\n",
        "\n",
        "  fig = px.scatter_geo(df_.loc[start: end], lat='lat', lon='long', color='draft',\n",
        "                       hover_name=df_.loc[start: end].index)\n",
        "\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCU2YOfOdJda"
      },
      "source": [
        "def draft_and_voyages(vessel=103):\n",
        "\n",
        "  df = alldf.query(f'vessel == {vessel}')\n",
        "  \n",
        "  in_port = df[df['pred_port'] > 0].index\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(20,5))\n",
        "  \n",
        "  df[['port_dist', 'draft']].plot(ax=ax)\n",
        "  \n",
        "  for p in in_port:\n",
        "    plt.axvline(p, ls='--', lw=0.5, c='r', label='port')\n",
        "  \n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-KDUEhEJzCF"
      },
      "source": [
        "imp_cols = ['vessel', 'lat_long', 'draft', 'vin_diff', 'vin_speed', 'isnan', 'pred_port', 'draft_change', 'sum_draft_change', 'port_dist', 'sum_draft_change']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDVWJpvbbyhD"
      },
      "source": [
        "voyages_df[voyages_df['len_voyage'] < '3 days']['vessel'].value_counts().sort_values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFvc84oLq_js"
      },
      "source": [
        "alldf.groupby(['vessel', 'seq_kneigh']).agg({'draft': ['first', 'last'],\n",
        "                                             'pred_port' : 'median',\n",
        "                                             'heading' : ['first', 'last'],\n",
        "                                             'port_dist' : 'min',\n",
        "                                             'vin_speed' : 'min'}).head(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaJRHeILKvRB"
      },
      "source": [
        "print(alldf.query('isnan == 1 & pred_port > 0')[imp_cols].to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dajdwxDMQ4bI"
      },
      "source": [
        "alldf.query('pred_port == 115 & isnan == 1')['vessel'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY-J79oIREb9"
      },
      "source": [
        "print(alldf.query('vessel == 165')[imp_cols].to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a4zWI2oQms2"
      },
      "source": [
        "print(alldf.query('vessel == 1')[imp_cols].to_string())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}