{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sym_cargo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bTzsC2_o8Jg772hCJWDRqrHnkqeQuRQx",
      "authorship_tag": "ABX9TyNwpBZVfm1gNQYS5g0UHm+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaobviously/sym-cargo/blob/main/sym_cargo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRudeILZCNAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d8f63b-ca4e-4a43-ae43-439b4df3a72b"
      },
      "source": [
        "!pip install plotly-express --quiet\n",
        "!pip install vincenty --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for vincenty (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrMMphhGyTIp"
      },
      "source": [
        "I'll clean up this repo and provide visualizations and the requirements.txt file later this week. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFygxcBXBsUT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.cluster import DBSCAN\n",
        "from xgboost import XGBClassifier\n",
        "from vincenty import vincenty\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import plotly_express as px"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERdgnPI_B8xV"
      },
      "source": [
        "port_file = '/content/drive/MyDrive/Ports/ports.csv'\n",
        "tracking_file = '/content/drive/MyDrive/Ports/tracking.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGQ3oW9dCGF6"
      },
      "source": [
        "def wrangle():\n",
        "  \n",
        "  df1 = pd.read_csv(port_file)\n",
        "\n",
        "  # converting lat and long to radians to compute haversine distance\n",
        "  df1['lat_rad'] = np.radians(df1['lat'])\n",
        "  df1['long_rad'] = np.radians(df1['long'])\n",
        "  \n",
        "  # rounding lat and long in port df\n",
        "  df1['lat'] = df1['lat'].round(1)\n",
        "  df1['long'] = df1['long'].round(1)\n",
        "\n",
        "  df2 = pd.read_csv(tracking_file, parse_dates=['datetime'])\n",
        "  df2 = df2.drop_duplicates()\n",
        "  df2 = df2.sort_values(['vessel', 'datetime'])\n",
        "  df2['vessel_1back'] = df2['vessel'].shift()\n",
        "  \n",
        "  # converting lat and long to radians to compute haversine distance  \n",
        "  df2['lat_rad'] = np.radians(df2['lat'])\n",
        "  df2['long_rad'] = np.radians(df2['long'])\n",
        "\n",
        "  # adding lat/long column and lat/long 1 back to later compute delta\n",
        "  df2['lat_long'] = [[x,y] for x, y in zip(df2['lat'], df2['long'])]\n",
        "  df2['lat_long_1back'] = df2.groupby('vessel')['lat_long'].transform(lambda x: x.shift())\n",
        "  \n",
        "  # time deltas to compute impossible distances travelled\n",
        "  df2['time_delta'] = df2.groupby('vessel')['datetime'].transform(lambda x: x - x.shift(1))\n",
        "  df2['hour_delta'] = df2['time_delta'].apply(lambda x: x.seconds / 3600)\n",
        "\n",
        "  # filtering using query to eliminate unneeded/impossible values\n",
        "  df2 = df2.query('hour_delta > 0.25 & speed <30 & heading <=360 & draft < 12.5')\n",
        "  df2 = df2.reset_index(drop=True)\n",
        "\n",
        "  return df1, df2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZJrWQ6eCIqV"
      },
      "source": [
        "df1, df2 = wrangle()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tL74j_2a7LR"
      },
      "source": [
        "def vincent_distance(row):\n",
        "  \"\"\" \n",
        "  returns the vincenty distance for contiguous rows - will be used to identify\n",
        "  impossible distances travelled, and so on. could be used to create distance\n",
        "  matrix, but this may not be worthwhile \n",
        "  \"\"\"\n",
        "  if row['vessel'] != row['vessel_1back']:\n",
        "    return -99\n",
        "\n",
        "  loc1 = row['lat_long']\n",
        "  loc2 = row['lat_long_1back']\n",
        "\n",
        "  try:\n",
        "    distance = vincenty(loc1, loc2)\n",
        "    return distance\n",
        "  except:\n",
        "    return -99"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1P_JxyybKHc"
      },
      "source": [
        "# creating a dictionary of ports with their lat and longs - will be used to\n",
        "# repeatedly to explore data and assign values\n",
        "\n",
        "ports = {port:(lat, long) for port, lat, long in zip(df1['port'], df1['lat'], df1['long'])}\n",
        "\n",
        "# a dictionary to retrieve the port id from the index\n",
        "idx_ports = {idx:port for idx, port in zip(df1.index, df1.port)}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rg5F1xcTElh",
        "outputId": "2e1a707f-044b-4963-f8f0-f2a53299ff0c"
      },
      "source": [
        "# training a nearest neighbor model to  find the closest port when the \n",
        "# conditions indicating an extended stop have occurred. the metric is haversine\n",
        "# in order to compute the 'great circle' distance. so i don't forget, the model\n",
        "# returns the *index* of the port, not the port's identifying label\n",
        "\n",
        "ports_train = df1[['lat_rad', 'long_rad']]\n",
        "\n",
        "neigh_ports = NearestNeighbors(n_neighbors=3, algorithm='ball_tree', metric='haversine')\n",
        "neigh_ports.fit(ports_train)\n",
        "\n",
        "dist, n = neigh_ports.kneighbors(np.array([0.677565, 0.469731]).reshape(1,-1))\n",
        "\n",
        "print(dist[0] * 6370)\n",
        "print([idx_ports[n] for n in n[0]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  3.30931026  46.44757565 255.13837716]\n",
            "[82, 113, 44]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC92dd_FI7MT"
      },
      "source": [
        "def nearest_port(df, radius=0.01):\n",
        "  \"\"\"\n",
        "  returns the port identifier of the nearest port using the nearest neighbors\n",
        "  model \n",
        "  \"\"\"\n",
        "\n",
        "  data = np.array([df['lat_rad'], df['long_rad']]).reshape(1, -1)\n",
        "  dist, pred = neigh_ports.radius_neighbors(data, radius=radius, sort_results = True) \n",
        "\n",
        "  if len(dist[0]) == 0:\n",
        "    return -1\n",
        "  \n",
        "  else:\n",
        "    return idx_ports[pred[0][0]]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2cHgfSNZbx2"
      },
      "source": [
        "def nearest_distance(df, radius=0.0125):\n",
        "  \"\"\"\n",
        "  returns the distance of the nearest port in the dataset\n",
        "  \"\"\"\n",
        "  \n",
        "  data = np.array([df['lat_rad'], df['long_rad']]).reshape(1, -1)\n",
        "  dist, pred = neigh_ports.radius_neighbors(data, radius=radius, sort_results = True) \n",
        "\n",
        "  if len(dist[0]) == 0:\n",
        "    return -1\n",
        "  \n",
        "  else:\n",
        "    return dist[0][0]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoYZuM6lqJIa"
      },
      "source": [
        "def vincenty_port(row):\n",
        "  \"\"\"\n",
        "  a function that computes the vincenty distance between the assigned port\n",
        "  and the latitude and longitude of the location data\n",
        "  \"\"\"\n",
        "  port = row['port_coords']\n",
        "  loc = row['lat_long']\n",
        "  return vincenty(port, loc)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLCHF2I5CII2"
      },
      "source": [
        "def train_dbscan(df=df1, eps=0.1, min_samples=2):\n",
        "  \"\"\"\n",
        "  use the dbscan clustering algorithm to find groupss of ports\n",
        "\n",
        "  params\n",
        "  ------\n",
        "      df: pandas df\n",
        "      eps: min distance between points in cluster\n",
        "      min_samples: min members in a cluster\n",
        "\n",
        "  returns\n",
        "  -------\n",
        "      labels: labels matching index of long/lat input pairs\n",
        "  \"\"\"\n",
        "  \n",
        "  coords = df[['long_rad', 'lat_rad']].values\n",
        "  db = DBSCAN(eps=eps, min_samples=min_samples, algorithm='ball_tree', metric='haversine')\n",
        "\n",
        "  db.fit(coords)\n",
        "\n",
        "  return db.labels_"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU_Co92uMDoL"
      },
      "source": [
        "# creating a dictionary of labels\n",
        "df1['labels'] = train_dbscan()\n",
        "db_labels = {port:cluster for port, cluster in zip(df1['port'], df1['labels'])}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxCo8-h_g9E8"
      },
      "source": [
        "def assign_ports(df):\n",
        "  \"\"\"\n",
        "  prepares a dataframe for port assignment by resampling  and filtering\n",
        "  it\n",
        "\n",
        "  params:\n",
        "  -----\n",
        "        df: pandas dataframe\n",
        "  \n",
        "  returns:\n",
        "  -------\n",
        "        df: processed pandas dataframe\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # resampling the data to standardize time intervals\n",
        "  df = df.resample('4H').mean().ffill()\n",
        "  df['lat_rad'] = df['lat_rad'].resample('4H').median().ffill()\n",
        "  df['long_rad'] = df['long_rad'].resample('4H').median().ffill()\n",
        "  \n",
        "  # applying a mask to limit the rows the predict function is applied to\n",
        "  mask = (df['speed'] <= 5)\n",
        "  df_temp = df[mask]\n",
        "\n",
        "  df['pred_port'] = 0\n",
        "  df.loc[mask, 'pred_port'] = df_temp.apply(nearest_port, axis=1)  \n",
        "  df['port_coords'] = [list(ports[k]) if k in ports else -99 for k in df['pred_port']]\n",
        "  df['lat_long'] = [[x,y] for x, y in zip(df['lat'], df['long'])]\n",
        "\n",
        "  # applying a mask to limit the rows vincenty func is applied to\n",
        "  vin_mask = (df['pred_port'] > 0)\n",
        "  vin_temp = df[vin_mask]\n",
        "  \n",
        "  df['port_dist'] = 0\n",
        "  df.loc[vin_mask, 'port_dist'] = vin_temp.apply(vincenty_port, axis=1)\n",
        "\n",
        "  # eliminating entries in sequences where max distance greatly differs from min\n",
        "  # indicates 'waiting to enter port'\n",
        "  df['seq'] = df['pred_port'].diff().ne(0).cumsum()\n",
        "  df['seq_count'] = df.groupby('seq')['seq'].transform('count')\n",
        "  df['dist_diff'] = df.groupby('seq')['port_dist'].transform(lambda x: x - x.min())\n",
        "  df['pred_port'] = np.where(df['dist_diff'] >= 15, 0, df['pred_port'])     # 15km away from closest point this trip to the port \n",
        "\n",
        "  # determining whether a block contains or is adjacent to a change in draft\n",
        "  df['draft_delta_back'] = df['draft'].transform(lambda x: abs(x.diff()).ge(0.5))\n",
        "  df['draft_delta_ahead'] = df['draft'].transform(lambda x: abs(x.diff(-1)).ge(0.5))\n",
        "  df['sum_draft_back'] = df.groupby('seq')['draft_delta_back'].transform('sum')\n",
        "  df['sum_draft_ahead'] = df.groupby('seq')['draft_delta_ahead'].transform('sum')\n",
        "  df['sum_draft'] = df['sum_draft_ahead'] + df['sum_draft_back']\n",
        "\n",
        "  condition = (df['seq_count'] <= 4) & (df['sum_draft'] <1)\n",
        "  df['pred_port'] = np.where(condition, 0, df['pred_port'])\n",
        "\n",
        "  # recasting vessel and pred_port columns as integers\n",
        "  df[['vessel', 'pred_port']] = df[['vessel', 'pred_port']].astype(int)\n",
        "\n",
        "\n",
        "  return df"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDnoQ4hnfhce"
      },
      "source": [
        "def get_voyages(df):\n",
        "  \"\"\"\n",
        "  converts the port sequences in each dataframe into voyages\n",
        "  with the proper formatting\n",
        "\n",
        "  param:\n",
        "  -----\n",
        "      df: pandas DataFrame\n",
        "  \n",
        "  returns:\n",
        "  -------\n",
        "      df: processed pandas DataFrame\n",
        "      \n",
        "  \"\"\"\n",
        "  # filtering out columns without an assigned port\n",
        "  nz = df[(df['pred_port'] > 0) | (df['pred_port'] == -75)].reset_index()\n",
        "\n",
        "  vessel = nz['vessel'][0]\n",
        "  dt = nz['datetime']\n",
        "  pred = nz['pred_port']\n",
        "\n",
        "  records = []\n",
        "\n",
        "  for i in range(len(dt)-1):\n",
        "    if pred[i] != pred[i+1]:\n",
        "      start_port = pred[i]\n",
        "      end_port = pred[i+1]\n",
        "      begin_date = dt[i]\n",
        "      end_date = dt[i+1]\n",
        "      records.append([vessel, begin_date, end_date, start_port, end_port])\n",
        "\n",
        "  df = pd.DataFrame.from_records(records, columns = ['vessel', 'begin_date', 'end_date', 'begin_port_id', 'end_port_id'])\n",
        "  \n",
        "  return df"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbHcYBVQcWst"
      },
      "source": [
        "# calculating the distance between each row using the vincenty function above.\n",
        "# note it only calcs within each vessel group (see function). the elapsed time\n",
        "# and the total distance travelled implies a speed and that speed allows for\n",
        "# effetcive filtering of impossible routes\n",
        "\n",
        "df2['vin_diff'] = df2.apply(vincent_distance, axis=1)\n",
        "df2['vin_per_hour'] = df2['vin_diff'] / df2['hour_delta']\n",
        "df2 = df2.query('vin_per_hour <= 50')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9tCbNDQiRfQ"
      },
      "source": [
        "# creating a dictionary of vessel dataframes with a datetime index\n",
        "\n",
        "vessel_dfs = {}\n",
        "\n",
        "for vessel in df2.vessel.unique():\n",
        "  df_ = df2[df2['vessel'] == vessel]\n",
        "  vessel_dfs[vessel] = df_.set_index('datetime')\n",
        "\n",
        "# assigning ports to each dataframe\n",
        "processed_dfs = {key:assign_ports(vessel_dfs[key]) for key in vessel_dfs.keys()}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irWz30hWlesV"
      },
      "source": [
        "alldf = pd.concat(processed_dfs[key] for key in processed_dfs.keys())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_TnV_EudLEQ"
      },
      "source": [
        "# creating a dictionary of dataframes for each port and then extracting the min,\n",
        "# max, and max_draft distances for assigned ports\n",
        "\n",
        "ports_dfs = {}\n",
        "\n",
        "for port in alldf.pred_port.unique():\n",
        "  ports_dfs[port] = alldf[alldf['pred_port'] == port]\n",
        "\n",
        "del ports_dfs[-1]\n",
        "del ports_dfs[0]\n",
        "\n",
        "min_max = {}\n",
        "\n",
        "for df in ports_dfs.keys():\n",
        "  draft_max = ports_dfs[df].query('sum_draft >=1').port_dist.max()\n",
        "  min_max[df] = [ports_dfs[df]['port_dist'].max(), ports_dfs[df]['port_dist'].min(), draft_max]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SIs4v7TvD-a"
      },
      "source": [
        "voyages_df = pd.concat([get_voyages(processed_dfs[key]) for key in processed_dfs.keys()])\n",
        "voyages_df['begin_date'] = voyages_df['begin_date'].dt.date\n",
        "voyages_df['end_date'] = voyages_df['end_date'].dt.date\n",
        "# voyages_df['len_voyage'] = voyages_df['end_date'] - voyages_df['begin_date']\n",
        "# voyages_df['begin_coords'] = [ports[key] for key in voyages_df['begin_port_id']]\n",
        "# voyages_df['end_coords'] = [ports[key] for key in voyages_df['end_port_id']]\n",
        "# voyages_df['voyage_dist'] = [vincenty(x, y) for x, y in zip(voyages_df['begin_coords'], voyages_df['end_coords'])]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUI1F3FtqaKT"
      },
      "source": [
        "voyages_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF-vL7n3WKGb"
      },
      "source": [
        "def prepare_data(df, n_input = 3):\n",
        "  \"\"\"\n",
        "  preparing the sequences for window based models\n",
        "  \"\"\"\n",
        "\n",
        "  df = get_voyages(df)\n",
        "  vessel = df['vessel'].iloc[0]\n",
        "  ports_ = np.array(df['begin_port_id'].append(pd.Series(df['end_port_id'].iloc[-1])))  \n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "  start = 0\n",
        "\n",
        "  for i in range(len(ports_)):\n",
        "    last_input = start + n_input\n",
        "    last_output = last_input + 3\n",
        "    if last_output <= len(ports_):\n",
        "      x = ports_[start:last_input]\n",
        "      y = ports_[last_input: last_output]\n",
        "      X.append(x)\n",
        "      Y.append(y)\n",
        "      start += 1\n",
        "  try:\n",
        "    df = pd.concat([pd.DataFrame(X),\n",
        "                  pd.DataFrame(Y, columns=['port_1ahead', 'port_2ahead', 'port_3ahead'])], axis=1)\n",
        "    \n",
        "  except:\n",
        "    df = pd.DataFrame()\n",
        "    \n",
        "  # X = []\n",
        "\n",
        "  # for x in X:\n",
        "  #   for n in x:\n",
        "  #     if n == -75:\n",
        "  #       port_coords = [33, 140]\n",
        "  #     else:\n",
        "  #       port_coords = list(ports[n])\n",
        "  #     port = [n]\n",
        "  #     port.extend(port_coords)\n",
        "  #     new_X.append(port)\n",
        "  \n",
        "  df['vessel'] = len(df) * [vessel]\n",
        "  \n",
        "  return df.astype(int)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MldbZ9EkYdqU"
      },
      "source": [
        "model_df = pd.concat([prepare_data(processed_dfs[key], 3) for key in processed_dfs.keys()])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtTQNF2qY-RB"
      },
      "source": [
        "def build_model(target='port_1ahead', min_samples=5, n_back = 6):\n",
        "\n",
        "  model_df = pd.concat([prepare_data(processed_dfs[key], n_back) for key in processed_dfs.keys()]) \n",
        "\n",
        "  model_df['cluster_1back'] = [db_labels[n] for n in model_df[0]]\n",
        "  model_df['cluster_2back'] = [db_labels[n] for n in model_df[1]]\n",
        "  model_df['cluster_3back'] = [db_labels[n] for n in model_df[2]]\n",
        "\n",
        "  model_df['samples'] = model_df.groupby('vessel')['vessel'].transform(lambda x: x.count())\n",
        "  filtered_df = model_df.query('samples > @min_samples')\n",
        "\n",
        "  vessels_excluded = set(model_df['vessel'].unique()).difference(set(filtered_df['vessel'].unique()))\n",
        "\n",
        "  features = [n for n in range(n_back)] + ['cluster_1back', 'cluster_2back', 'cluster_3back'] \n",
        "  target = target\n",
        "\n",
        "  X = filtered_df[features]\n",
        "  y = filtered_df[target]\n",
        "  model = XGBClassifier()\n",
        "\n",
        "  param_grid = {\n",
        "      'learning_rate': [0.01, 0.02, 0.03]\n",
        "  }\n",
        "\n",
        "  grid_search = GridSearchCV(model, param_grid, cv=3)\n",
        "  grid_result = grid_search.fit(X, y)\n",
        "\n",
        "  print('The training excluded vessels:', vessels_excluded)\n",
        "  print('The best model params were:', grid_result.best_params_)\n",
        "  print('The best accuracy achieved was:', grid_result.best_score_)\n",
        "  \n",
        "  return grid_result"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtEHbOIdTCDW"
      },
      "source": [
        "model_1ahead = build_model(target='port_1ahead', min_samples=5, n_back=3)\n",
        "model_2ahead = build_model(target='port_2ahead', min_samples=5, n_back=3)\n",
        "model_3ahead = build_model(target='port_3ahead', min_samples=5, n_back=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RO8RBNQqWb3"
      },
      "source": [
        "def find_next_port(df):\n",
        "  \"\"\"\n",
        "  find the next port visited for each row in the DataFrame, excluding the current \n",
        "  port. the value 0 is used to indicate that there is no next port in the data\n",
        "  \n",
        "  params\n",
        "  ------\n",
        "      df : pandas DataFrame\n",
        "\n",
        "  return\n",
        "  ------\n",
        "      df: pandas DataFrame \n",
        "  \n",
        "  \"\"\"\n",
        "\n",
        "  ports = df['pred_port']\n",
        "\n",
        "  next_port = []\n",
        "\n",
        "  for i in range(len(ports)):\n",
        "    p = ports[i]\n",
        "    for n in ports[i:]:\n",
        "      if (p != n) & (n >0) :\n",
        "        next_port.append(n)\n",
        "        break\n",
        "\n",
        "  # padding zeros at the end to indicate no next port \n",
        "  zeroes = [0] * (len(ports) - len(next_port))\n",
        "  next_ports = next_port + zeroes\n",
        "  \n",
        "  df['next_port'] = next_ports\n",
        "\n",
        "  return df"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP1YTJ8kwObP"
      },
      "source": [
        "# appending the series with the 'next port visited' data for each row. alternative\n",
        "# way of predicting the next port using the last observation in the unmodified\n",
        "# vessel datasets\n",
        "\n",
        "# for_another_model = [find_next_port(v) for k, v in processed_dfs.items()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u05T1sJz0MaK"
      },
      "source": [
        "# creating another model to predict the next port using more features. \n",
        "\n",
        "# df3 = pd.concat(for_another_model)\n",
        "# df3 = df3.sample(frac=0.1)\n",
        "\n",
        "# features = ['vessel', 'lat', 'long', 'heading', 'draft', 'pred_port', 'seq_count']\n",
        "# target = 'next_port'\n",
        "# threshold = '2019-10-01'\n",
        "# mask = df3.index < threshold\n",
        "\n",
        "# X_train = df3[mask][features]\n",
        "# y_train = df3[mask][target]\n",
        "\n",
        "# X_test = df3[~mask][features]\n",
        "# y_test = df3[~mask][target]\n",
        "\n",
        "# eval_set = [(X_test, y_test)]\n",
        "# model = XGBClassifier()\n",
        "\n",
        "# model.fit(X_train, y_train, eval_set=eval_set)\n",
        "\n",
        "# print('The model accuracy is:', model.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNRQE-8t6_RW"
      },
      "source": [
        "# [(x,y) for x,y in zip(X_train.columns, model.feature_importances_)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5ERpuNpF_WT"
      },
      "source": [
        "def get_pred_data(df, n_input = 3):\n",
        "  \"\"\"\n",
        "  preparing the sequences for window based models\n",
        "  \"\"\"\n",
        "\n",
        "  df = get_voyages(df)\n",
        "  vessel = df['vessel'].iloc[0]\n",
        "  ports_ = np.array(df['begin_port_id'].append(pd.Series(df['end_port_id'].iloc[-1])))  \n",
        "\n",
        "  return ports_[-n_input:]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NlGujqAv2FW"
      },
      "source": [
        "# creating a dictionary with the most recent ports visited for each vessel\n",
        "\n",
        "window_data = {key:get_pred_data(processed_dfs[key], n_input=3) for key in processed_dfs.keys()}"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJkGCyNIwvvS"
      },
      "source": [
        "# creating a dataframe with the features used in the models\n",
        "\n",
        "sub = pd.DataFrame.from_dict(window_data, orient='index')\n",
        "\n",
        "sub['cluster_1back'] = [db_labels[n] for n in sub[0]]\n",
        "sub['cluster_2back'] = [db_labels[n] for n in sub[1]]\n",
        "sub['cluster_3back'] = [db_labels[n] for n in sub[2]]"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i6_80Y91LAe"
      },
      "source": [
        "# predicting the next port. also including the second most likely port in case\n",
        "# the model predicts duplicates. \n",
        "\n",
        "port_1 = model_1ahead.predict(sub)\n",
        "port_2 = model_2ahead.predict(sub)\n",
        "port_2_alt = [model_2ahead.best_estimator_.classes_[np.argsort(n)[-2]] for n in model_2ahead.predict_proba(sub)]\n",
        "port_3 = model_3ahead.predict(sub)\n",
        "port_3_alt = [model_3ahead.best_estimator_.classes_[np.argsort(n)[-2]] for n in model_3ahead.predict_proba(sub)]\n",
        "sub['port_1ahead'] = port_1\n",
        "sub['port_2ahead'] = port_2\n",
        "sub['port_2ahead_2nd'] = port_2_alt\n",
        "sub['port_3ahead'] = port_3\n",
        "sub['port_3ahead_2nd'] = port_3_alt"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VJNB5MI0E0a"
      },
      "source": [
        "# using conditional assignment to replace port predictions with the second most\n",
        "# likely\n",
        "\n",
        "sub.loc[sub['port_1ahead'] == sub['port_2ahead'], 'port_2ahead'] = sub['port_2ahead_2nd']\n",
        "sub.loc[sub['port_2ahead'] == sub['port_3ahead'], 'port_3ahead'] = sub['port_3ahead_2nd']"
      ],
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3SrpcaTKtDo"
      },
      "source": [
        "# changing the shape of the dataframe so it conforms to what's required\n",
        "\n",
        "# resetting the index and renaming the column\n",
        "sub = sub.reset_index()\n",
        "sub.rename(columns={'index':'vessel'}, inplace=True)\n",
        "\n",
        "# limiting columns to those required and renaming\n",
        "sub = sub[['vessel', 2, 'port_1ahead', 'port_2ahead', 'port_3ahead']]\n",
        "sub.rename(columns={2:'final_port'}, inplace=True)\n",
        "\n",
        "# using melt to narrow the DataFrame and put the voyages into the same column\n",
        "sub = pd.melt(sub, id_vars='vessel').sort_values(by=['vessel', 'variable'])\n",
        "sub['end_port_id'] = sub.groupby('vessel')['value'].transform(lambda x: x.shift(-1))\n",
        "sub = sub.dropna()\n",
        "\n",
        "# adding a voyage count, more renaming\n",
        "sub['voyage'] = sub.groupby('vessel').cumcount()+1\n",
        "sub.rename(columns={'value' : 'begin_port_id'}, inplace=True)\n",
        "sub.drop(columns=['variable'], inplace=True)\n",
        "sub['end_port_id'] = sub['end_port_id'].astype(int)\n",
        "sub = sub.reset_index(drop=True)"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lipU-tqdU_Va"
      },
      "source": [
        "sub.to_csv('predict.csv', index=False)\n",
        "voyages_df.to_csv('voyages.csv', index=False)"
      ],
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd_OvZ0lenDm"
      },
      "source": [
        "fig = px.scatter_geo(alldf[alldf['vessel'] == 138], lat='lat', lon='long', size='port_dist',\n",
        "                     hover_name='pred_port')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnaJpiELRKK4"
      },
      "source": [
        "# submissions\n",
        "\n",
        "voyages = pd.DataFrame(columns= ['vessel', 'begin_date', 'end_date', 'begin_port_id', 'end_port_id'])\n",
        "predict = pd.DataFrame(columns= ['vessel', 'begin_port_id', 'end_port_id', 'voyage'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}